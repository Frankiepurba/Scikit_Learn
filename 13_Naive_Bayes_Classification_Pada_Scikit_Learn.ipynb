{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Classification Task dengan Naive Bayes\n",
    "\n",
    "`Classification Task dengan Naive Bayes` adalah keluarga \"pengklasifikasi probabilistik\" (probabilistic classifiers) sederhana berdasarkan penerapan teorema Bayes dengan asumsi independensi yang kuat (naif) di antara fitur-fiturnya (lihat pengklasifikasi Bayes). Mereka adalah salah satu model jaringan Bayesian yang paling sederhana, tetapi digabungkan dengan estimasi kepadatan kernel, mereka dapat mencapai tingkat akurasi yang lebih tinggi. \n",
    "\n",
    "Selain itu Classification Task dengan Naive Bayes juga sangat skalabel, membutuhkan sejumlah parameter linier dalam jumlah variabel (fitur / prediktor) dalam masalah pembelajaran. Pelatihan kemungkinan maksimum dapat dilakukan dengan mengevaluasi ekspresi bentuk tertutup, yang membutuhkan waktu linier, bukan dengan pendekatan berulang yang mahal seperti yang digunakan untuk banyak jenis pengklasifikasi lainnya.\n",
    "\n",
    "Referensi: [https://en.wikipedia.org/wiki/Naive_Bayes_classifier](https://en.wikipedia.org/wiki/Naive_Bayes_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bayes' Theorem\n",
    "\n",
    "Bayes' theorem menawarkan suatu formula untuk menghitung nilai probability dari suatu event dengan memanfaatkan pengetahuan sebelumnya dari kondisi terkait; atau sering kali dikenal dengan istilah conditional probability.\n",
    "\n",
    "$P(A|B) = \\frac{P(B|A) \\times P(A)}{P(B)}$ <br/>\n",
    "\n",
    "$P(y|X) = \\frac{P(X|y) \\times P(y)}{P(X)}$ <br/>\n",
    "\n",
    "$Posterior = \\frac{ Likelihood \\times Prior}{ Evidence }$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pengenalan Naive Bayes Classification\n",
    "\n",
    "##### Studi Kasus 1\n",
    "\n",
    "Semisal terdapat sebuah warung yang menawarkan tiga buah menu yaitu :\n",
    "- Siomay\n",
    "- Bakso\n",
    "- Lumpia\n",
    "\n",
    "Warung ini hanya memiliki dua pelanggan saja yaitu `Asep` dan `Joko`, untuk setiap pelanggan sudah didata probabilitas pemesanan mereka untuk setiap menu yang ditawarkan berikut adalah ilustrasi yang dapat dipahami.\n",
    "\n",
    "![](./images/asep_joko_snack.png)\n",
    "**Misi**: Lakukan prediksi siapa pelanggan yang melakukan pemesanan dengan diketahui pesanannya adalah **Lumpia** dan **Bakso**.\n",
    "\n",
    "##### Prior Probability: $P(y)$\n",
    "\n",
    "`Prior Probability` adalah nilai probability dari kemunculan suatu nilai target label tertentu tanpa memperhatikan nilai feature. **`P(y)`**  merupakan notasinya dan nilai ini akan bergantung pada nilai dataset yang dimiliki, untuk kasus disini kita dapat mengasumsikan bahwa peluang untuk suatu pemesanan dilakukan oleh Asep atau Joko adalah berimbang seperti sebagai berikut :\n",
    "\n",
    "- $P(Asep) = 0.5$\n",
    "- $P(Joko) = 0.5$\n",
    "\n",
    "Referensi: [https://en.wikipedia.org/wiki/Prior_probability](https://en.wikipedia.org/wiki/Prior_probability)\n",
    "\n",
    "\n",
    "\n",
    "##### Likelihood: $P(X|y)$\n",
    "\n",
    "`likelihood function` (sering disebut likelihood) mengukur kesesuaian model statistik ke sampel data untuk nilai tertentu dari parameter yang tidak diketahui. Ini dibentuk dari distribusi probabilitas gabungan sampel, tetapi dilihat dan digunakan sebagai fungsi parameter saja, sehingga memperlakukan variabel acak sebagai tetap pada nilai yang diamati.\n",
    "\n",
    "Likelihood juga dapat mendeskripsikan permukaan hiper yang puncaknya, jika ada, mewakili kombinasi nilai parameter model yang memaksimalkan probabilitas pengambilan sampel yang diperoleh. Prosedur untuk mendapatkan argumen dari fungsi kemungkinan maksimum ini dikenal sebagai estimasi kemungkinan maksimum, yang untuk kenyamanan komputasi biasanya dilakukan dengan menggunakan logaritma natural dari kemungkinan, yang dikenal sebagai fungsi kemungkinan log.\n",
    "\n",
    "\n",
    "Nilai probability atau kemungkinan lumpia dan bakso dengan nama pemesannya adalah **Asep** dapat dikalkulasikan sebagai berikut :\n",
    "- Asep:\n",
    "$$\n",
    "\\begin{aligned}\n",
    " P(lumpia,bakso|Asep) &= (0.1 \\times 0.8)\\\\ \n",
    "                      &= 0.08\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Nilai probability atau kemungkinan lumpia dan bakso dengan nama pemesannya adalah **Joko** dapat dikalkulasikan sebagai berikut :\n",
    "- Joko:\n",
    "$$\n",
    "\\begin{aligned}\n",
    " P(lumpia,bakso|Joko) &= (0.3 \\times 0.2)\\\\ \n",
    "                      &= 0.06\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Referensi: [https://en.wikipedia.org/wiki/Likelihood_function](https://en.wikipedia.org/wiki/Likelihood_function)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### Evidence atau Normalizer: $P(X)$\n",
    "\n",
    "Evidence atau Normalizer dapat didefinisikan dari total akumulasi dari hasil perkalian antara nilai `Likelihood` dengan `Prior`\n",
    "-\tP(X) sebagai notasi dari Evidence atau Normalizer\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    " Evidence &= \\sum (Likelihood \\times Prior) \\\\\n",
    " P(lumpia,bakso) &= (0.08 \\times 0.5)+ (0.06 \\times 0.5) \\\\\n",
    "                 &= 0.07\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "<!-- - Evidence $= \\sum ($Likelihood $\\times$ Prior$)$\n",
    "- Evidence = $P($lumpia,bakso$) = P($lumpia,bakso$|$Asep$) \\times P($Asep$) + P($lumpia,bakso$|$Joko$) \\times P($Joko$)  = (0.08 \\times 0.5)+ (0.06 \\times 0.5) = 0.07$ -->\n",
    "\n",
    "\n",
    "\n",
    "##### Posterior Probability: $P(y|X)$ \n",
    "\n",
    "`Posterior Probability` dari peristiwa acak atau proposisi tidak pasti adalah probabilitas bersyarat yang diberikan (Clarification needed) setelah bukti atau latar belakang yang relevan diperhitungkan. Posterior, dalam konteks ini, berarti setelah memperhitungkan bukti-bukti yang relevan terkait dengan kasus tertentu yang sedang diperiksa.\n",
    "\n",
    "Distribusi Posterior Probability adalah distribusi probabilitas dari kuantitas yang tidak diketahui, diperlakukan sebagai variabel acak, bergantung pada bukti yang diperoleh dari eksperimen atau survei.\n",
    "\n",
    "- Referensi: [https://en.wikipedia.org/wiki/Posterior_probability](https://en.wikipedia.org/wiki/Posterior_probability)\n",
    "\n",
    "- Formula: <br/>\n",
    "$Posterior = \\frac{ Likelihood \\times Prior}{ Evidence }$\n",
    "\n",
    "Pertama **Asep** adalah sebagai pemesan bila diketahui pesanannya adalah **lumpia** dan **bakso** seperti sebagai berikut :\n",
    "- Asep:\n",
    "$$\n",
    "\\begin{aligned}\n",
    " P(Asep|lumpia,bakso) &= \\frac{0.08 \\times 0.5}{0.07} \\\\\n",
    "                      &= 0.57 \n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Kedua **Joko** adalah sebagai pemesan bila diketahui pesanannya adalah **lumpia** dan **bakso** seperti sebagai berikut :\n",
    "- Joko:\n",
    "$$\n",
    "\\begin{aligned}\n",
    " P(Joko|lumpia,bakso) &= \\frac{0.06 \\times 0.5}{0.07} \\\\\n",
    "                      &= 0.43 \n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### Studi Kasus 2\n",
    "\n",
    "Studi kasus berikut kita akan diminta untuk melakukan klasifikasi pelanggan berdasarkan informasi pemesanan yang diterima, hanya saja kali ini pemesanannya adalah **siomay** dan **bakso** seperti dibawah ini.\n",
    "\n",
    "![](./images/asep_joko_snack.png)\n",
    "**Misi**: Lakukan prediksi siapa pelanggan yang melakukan pemesanan dengan diketahui pesanannya adalah **siomay** dan **bakso**.\n",
    "\n",
    "##### Posterior Probability: $P(y|X)$ (kasus 2)\n",
    "- pesanan: siomay, bakso\n",
    "- Evidence: $P(X)$\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "P(siomay,bakso) &= (0.1 \\times 0.8 \\times 0.5) + (0.5 \\times 0.2 \\times 0.5) \\\\\n",
    "&= 0.09\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Pertama kita akan hitung nilai probability **Asep** sebagai pemesan bila diketahui pesanannya adalah **siomay** dan **bakso** seperti sebagai berikut :\n",
    "- Asep:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "P(Asep|siomay,bakso) &= \\frac{(0.1 \\times 0.8) \\times 0.5}{0.09} \\\\\n",
    "                     &= 0.444\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Kedua kita akan hitung nilai probability **Joko** sebagai pemesan bila diketahui pesanannya adalah **siomay** dan **bakso** seperti sebagai berikut :\n",
    "- Joko:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "P(Joko|siomay,bakso) &= \\frac{(0.5 \\times 0.2) \\times 0.5}{0.09} \\\\\n",
    "                     &= 0.555\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Apa dan mengapa disebut Naive Bayes?\n",
    "\n",
    "Mengapa model ini disebut dengan Bayes?. Karena kata Bayes berasal dari nama orang statistion yaitu **Thomas Bayes** yang menggagas suatu theorem yang dikenal sebagai **Bayes Theorem** .\n",
    "\n",
    "- Karena sewaktu kita mendefinisikan Likelihood $P(lumpia,bakso|Asep)$, <br/>\n",
    "\n",
    "Mengapa model ini disebut dengan Naive?. Karena suatu kita mendefinisikan `Likelihood` nilai probability kemunculan pemesana lumpia dan bakso bila diketahui pemesannya adalah **Asep** kita mengasumsikan bahwa nilai probability kemunculan pemesan lumpia bila diketahui pemesannya adalah Asep itu kondisional independent terhadap nilai probability dari nilai kemunculan nilai pesanan bakso bila diketahui pemesannya adalah Asep dan demikian sebaliknya seperti keterangan sebagai berikut :\n",
    "\n",
    "- kita mengasumsikan $P(lumpia|Asep)$ conditionally independent terhadap $P(bakso|Asep)$; demikian sebaliknya. <br/>\n",
    "- Sehingga dapat diformulasikan sebagai berikut:\n",
    "\n",
    "$P(lumpia,bakso|Asep) = P(lumpia|Asep) \\times P(bakso|Asep)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Dataset: Breast Cancer Wisconsin (Diagnostic) \n",
    "\n",
    "Pada tahap ini pertama-tama kita akan mempersiapkan Datasetnya, untuk kali ini kita memakai Dataset dari `Breast Cancer Wisconsin (Diagnostic)` yang merupakan open dataset ditawarkan oleh `UCI Machine Learning`.\n",
    "\n",
    "Referensi: [https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Load Dataset\n",
    "\n",
    "Pada tahap `Load Dataset` pertama-tama kita melakukan import module `from sklearn.datasets import load_breast_cancer` yang diikuti dengan `print(load_breast_cancer().DESCR` seperti script dibawah ini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _breast_cancer_dataset:\n",
      "\n",
      "Breast cancer wisconsin (diagnostic) dataset\n",
      "--------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry\n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        worst/largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 0 is Mean Radius, field\n",
      "        10 is Radius SE, field 20 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "print(load_breast_cancer().DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Dengan menggunakan jupyter notebook kita dapat memiliki kebebasan untuk melakukan akses dokumentasi suatu `function` tertentu sebagai contoh untuk mengakses dokumentasi dari `load_breast_cancer?`. Setelah proses dieksekusi maka kita akan mendapatkan akses ke dokumentasi dari function tersebut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_breast_cancer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Selanjutnya kita akan coba untuk melakukan eksekuysi script berikut dengan cara memanggil `load_breast_cancer(return_X_y=True)` yang memiliki parameter `return_X_y=True` kemudian ditampung ke dalam variabel sebagai berikut :\n",
    "- `X` menampung nilai Features\n",
    "- `y` menampung nilai Label\n",
    "\n",
    "Lalu `X.shape` seperti script dibawah ini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training & Testing Set\n",
    "\n",
    "Sebelum melakukan `Training & Testing Set` terlebih dahulu kita melakukam import module `from sklearn.model_selection import train_test_split` dengan memanggil `train_test_split` yang memilik parameter sebagai berikut :\n",
    "\n",
    "- `X`\n",
    "- `y`\n",
    "- `test_size=0.2`\n",
    "- `random_state=0)`\n",
    "\n",
    "Kemudian ditampung ke dalam 4 variabel yaitu `X_train, X_test, y_train, y_test`, lalu memanggil shape seperti diabwah ini.\n",
    "\n",
    "- `pint(f'X_train shape {X_train.shape}')`\n",
    "- `print(f'X_test shape {X_test.shape}')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape (455, 30)\n",
      "X_test shape (114, 30)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=0)\n",
    "\n",
    "print(f'X_train shape {X_train.shape}')\n",
    "print(f'X_test shape {X_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Naive Bayes dengan Scikit Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selanjutnya kita juga dapat melakukan `Naive Bayes` dengan `Scikit Learn`, untuk melakukannya pertama-tama kita melakukan 2 buah import module `from sklearn.naive_bayes import GaussianNB` dan `from sklearn.metrics import accuracy_score`. Kemudian memanggili `GaussianNB()` yang ditampung ke dalam variabel `model` lalu melakukan fit `model.fit(X_train, y_train)` dengan 2 parameter yaiut `X_train` dan `y_train` serta diikuti dengan melakukan prediksi model `model.predict(X_test)` yang ditampung ke dalam variabel `y_pred` dan memanggil `accuracy_score(y_test, y_pred)` seperti script dibawah ini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9298245614035088"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Script diatas dapat juga dapat peroleh cara yang sederhana hanya dengan memanggil `model.score(X_test, y_test)` yang memiliki 2 buah parameter `X_test` dan `y_test` seperti script dibawah ini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9298245614035088"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

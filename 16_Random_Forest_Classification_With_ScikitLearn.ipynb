{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 16 Classification Task dengan Random Forest\n",
    "\n",
    "\n",
    "**`Random Forest`** adalah metode pembelajaran ensemble untuk klasifikasi, regresi dan tugas-tugas lain yang beroperasi dengan membangun banyak pohon keputusan pada waktu pelatihan. Untuk tugas klasifikasi, output dari hutan acak adalah kelas yang dipilih oleh sebagian besar pohon. Untuk tugas regresi, prediksi rata-rata atau rata-rata dari masing-masing pohon dikembalikan. Decision Random Forest yang benar untuk kebiasaan pohon keputusan yang terlalu pas dengan set pelatihan mereka. Hutan acak umumnya mengungguli pohon keputusan, tetapi akurasinya lebih rendah daripada pohon yang didorong gradien. Namun, karakteristik data dapat memengaruhi kinerjanya.\n",
    "\n",
    "\n",
    "Referensi: [https://en.wikipedia.org/wiki/Random_forest](https://en.wikipedia.org/wiki/Random_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## General ML Model Training\n",
    "\n",
    "Pada `Random Forest` sebelumnya kita akan membahas mengenai mekanisme kerja random forest, pertama-tama kita akan mempelajari kembali General Workflow proses `Training Model` dalam machine learning. Proses training akan diawali dengan `Training Set` yang terdiri dari training feature (`X_train`) dan juga sekumpulan label (`y_train`) hal tersebut digunakan untuk proses training model, model yang sudah ditraining tersebut akan dikenal dengan `Trained Model` yang digunakan untuk melakukan prediksi terhadap sekumpulan nilai features (`X_new`) dan `y_pred` setelah trained model.\n",
    "\n",
    "<div>\n",
    "    <img src=\"./images/general_ML_model_training.png\" width=\"500\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ensemble Learning: heterogeneous & homogeneous\n",
    "\n",
    "`**Ensemble Learning**` menggunakan beberapa `algoritma pembelajaran untuk mendapatkan kinerja prediktif yang lebih baik daripada yang bisa diperoleh dari salah satu algoritma pembelajaran konstituen saja`. Tidak seperti ansambel statistik dalam mekanika statistik, yang biasanya tidak terbatas, ansambel pembelajaran mesin hanya terdiri dari serangkaian model alternatif yang terbatas, tetapi biasanya memungkinkan struktur yang jauh lebih fleksibel untuk ada di antara alternatif-alternatif tersebut.\n",
    "\n",
    "Pada kali ini training set yang tersedia akan digunakan untuk melakukan training ke beberapa training model, untuk kasus ini ada 3 training model yaitu : `KNN`, `SVM`, dan `Decision Tree`. Proses training tersebut akan menghasilkan 3 buah trained model yaitu `Trained Model 1`, `Trained Model 2`, dan `Trained Model 3` yang akan digunakan untuk melakukan presdiksi terhadap sekumpulan feature yang baru yang direpresentasikan sebagai `y_pred 1`, `y_pred 2`, dan `y_pred 3` terhadap masing masing-masing `x_new` yang akan disatukan ke suatu mekanisme yang dikenal dengan istilah majority voting yang menggunakan nilai `Mean (rata-rata)` sebagai regression task dan `Mode (Kemunculan terbanyak)` sebagai classification task. Pada kasus ini hasil akhir akan dipresentasikan sebagai `y_pred final` seperti gambar yang ada dibawah ini.\n",
    "\n",
    "- Ensemble Learning: heterogeneous sebagai paduan jenis model learning yang berbeda.\n",
    "- Ensemble Learning: homogeneous sebagai paduan jenis model learning yang sama.\n",
    "\n",
    "\n",
    "Referensi: [https://en.wikipedia.org/wiki/Ensemble_learning](https://en.wikipedia.org/wiki/Ensemble_learning)\n",
    "<p/>\n",
    "\n",
    "<div>\n",
    "    <img src=\"./images/ensemble_learning.png\" width=\"800\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bagging: Bootstrap Aggregating\n",
    "\n",
    "\n",
    "`Bootstrap Aggregating (Bagging)` adalah meta-algoritma ansambel pembelajaran mesin yang dirancang untuk meningkatkan stabilitas dan akurasi algoritme pembelajaran mesin yang digunakan dalam klasifikasi dan regresi statistik. Ini juga mengurangi varians dan membantu menghindari overfitting. Meskipun biasanya diterapkan pada metode pohon keputusan, metode ini dapat digunakan dengan semua jenis metode. Bagging adalah kasus khusus dari model pendekatan rata-rata.\n",
    "\n",
    "Pada kasus kali ini adalah Ensemble Learning: homogeneous dikarenakan menggunakan 3 `Model` yang sama atau sejenis. Dengan menggunakan `Model` yang sama bisa dibilang dengan hal yang sia-sia karena akan menghasilkan nilai trained model yang sama persis, namun disini kita akan menggunakan `**Bootstrap Aggregating (Bagging)**` dengan melakukan proses `Random Sampling with Replacement` terhadap training set yang kita miliki dan akan menghasilkan beberapa training set yang baru sejumlah model yang akan kita training yang dikenal dengan istilah `Bag 1`, `Bag 2`, dan `Bag 3` seperti gambar dibawah ini.\n",
    "\n",
    "\n",
    "Referensi: [https://en.wikipedia.org/wiki/Bootstrap_aggregating](https://en.wikipedia.org/wiki/Bootstrap_aggregating)\n",
    "<p/>\n",
    "\n",
    "<div>\n",
    "    <img src=\"./images/bagging.png\" width=\"800\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Random Forest\n",
    "\n",
    "\n",
    "`**Random Forest**` adalah metode pembelajaran ensemble untuk klasifikasi, regresi dan tugas-tugas lain yang beroperasi dengan membangun banyak pohon keputusan pada waktu pelatihan. Untuk tugas klasifikasi, output dari hutan acak adalah kelas yang dipilih oleh sebagian besar pohon. Untuk tugas regresi, prediksi rata-rata atau rata-rata dari masing-masing pohon dikembalikan. Hutan keputusan acak benar untuk kebiasaan pohon keputusan yang terlalu pas dengan set pelatihan mereka. Hutan acak umumnya mengungguli pohon keputusan, tetapi akurasinya lebih rendah daripada pohon yang didorong gradien. Namun, karakteristik data dapat memengaruhi kinerjanya.\n",
    " \n",
    "Algoritma pertama untuk hutan keputusan acak dibuat pada tahun 1995 oleh Tin Kam Ho menggunakan metode subruang acak, yang, dalam formulasi Ho, adalah cara untuk menerapkan pendekatan \"diskriminasi stokastik\" untuk klasifikasi yang diusulkan oleh Eugene Kleinberg.\n",
    "\n",
    "Gambar berikut menggunakan `Bagging + Features Randomness` yang akan menghasilkan berbagai macam `Trained Model` yang selanjutnya akan di lakukan majority voting `Mean` atau `Mode` sebagai hasil akhir atau final.\n",
    "\n",
    "\n",
    "Referensi: [https://en.wikipedia.org/wiki/Random_forest](https://en.wikipedia.org/wiki/Random_forest)\n",
    "<p/>\n",
    "\n",
    "<div>\n",
    "    <img src=\"./images/random_forest.png\" width=\"800\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Dataset\n",
    "\n",
    "`Iris Flower Dataset` adalah kumpulan data multivariat yang diperkenalkan oleh ahli statistik, eugenika, dan ahli biologi Inggris Ronald Fisher dalam makalahnya tahun 1936 Penggunaan beberapa pengukuran dalam masalah taksonomi sebagai contoh analisis diskriminan linier. Kadang-kadang disebut kumpulan data Iris Anderson karena Edgar Anderson mengumpulkan data untuk mengukur variasi morfologi bunga Iris dari tiga spesies terkait. Dua dari tiga spesies dikumpulkan di Semenanjung Gasp√© \"semuanya dari padang rumput yang sama, dan dipetik pada hari yang sama dan diukur pada waktu yang sama oleh orang yang sama dengan peralatan yang sama\".\n",
    "\n",
    "Kumpulan data terdiri dari 50 sampel dari masing-masing tiga spesies Iris (`Iris setosa`, `Iris virginica`, and `Iris versicolor`). Empat fitur diukur dari setiap sampel: panjang dan lebar sepal dan petal, dalam sentimeter. Berdasarkan kombinasi keempat fitur ini, Fisher mengembangkan model diskriminan linier untuk membedakan spesies satu sama lain.\n",
    "\n",
    "\n",
    "Referensi: [https://en.wikipedia.org/wiki/Iris_flower_data_set](https://en.wikipedia.org/wiki/Iris_flower_data_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Pada tahap ini terlebih dahulu untuk melakukan import module `from sklearn.datasets import load_iris` selanjutnya memanggil `load_iris(return_X_y=True)` yang ditampung ke dalam dua variabel `X` dan `y` kemudian mengubah dimensi feature dengan `X.shape` seperti script dibawah ini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensi Feature: (150, 4)\n",
      "Class: {0, 1, 2}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "print(f'Dimensi Feature: {X.shape}')\n",
    "print(f'Class: {set(y)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Tahap selanjutnya kita akan melakukan `Training` dan `Testing` split dengan terlebih dahulu melakukan import module `from sklearn.model_selection import train_test_split` kemudian memanggil `train_test_split(X, y, test_size=0.3, random_state=0)` yang ditampung ke dalam variabel `X_train, X_test, y_train, y_test` seperti script dibawah ini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Classification dengan `RandomForestClassifier`\n",
    "\n",
    "Melakukan Classification dengan `RandomForestClassifier` pertama-tama melakukan import module dengan `from sklearn.ensemble import RandomForestClassifier` kemudian memanggil `RandomForestClassifier(n_estimators=100, random_state=0)` yang ditampung ke dalam variabel `model` lau melakukan model fit dengan `model.fit(X_train, y_train)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, \n",
    "                               random_state=0)\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Evaluasi Model\n",
    "\n",
    "Pada tahap ini kita akan melakukan evaluasi peforma dari model random forest yang sebelumnya kita lakukan, pertama-tama kita melakukan import module dengan `from sklearn.metrics import classification_report` kemudian memanggil `model.predict(X_test)` yang ditampung ke dalam variabel `y_pred` selanjutnya mencetak ke layar dengan `print(classification_report(y_test, y_pred))`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      0.94      0.97        18\n",
      "           2       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.97      0.98      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 10 Mengenal Text Processing: <br/>Bag of Words & Stop Word Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bag of Words model sebagai representasi text\n",
    "\n",
    "Bag of Words bertujuan untuk menyederhanakan representasi text sebagai sekumpulan kata serta mengabaikan grammar dan posisi tiap kata pada kalimat. Kemudian text akan dikonversi menjadi lowercase dan tanda baca akan diabaikan.\n",
    "\n",
    "Referensi: [https://en.wikipedia.org/wiki/Bag-of-words_model](https://en.wikipedia.org/wiki/Bag-of-words_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Dataset\n",
    "\n",
    "Sebelum melakukan ``Bag of Words & Stop Word Filtering`` pertama-tama kita mempersiapkan Dataset terlebih dahulu dengan ``corpus`` (Dataset Pendek) sebagai variabel yang berisikan list sebagai berikut :\n",
    "\n",
    "- ``'Linux has been around since the mid-1990s.'``\n",
    "- ``'Linux distributions include the Linux kernel.'``\n",
    "- ``'Linux is one of the most prominent open-source software.'``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Linux has been around since the mid-1990s.',\n",
       " 'Linux distributions include the Linux kernel.',\n",
       " 'Linux is one of the most prominent open-source software.']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [\n",
    "    'Linux has been around since the mid-1990s.',\n",
    "    'Linux distributions include the Linux kernel.',\n",
    "    'Linux is one of the most prominent open-source software.'\n",
    "]\n",
    "\n",
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Bag of Words model dengan `CountVectorizer`\n",
    "\n",
    "Bag of Words model dapat diterapkan dengan memanfatkan `CountVectorizer`.\n",
    "\n",
    "`CountVectorizer` biasa digunakan untuk mengonversikan kumpulan dokumen teks menjadi vektor jumlah istilah/token. Ini juga memungkinkan pra-pemrosesan data teks sebelum menghasilkan representasi vektor. Fungsionalitas ini menjadikannya modul representasi fitur yang sangat fleksibel untuk teks.\n",
    "\n",
    "Referensi : https://ichi.pro/id/countvectorizer-dengan-python-42072304686163\n",
    "\n",
    "Sebelum melakukan `CountVectorizer` terlebih dahulu untuk import module `from sklearn.feature_extraction.text import CountVectorizer` dengan memanggil `CountVectorizer()` yang ditampung ke dalam variabel `vectorizer`. Selanjutnya melakukan tranform fit `fit_transform(corpus)` dengan parameter `corpus` yang diikuti method `todense()` kemudian ditampung ke dalam variabel `vectorized_X` seperti script dibawah ini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       "        [0, 0, 0, 1, 0, 1, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1]],\n",
       "       dtype=int64)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vectorized_X = vectorizer.fit_transform(corpus).todense()\n",
    "vectorized_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Hasil diatas akan merepresentasikan sebagai berikut :\n",
    "\n",
    "- `[1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1]` sebagai `'Linux has been around since the mid-1990s.'`\n",
    "- `[0, 0, 0, 1, 0, 1, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]` sebagai `'Linux distributions include the Linux kernel.'`\n",
    "- `[0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1]` sebagai `'Linux is one of the most prominent open-source software.'`\n",
    "\n",
    "Untuk informasi mengenai angka **1** dan **0** diatas kita dapat mengetahuinya dengan memanggil `vectorizer.get_feature_names()` yang nilai pada array tidak hanya **0** dan **1**. Setiap nilai tersebut merepresentasikan jumlah kemunculan token/kata tertentu pada kalimat seperti script dibawah ini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1990s',\n",
       " 'around',\n",
       " 'been',\n",
       " 'distributions',\n",
       " 'has',\n",
       " 'include',\n",
       " 'is',\n",
       " 'kernel',\n",
       " 'linux',\n",
       " 'mid',\n",
       " 'most',\n",
       " 'of',\n",
       " 'one',\n",
       " 'open',\n",
       " 'prominent',\n",
       " 'since',\n",
       " 'software',\n",
       " 'source',\n",
       " 'the']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Hasil diatas diurutkan berdasarkan dari `CountVectorizer` yang memiliki nilai lower atau huruf kecil."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Euclidean Distance untuk mengukur kedekatan/jarak antar dokumen (vector)\n",
    "\n",
    "\n",
    "Euclidean distance adalah perhitungan jarak dari 2 buah titik dalam Euclidean space. Jarak Euclidean biasa diterapkan untuk membantu proses klasifikasi pada data mining, jarak euclidean diterapkan untuk berbagai dimensi.\n",
    "\n",
    "\n",
    "Referensi : https://www.kitainformatika.com/2019/10/mengukur-jarak-euclidean-teori-dan.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Sebelum melakukan Euclidean Distance terlebih dahulu untuk melakukan import module `from sklearn.metrics.pairwise import euclidean_distances` dengan pemahaman bahwa kalimat pertama akan diukur dengan kalimat kedua bergitu juga untuk selanjutnya dengan memakai statement script dibawah ini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jarak dokumen 1 dan 2: [[3.16227766]]\n",
      "Jarak dokumen 1 dan 3: [[3.74165739]]\n",
      "Jarak dokumen 2 dan 3: [[3.46410162]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "for i in range(len(vectorized_X)):\n",
    "    for j in range(i, len(vectorized_X)):\n",
    "        if i == j:\n",
    "            continue\n",
    "        jarak = euclidean_distances(vectorized_X[i], vectorized_X[j])\n",
    "        print(f'Jarak dokumen {i+1} dan {j+1}: {jarak}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Stop Word Filtering pada text\n",
    "\n",
    "Stop Word Filtering menyederhanakan representasi text dengan mengabaikan beberapa kata seperti determiners (the, a, an),  auxiliary verbs (do, be, will), dan prepositions (on, in, at).\n",
    "\n",
    "Stop Word biasanya mengacu pada kata-kata atau teks yang paling umum dalam suatu bahasa, tidak ada daftar kata berhenti universal tunggal yang digunakan oleh semua alat pemrosesan bahasa alami, dan bahkan tidak semua alat menggunakan daftar seperti itu. Beberapa alat secara khusus menghindari penghapusan kata-kata berhenti ini untuk mendukung pencarian frase.\n",
    "\n",
    "Referensi: [https://en.wikipedia.org/wiki/Stop_word](https://en.wikipedia.org/wiki/Stop_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Dataset\n",
    "\n",
    "Pada tahap `Stop Word Filtering pada test` dapat menggunakan dataset sebelumnya seperti sebagai berikut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Linux has been around since the mid-1990s.',\n",
       " 'Linux distributions include the Linux kernel.',\n",
       " 'Linux is one of the most prominent open-source software.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Stop Word Filtering dengan `CountVectorizer`\n",
    "\n",
    "Stop Word Filtering juga dapat diterapkan dengan memanfatkan `CountVectorizer` dengan melakukan import module terlebih dahulu `from sklearn.feature_extraction.text import CountVectorizer` dengan memanggil `CountVectorizer(stop_words='english')` yang berisikan parameter `stop_words='english'` ditampung ke dalam variabel `vectorizer`. Selanjutnya melakukan tranform fit `fit_transform(corpus)` dengan parameter `corpus` yang diikuti method `todense()` kemudian ditampung ke dalam variabel `vectorized_X` seperti script dibawah ini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 0, 0, 0, 1, 1, 0, 0, 0, 0],\n",
       "        [0, 1, 1, 1, 2, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 0, 1, 1, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "vectorized_X = vectorizer.fit_transform(corpus).todense()\n",
    "vectorized_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Hasil diatas akan merepresentasikan sebagai berikut :\n",
    "\n",
    "- `[1, 0, 0, 0, 1, 1, 0, 0, 0, 0]` sebagai `'Linux has been around since the mid-1990s.'`\n",
    "- `[0, 1, 1, 1, 2, 0, 0, 0, 0, 0]` sebagai `'Linux distributions include the Linux kernel.'`\n",
    "- `[0, 0, 0, 0, 1, 0, 1, 1, 1, 1]` sebagai `'Linux is one of the most prominent open-source software.'`\n",
    "\n",
    "Untuk informasi mengenai angka **1** dan **0** diatas kita dapat mengetahuinya dengan memanggil `vectorizer.get_feature_names()` yang nilai pada array tidak hanya **0** dan **1**. Setiap nilai tersebut merepresentasikan jumlah kemunculan token/kata tertentu pada kalimat seperti script dibawah ini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1990s',\n",
       " 'distributions',\n",
       " 'include',\n",
       " 'kernel',\n",
       " 'linux',\n",
       " 'mid',\n",
       " 'open',\n",
       " 'prominent',\n",
       " 'software',\n",
       " 'source']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Load Boston Housing Price\n",
    "\n",
    "\n",
    "**Load Boston Housing Price** merupakan sebuah `sample dataset` yang disediakan oleh `scikit learn`. Sample dataset tersebut akan digunakan untuk melakukan prediksi harga rumah dengan beberapa cara `Regression` seperti dibawah ini.\n",
    "\n",
    "\n",
    "### `1. Simple Linear Regression`\n",
    "### `2. Multiple Linear Regression`\n",
    "### `3. Polynomial Regression`\n",
    "### `4. K Nearest Neighbours (KNN)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Sample Dataset Load Boston Housing Price\n",
    "\n",
    "Pada tahap `Sample Dataset` terlebih dahulu kita untuk melakukan `from sklearn.datasets import load_boston` dengan mempersiapkan `sample dataset` yang akan di olah yaitu `load_boston()` dan ditampung ke dalam variabel `boston_dataset` seperti script dibawah ini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n",
       "         4.9800e+00],\n",
       "        [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n",
       "         9.1400e+00],\n",
       "        [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n",
       "         4.0300e+00],\n",
       "        ...,\n",
       "        [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "         5.6400e+00],\n",
       "        [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n",
       "         6.4800e+00],\n",
       "        [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "         7.8800e+00]]),\n",
       " 'target': array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
       "        18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
       "        15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
       "        13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
       "        21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
       "        35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
       "        19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
       "        20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
       "        23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
       "        33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
       "        21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
       "        20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
       "        23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
       "        15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
       "        17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
       "        25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
       "        23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
       "        32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
       "        34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
       "        20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
       "        26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
       "        31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
       "        22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
       "        42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
       "        36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
       "        32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
       "        20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
       "        20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
       "        22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
       "        21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
       "        19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
       "        32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
       "        18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
       "        16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
       "        13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
       "         7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
       "        12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
       "        27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
       "         8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
       "         9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
       "        10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
       "        15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
       "        19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
       "        29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
       "        20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
       "        23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9]),\n",
       " 'feature_names': array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
       "        'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='<U7'),\n",
       " 'DESCR': \".. _boston_dataset:\\n\\nBoston house prices dataset\\n---------------------------\\n\\n**Data Set Characteristics:**  \\n\\n    :Number of Instances: 506 \\n\\n    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\\n\\n    :Attribute Information (in order):\\n        - CRIM     per capita crime rate by town\\n        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\\n        - INDUS    proportion of non-retail business acres per town\\n        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\\n        - NOX      nitric oxides concentration (parts per 10 million)\\n        - RM       average number of rooms per dwelling\\n        - AGE      proportion of owner-occupied units built prior to 1940\\n        - DIS      weighted distances to five Boston employment centres\\n        - RAD      index of accessibility to radial highways\\n        - TAX      full-value property-tax rate per $10,000\\n        - PTRATIO  pupil-teacher ratio by town\\n        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\\n        - LSTAT    % lower status of the population\\n        - MEDV     Median value of owner-occupied homes in $1000's\\n\\n    :Missing Attribute Values: None\\n\\n    :Creator: Harrison, D. and Rubinfeld, D.L.\\n\\nThis is a copy of UCI ML housing dataset.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/housing/\\n\\n\\nThis dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\\n\\nThe Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\\nprices and the demand for clean air', J. Environ. Economics & Management,\\nvol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\\n...', Wiley, 1980.   N.B. Various transformations are used in the table on\\npages 244-261 of the latter.\\n\\nThe Boston house-price data has been used in many machine learning papers that address regression\\nproblems.   \\n     \\n.. topic:: References\\n\\n   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\\n   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\\n\",\n",
       " 'filename': 'C:\\\\Users\\\\User\\\\anaconda3\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\boston_house_prices.csv'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston_dataset = load_boston()\n",
    "\n",
    "boston_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 01 Simple Linear Regression\n",
    "\n",
    "Simple Linear Regression akan memodelkan hubungan antara sebuah response variable dengan sebuah explanatory variable sebagai suatu garis lurus (linear). `Simple linear regression` adalah model yang paling pertama kali diperkenalkan dalam model `Machine Learnig`\n",
    "\n",
    "Referensi: [https://en.wikipedia.org/wiki/Simple_linear_regression](https://en.wikipedia.org/wiki/Simple_linear_regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Pilihan Features\n",
    "\n",
    "Pada kasus kali ini memilih **`RM`** (Jumlah Kamar Rumah) sebagai Feature dan **`Price`** (Harga) sebagai Target. Pemilihan tersebut dikarenakan banyaknya permintaan umum seperti Jumlah Kamar yang ada di dalam rumah, maka permintaan tersebut akan sangat memengaruhi Price (Harga) yang di tentukan dari Sample Dataset untuk diprediksi.\n",
    "\n",
    "Untuk Keterangan yang dipilih adalah sebagai berikut :\n",
    "- **RM** (average number of rooms per dwelling) adalah Jumlah kamar setiap rumah sebagai **`Features`**.\n",
    "- **Price** adalah harga sebagai **`Target`**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sample Dataset\n",
    "\n",
    "Pada tahap `Sample Dataset` terlebih dahulu kita untuk melakukan `import pandas as pd` dengan mempersiapkan `sample_data` yang akan di olah yaitu `Load Boston Housing Price` sebagai berikut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...    ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786  1.0  273.0   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875  1.0  273.0   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675  1.0  273.0   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889  1.0  273.0   \n",
       "505  0.04741   0.0  11.93   0.0  0.573  6.030  80.8  2.5050  1.0  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  \n",
       "0       15.3  396.90   4.98  \n",
       "1       17.8  396.90   9.14  \n",
       "2       17.8  392.83   4.03  \n",
       "3       18.7  394.63   2.94  \n",
       "4       18.7  396.90   5.33  \n",
       "..       ...     ...    ...  \n",
       "501     21.0  391.99   9.67  \n",
       "502     21.0  396.90   9.08  \n",
       "503     21.0  396.90   5.64  \n",
       "504     21.0  393.45   6.48  \n",
       "505     21.0  396.90   7.88  \n",
       "\n",
       "[506 rows x 13 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "boston_df = pd.DataFrame(boston_dataset.data, columns=boston_dataset.feature_names)\n",
    "boston_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Untuk mengetahui harga rumah dari sample dataset yang disediakan, kita dapat menambahkan kolom harga sebagai `Price` seperti tampilan script dibawah ini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...    ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786  1.0  273.0   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875  1.0  273.0   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675  1.0  273.0   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889  1.0  273.0   \n",
       "505  0.04741   0.0  11.93   0.0  0.573  6.030  80.8  2.5050  1.0  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  Price  \n",
       "0       15.3  396.90   4.98   24.0  \n",
       "1       17.8  396.90   9.14   21.6  \n",
       "2       17.8  392.83   4.03   34.7  \n",
       "3       18.7  394.63   2.94   33.4  \n",
       "4       18.7  396.90   5.33   36.2  \n",
       "..       ...     ...    ...    ...  \n",
       "501     21.0  391.99   9.67   22.4  \n",
       "502     21.0  396.90   9.08   20.6  \n",
       "503     21.0  396.90   5.64   23.9  \n",
       "504     21.0  393.45   6.48   22.0  \n",
       "505     21.0  396.90   7.88   11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_df['Price'] = boston_dataset.target\n",
    "boston_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Selanjutnya kita juga dapat mengambil dan menampilkan hanya beberapa dataset yang tersedia seperti script dibawah ini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RM</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.575</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.421</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.185</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.998</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.147</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>6.593</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>6.120</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>6.976</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>6.794</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>6.030</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        RM  Price\n",
       "0    6.575   24.0\n",
       "1    6.421   21.6\n",
       "2    7.185   34.7\n",
       "3    6.998   33.4\n",
       "4    7.147   36.2\n",
       "..     ...    ...\n",
       "501  6.593   22.4\n",
       "502  6.120   20.6\n",
       "503  6.976   23.9\n",
       "504  6.794   22.0\n",
       "505  6.030   11.9\n",
       "\n",
       "[506 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_df[[\"RM\", \"Price\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Visualisasi Data\n",
    "\n",
    "`Visualisasi Data` sering kali dipakai untuk mempresentasikan data yang terstruktur ataupun tidak dengan grafik atau bagan untuk menampilkan info yang tersembunyi didalam data.\n",
    "\n",
    "Referensi : https://www.finereport.com/en/data-visualization/visualisasi-data.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Sebelum melakukan visualisasi data terlebih dahulu kita melakukan import module `import matplotlib.pyplot as plt` dengan beberapa keterangan dari data sebagai berikut :\n",
    "\n",
    "- `plt.scatter(boston_dataset.data[:,5],boston_dataset.target)` sebagai menampilkan data plot scatter dengan parameter `(boston_dataset.data[:,5],boston_dataset.target)`\n",
    "- `plt.ylabel('Harga (Price) dalam $1000')` sebagai label y dengan keterangan Harga (Price) dalam $10000\n",
    "- `plt.xlabel('Jumlah Kamar Rumah')` sebagai jumlah kamar rumah (RM).\n",
    "- `plt.grid(True)` sebagai tampilan `grid`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(boston_dataset.data[:,5],boston_dataset.target)\n",
    "plt.ylabel('Harga (Price) dalam $1000')\n",
    "plt.xlabel('Jumlah Kamar Rumah')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Hasil script diatas dapat disimpulkan bahwa harga rumah akan terus naik yang diikuti dengan meningkatnya jumlah kamar `(RM)` yang ada disetiap rumah."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: [6.575 6.421 7.185 6.998 7.147 6.43  6.012 6.172 5.631 6.004 6.377 6.009\n",
      " 5.889 5.949 6.096 5.834 5.935 5.99  5.456 5.727 5.57  5.965 6.142 5.813\n",
      " 5.924 5.599 5.813 6.047 6.495 6.674 5.713 6.072 5.95  5.701 6.096 5.933\n",
      " 5.841 5.85  5.966 6.595 7.024 6.77  6.169 6.211 6.069 5.682 5.786 6.03\n",
      " 5.399 5.602 5.963 6.115 6.511 5.998 5.888 7.249 6.383 6.816 6.145 5.927\n",
      " 5.741 5.966 6.456 6.762 7.104 6.29  5.787 5.878 5.594 5.885 6.417 5.961\n",
      " 6.065 6.245 6.273 6.286 6.279 6.14  6.232 5.874 6.727 6.619 6.302 6.167\n",
      " 6.389 6.63  6.015 6.121 7.007 7.079 6.417 6.405 6.442 6.211 6.249 6.625\n",
      " 6.163 8.069 7.82  7.416 6.727 6.781 6.405 6.137 6.167 5.851 5.836 6.127\n",
      " 6.474 6.229 6.195 6.715 5.913 6.092 6.254 5.928 6.176 6.021 5.872 5.731\n",
      " 5.87  6.004 5.961 5.856 5.879 5.986 5.613 5.693 6.431 5.637 6.458 6.326\n",
      " 6.372 5.822 5.757 6.335 5.942 6.454 5.857 6.151 6.174 5.019 5.403 5.468\n",
      " 4.903 6.13  5.628 4.926 5.186 5.597 6.122 5.404 5.012 5.709 6.129 6.152\n",
      " 5.272 6.943 6.066 6.51  6.25  7.489 7.802 8.375 5.854 6.101 7.929 5.877\n",
      " 6.319 6.402 5.875 5.88  5.572 6.416 5.859 6.546 6.02  6.315 6.86  6.98\n",
      " 7.765 6.144 7.155 6.563 5.604 6.153 7.831 6.782 6.556 7.185 6.951 6.739\n",
      " 7.178 6.8   6.604 7.875 7.287 7.107 7.274 6.975 7.135 6.162 7.61  7.853\n",
      " 8.034 5.891 6.326 5.783 6.064 5.344 5.96  5.404 5.807 6.375 5.412 6.182\n",
      " 5.888 6.642 5.951 6.373 6.951 6.164 6.879 6.618 8.266 8.725 8.04  7.163\n",
      " 7.686 6.552 5.981 7.412 8.337 8.247 6.726 6.086 6.631 7.358 6.481 6.606\n",
      " 6.897 6.095 6.358 6.393 5.593 5.605 6.108 6.226 6.433 6.718 6.487 6.438\n",
      " 6.957 8.259 6.108 5.876 7.454 8.704 7.333 6.842 7.203 7.52  8.398 7.327\n",
      " 7.206 5.56  7.014 8.297 7.47  5.92  5.856 6.24  6.538 7.691 6.758 6.854\n",
      " 7.267 6.826 6.482 6.812 7.82  6.968 7.645 7.923 7.088 6.453 6.23  6.209\n",
      " 6.315 6.565 6.861 7.148 6.63  6.127 6.009 6.678 6.549 5.79  6.345 7.041\n",
      " 6.871 6.59  6.495 6.982 7.236 6.616 7.42  6.849 6.635 5.972 4.973 6.122\n",
      " 6.023 6.266 6.567 5.705 5.914 5.782 6.382 6.113 6.426 6.376 6.041 5.708\n",
      " 6.415 6.431 6.312 6.083 5.868 6.333 6.144 5.706 6.031 6.316 6.31  6.037\n",
      " 5.869 5.895 6.059 5.985 5.968 7.241 6.54  6.696 6.874 6.014 5.898 6.516\n",
      " 6.635 6.939 6.49  6.579 5.884 6.728 5.663 5.936 6.212 6.395 6.127 6.112\n",
      " 6.398 6.251 5.362 5.803 8.78  3.561 4.963 3.863 4.97  6.683 7.016 6.216\n",
      " 5.875 4.906 4.138 7.313 6.649 6.794 6.38  6.223 6.968 6.545 5.536 5.52\n",
      " 4.368 5.277 4.652 5.    4.88  5.39  5.713 6.051 5.036 6.193 5.887 6.471\n",
      " 6.405 5.747 5.453 5.852 5.987 6.343 6.404 5.349 5.531 5.683 4.138 5.608\n",
      " 5.617 6.852 5.757 6.657 4.628 5.155 4.519 6.434 6.782 5.304 5.957 6.824\n",
      " 6.411 6.006 5.648 6.103 5.565 5.896 5.837 6.202 6.193 6.38  6.348 6.833\n",
      " 6.425 6.436 6.208 6.629 6.461 6.152 5.935 5.627 5.818 6.406 6.219 6.485\n",
      " 5.854 6.459 6.341 6.251 6.185 6.417 6.749 6.655 6.297 7.393 6.728 6.525\n",
      " 5.976 5.936 6.301 6.081 6.701 6.376 6.317 6.513 6.209 5.759 5.952 6.003\n",
      " 5.926 5.713 6.167 6.229 6.437 6.98  5.427 6.162 6.484 5.304 6.185 6.229\n",
      " 6.242 6.75  7.061 5.762 5.871 6.312 6.114 5.905 5.454 5.414 5.093 5.983\n",
      " 5.983 5.707 5.926 5.67  5.39  5.794 6.019 5.569 6.027 6.593 6.12  6.976\n",
      " 6.794 6.03 ]\n",
      "y: [24.  21.6 34.7 33.4 36.2 28.7 22.9 27.1 16.5 18.9 15.  18.9 21.7 20.4\n",
      " 18.2 19.9 23.1 17.5 20.2 18.2 13.6 19.6 15.2 14.5 15.6 13.9 16.6 14.8\n",
      " 18.4 21.  12.7 14.5 13.2 13.1 13.5 18.9 20.  21.  24.7 30.8 34.9 26.6\n",
      " 25.3 24.7 21.2 19.3 20.  16.6 14.4 19.4 19.7 20.5 25.  23.4 18.9 35.4\n",
      " 24.7 31.6 23.3 19.6 18.7 16.  22.2 25.  33.  23.5 19.4 22.  17.4 20.9\n",
      " 24.2 21.7 22.8 23.4 24.1 21.4 20.  20.8 21.2 20.3 28.  23.9 24.8 22.9\n",
      " 23.9 26.6 22.5 22.2 23.6 28.7 22.6 22.  22.9 25.  20.6 28.4 21.4 38.7\n",
      " 43.8 33.2 27.5 26.5 18.6 19.3 20.1 19.5 19.5 20.4 19.8 19.4 21.7 22.8\n",
      " 18.8 18.7 18.5 18.3 21.2 19.2 20.4 19.3 22.  20.3 20.5 17.3 18.8 21.4\n",
      " 15.7 16.2 18.  14.3 19.2 19.6 23.  18.4 15.6 18.1 17.4 17.1 13.3 17.8\n",
      " 14.  14.4 13.4 15.6 11.8 13.8 15.6 14.6 17.8 15.4 21.5 19.6 15.3 19.4\n",
      " 17.  15.6 13.1 41.3 24.3 23.3 27.  50.  50.  50.  22.7 25.  50.  23.8\n",
      " 23.8 22.3 17.4 19.1 23.1 23.6 22.6 29.4 23.2 24.6 29.9 37.2 39.8 36.2\n",
      " 37.9 32.5 26.4 29.6 50.  32.  29.8 34.9 37.  30.5 36.4 31.1 29.1 50.\n",
      " 33.3 30.3 34.6 34.9 32.9 24.1 42.3 48.5 50.  22.6 24.4 22.5 24.4 20.\n",
      " 21.7 19.3 22.4 28.1 23.7 25.  23.3 28.7 21.5 23.  26.7 21.7 27.5 30.1\n",
      " 44.8 50.  37.6 31.6 46.7 31.5 24.3 31.7 41.7 48.3 29.  24.  25.1 31.5\n",
      " 23.7 23.3 22.  20.1 22.2 23.7 17.6 18.5 24.3 20.5 24.5 26.2 24.4 24.8\n",
      " 29.6 42.8 21.9 20.9 44.  50.  36.  30.1 33.8 43.1 48.8 31.  36.5 22.8\n",
      " 30.7 50.  43.5 20.7 21.1 25.2 24.4 35.2 32.4 32.  33.2 33.1 29.1 35.1\n",
      " 45.4 35.4 46.  50.  32.2 22.  20.1 23.2 22.3 24.8 28.5 37.3 27.9 23.9\n",
      " 21.7 28.6 27.1 20.3 22.5 29.  24.8 22.  26.4 33.1 36.1 28.4 33.4 28.2\n",
      " 22.8 20.3 16.1 22.1 19.4 21.6 23.8 16.2 17.8 19.8 23.1 21.  23.8 23.1\n",
      " 20.4 18.5 25.  24.6 23.  22.2 19.3 22.6 19.8 17.1 19.4 22.2 20.7 21.1\n",
      " 19.5 18.5 20.6 19.  18.7 32.7 16.5 23.9 31.2 17.5 17.2 23.1 24.5 26.6\n",
      " 22.9 24.1 18.6 30.1 18.2 20.6 17.8 21.7 22.7 22.6 25.  19.9 20.8 16.8\n",
      " 21.9 27.5 21.9 23.1 50.  50.  50.  50.  50.  13.8 13.8 15.  13.9 13.3\n",
      " 13.1 10.2 10.4 10.9 11.3 12.3  8.8  7.2 10.5  7.4 10.2 11.5 15.1 23.2\n",
      "  9.7 13.8 12.7 13.1 12.5  8.5  5.   6.3  5.6  7.2 12.1  8.3  8.5  5.\n",
      " 11.9 27.9 17.2 27.5 15.  17.2 17.9 16.3  7.   7.2  7.5 10.4  8.8  8.4\n",
      " 16.7 14.2 20.8 13.4 11.7  8.3 10.2 10.9 11.   9.5 14.5 14.1 16.1 14.3\n",
      " 11.7 13.4  9.6  8.7  8.4 12.8 10.5 17.1 18.4 15.4 10.8 11.8 14.9 12.6\n",
      " 14.1 13.  13.4 15.2 16.1 17.8 14.9 14.1 12.7 13.5 14.9 20.  16.4 17.7\n",
      " 19.5 20.2 21.4 19.9 19.  19.1 19.1 20.1 19.9 19.6 23.2 29.8 13.8 13.3\n",
      " 16.7 12.  14.6 21.4 23.  23.7 25.  21.8 20.6 21.2 19.1 20.6 15.2  7.\n",
      "  8.1 13.6 20.1 21.8 24.5 23.1 19.7 18.3 21.2 17.5 16.8 22.4 20.6 23.9\n",
      " 22.  11.9]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array(boston_df['RM'])\n",
    "y = np.array(boston_df['Price'])\n",
    "\n",
    "print(f'X: {X}')\n",
    "print(f'y: {y}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- X yang bernilai `Features` hanya menampung nilai dengan satu dimensi\n",
    "\n",
    "Kita akan melakukan `reshape` dengan parameter `(-1, 1)` seperti script dibawah ini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X.reshape(-1, 1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.575],\n",
       "       [6.421],\n",
       "       [7.185],\n",
       "       [6.998],\n",
       "       [7.147],\n",
       "       [6.43 ],\n",
       "       [6.012],\n",
       "       [6.172],\n",
       "       [5.631],\n",
       "       [6.004],\n",
       "       [6.377],\n",
       "       [6.009],\n",
       "       [5.889],\n",
       "       [5.949],\n",
       "       [6.096],\n",
       "       [5.834],\n",
       "       [5.935],\n",
       "       [5.99 ],\n",
       "       [5.456],\n",
       "       [5.727],\n",
       "       [5.57 ],\n",
       "       [5.965],\n",
       "       [6.142],\n",
       "       [5.813],\n",
       "       [5.924],\n",
       "       [5.599],\n",
       "       [5.813],\n",
       "       [6.047],\n",
       "       [6.495],\n",
       "       [6.674],\n",
       "       [5.713],\n",
       "       [6.072],\n",
       "       [5.95 ],\n",
       "       [5.701],\n",
       "       [6.096],\n",
       "       [5.933],\n",
       "       [5.841],\n",
       "       [5.85 ],\n",
       "       [5.966],\n",
       "       [6.595],\n",
       "       [7.024],\n",
       "       [6.77 ],\n",
       "       [6.169],\n",
       "       [6.211],\n",
       "       [6.069],\n",
       "       [5.682],\n",
       "       [5.786],\n",
       "       [6.03 ],\n",
       "       [5.399],\n",
       "       [5.602],\n",
       "       [5.963],\n",
       "       [6.115],\n",
       "       [6.511],\n",
       "       [5.998],\n",
       "       [5.888],\n",
       "       [7.249],\n",
       "       [6.383],\n",
       "       [6.816],\n",
       "       [6.145],\n",
       "       [5.927],\n",
       "       [5.741],\n",
       "       [5.966],\n",
       "       [6.456],\n",
       "       [6.762],\n",
       "       [7.104],\n",
       "       [6.29 ],\n",
       "       [5.787],\n",
       "       [5.878],\n",
       "       [5.594],\n",
       "       [5.885],\n",
       "       [6.417],\n",
       "       [5.961],\n",
       "       [6.065],\n",
       "       [6.245],\n",
       "       [6.273],\n",
       "       [6.286],\n",
       "       [6.279],\n",
       "       [6.14 ],\n",
       "       [6.232],\n",
       "       [5.874],\n",
       "       [6.727],\n",
       "       [6.619],\n",
       "       [6.302],\n",
       "       [6.167],\n",
       "       [6.389],\n",
       "       [6.63 ],\n",
       "       [6.015],\n",
       "       [6.121],\n",
       "       [7.007],\n",
       "       [7.079],\n",
       "       [6.417],\n",
       "       [6.405],\n",
       "       [6.442],\n",
       "       [6.211],\n",
       "       [6.249],\n",
       "       [6.625],\n",
       "       [6.163],\n",
       "       [8.069],\n",
       "       [7.82 ],\n",
       "       [7.416],\n",
       "       [6.727],\n",
       "       [6.781],\n",
       "       [6.405],\n",
       "       [6.137],\n",
       "       [6.167],\n",
       "       [5.851],\n",
       "       [5.836],\n",
       "       [6.127],\n",
       "       [6.474],\n",
       "       [6.229],\n",
       "       [6.195],\n",
       "       [6.715],\n",
       "       [5.913],\n",
       "       [6.092],\n",
       "       [6.254],\n",
       "       [5.928],\n",
       "       [6.176],\n",
       "       [6.021],\n",
       "       [5.872],\n",
       "       [5.731],\n",
       "       [5.87 ],\n",
       "       [6.004],\n",
       "       [5.961],\n",
       "       [5.856],\n",
       "       [5.879],\n",
       "       [5.986],\n",
       "       [5.613],\n",
       "       [5.693],\n",
       "       [6.431],\n",
       "       [5.637],\n",
       "       [6.458],\n",
       "       [6.326],\n",
       "       [6.372],\n",
       "       [5.822],\n",
       "       [5.757],\n",
       "       [6.335],\n",
       "       [5.942],\n",
       "       [6.454],\n",
       "       [5.857],\n",
       "       [6.151],\n",
       "       [6.174],\n",
       "       [5.019],\n",
       "       [5.403],\n",
       "       [5.468],\n",
       "       [4.903],\n",
       "       [6.13 ],\n",
       "       [5.628],\n",
       "       [4.926],\n",
       "       [5.186],\n",
       "       [5.597],\n",
       "       [6.122],\n",
       "       [5.404],\n",
       "       [5.012],\n",
       "       [5.709],\n",
       "       [6.129],\n",
       "       [6.152],\n",
       "       [5.272],\n",
       "       [6.943],\n",
       "       [6.066],\n",
       "       [6.51 ],\n",
       "       [6.25 ],\n",
       "       [7.489],\n",
       "       [7.802],\n",
       "       [8.375],\n",
       "       [5.854],\n",
       "       [6.101],\n",
       "       [7.929],\n",
       "       [5.877],\n",
       "       [6.319],\n",
       "       [6.402],\n",
       "       [5.875],\n",
       "       [5.88 ],\n",
       "       [5.572],\n",
       "       [6.416],\n",
       "       [5.859],\n",
       "       [6.546],\n",
       "       [6.02 ],\n",
       "       [6.315],\n",
       "       [6.86 ],\n",
       "       [6.98 ],\n",
       "       [7.765],\n",
       "       [6.144],\n",
       "       [7.155],\n",
       "       [6.563],\n",
       "       [5.604],\n",
       "       [6.153],\n",
       "       [7.831],\n",
       "       [6.782],\n",
       "       [6.556],\n",
       "       [7.185],\n",
       "       [6.951],\n",
       "       [6.739],\n",
       "       [7.178],\n",
       "       [6.8  ],\n",
       "       [6.604],\n",
       "       [7.875],\n",
       "       [7.287],\n",
       "       [7.107],\n",
       "       [7.274],\n",
       "       [6.975],\n",
       "       [7.135],\n",
       "       [6.162],\n",
       "       [7.61 ],\n",
       "       [7.853],\n",
       "       [8.034],\n",
       "       [5.891],\n",
       "       [6.326],\n",
       "       [5.783],\n",
       "       [6.064],\n",
       "       [5.344],\n",
       "       [5.96 ],\n",
       "       [5.404],\n",
       "       [5.807],\n",
       "       [6.375],\n",
       "       [5.412],\n",
       "       [6.182],\n",
       "       [5.888],\n",
       "       [6.642],\n",
       "       [5.951],\n",
       "       [6.373],\n",
       "       [6.951],\n",
       "       [6.164],\n",
       "       [6.879],\n",
       "       [6.618],\n",
       "       [8.266],\n",
       "       [8.725],\n",
       "       [8.04 ],\n",
       "       [7.163],\n",
       "       [7.686],\n",
       "       [6.552],\n",
       "       [5.981],\n",
       "       [7.412],\n",
       "       [8.337],\n",
       "       [8.247],\n",
       "       [6.726],\n",
       "       [6.086],\n",
       "       [6.631],\n",
       "       [7.358],\n",
       "       [6.481],\n",
       "       [6.606],\n",
       "       [6.897],\n",
       "       [6.095],\n",
       "       [6.358],\n",
       "       [6.393],\n",
       "       [5.593],\n",
       "       [5.605],\n",
       "       [6.108],\n",
       "       [6.226],\n",
       "       [6.433],\n",
       "       [6.718],\n",
       "       [6.487],\n",
       "       [6.438],\n",
       "       [6.957],\n",
       "       [8.259],\n",
       "       [6.108],\n",
       "       [5.876],\n",
       "       [7.454],\n",
       "       [8.704],\n",
       "       [7.333],\n",
       "       [6.842],\n",
       "       [7.203],\n",
       "       [7.52 ],\n",
       "       [8.398],\n",
       "       [7.327],\n",
       "       [7.206],\n",
       "       [5.56 ],\n",
       "       [7.014],\n",
       "       [8.297],\n",
       "       [7.47 ],\n",
       "       [5.92 ],\n",
       "       [5.856],\n",
       "       [6.24 ],\n",
       "       [6.538],\n",
       "       [7.691],\n",
       "       [6.758],\n",
       "       [6.854],\n",
       "       [7.267],\n",
       "       [6.826],\n",
       "       [6.482],\n",
       "       [6.812],\n",
       "       [7.82 ],\n",
       "       [6.968],\n",
       "       [7.645],\n",
       "       [7.923],\n",
       "       [7.088],\n",
       "       [6.453],\n",
       "       [6.23 ],\n",
       "       [6.209],\n",
       "       [6.315],\n",
       "       [6.565],\n",
       "       [6.861],\n",
       "       [7.148],\n",
       "       [6.63 ],\n",
       "       [6.127],\n",
       "       [6.009],\n",
       "       [6.678],\n",
       "       [6.549],\n",
       "       [5.79 ],\n",
       "       [6.345],\n",
       "       [7.041],\n",
       "       [6.871],\n",
       "       [6.59 ],\n",
       "       [6.495],\n",
       "       [6.982],\n",
       "       [7.236],\n",
       "       [6.616],\n",
       "       [7.42 ],\n",
       "       [6.849],\n",
       "       [6.635],\n",
       "       [5.972],\n",
       "       [4.973],\n",
       "       [6.122],\n",
       "       [6.023],\n",
       "       [6.266],\n",
       "       [6.567],\n",
       "       [5.705],\n",
       "       [5.914],\n",
       "       [5.782],\n",
       "       [6.382],\n",
       "       [6.113],\n",
       "       [6.426],\n",
       "       [6.376],\n",
       "       [6.041],\n",
       "       [5.708],\n",
       "       [6.415],\n",
       "       [6.431],\n",
       "       [6.312],\n",
       "       [6.083],\n",
       "       [5.868],\n",
       "       [6.333],\n",
       "       [6.144],\n",
       "       [5.706],\n",
       "       [6.031],\n",
       "       [6.316],\n",
       "       [6.31 ],\n",
       "       [6.037],\n",
       "       [5.869],\n",
       "       [5.895],\n",
       "       [6.059],\n",
       "       [5.985],\n",
       "       [5.968],\n",
       "       [7.241],\n",
       "       [6.54 ],\n",
       "       [6.696],\n",
       "       [6.874],\n",
       "       [6.014],\n",
       "       [5.898],\n",
       "       [6.516],\n",
       "       [6.635],\n",
       "       [6.939],\n",
       "       [6.49 ],\n",
       "       [6.579],\n",
       "       [5.884],\n",
       "       [6.728],\n",
       "       [5.663],\n",
       "       [5.936],\n",
       "       [6.212],\n",
       "       [6.395],\n",
       "       [6.127],\n",
       "       [6.112],\n",
       "       [6.398],\n",
       "       [6.251],\n",
       "       [5.362],\n",
       "       [5.803],\n",
       "       [8.78 ],\n",
       "       [3.561],\n",
       "       [4.963],\n",
       "       [3.863],\n",
       "       [4.97 ],\n",
       "       [6.683],\n",
       "       [7.016],\n",
       "       [6.216],\n",
       "       [5.875],\n",
       "       [4.906],\n",
       "       [4.138],\n",
       "       [7.313],\n",
       "       [6.649],\n",
       "       [6.794],\n",
       "       [6.38 ],\n",
       "       [6.223],\n",
       "       [6.968],\n",
       "       [6.545],\n",
       "       [5.536],\n",
       "       [5.52 ],\n",
       "       [4.368],\n",
       "       [5.277],\n",
       "       [4.652],\n",
       "       [5.   ],\n",
       "       [4.88 ],\n",
       "       [5.39 ],\n",
       "       [5.713],\n",
       "       [6.051],\n",
       "       [5.036],\n",
       "       [6.193],\n",
       "       [5.887],\n",
       "       [6.471],\n",
       "       [6.405],\n",
       "       [5.747],\n",
       "       [5.453],\n",
       "       [5.852],\n",
       "       [5.987],\n",
       "       [6.343],\n",
       "       [6.404],\n",
       "       [5.349],\n",
       "       [5.531],\n",
       "       [5.683],\n",
       "       [4.138],\n",
       "       [5.608],\n",
       "       [5.617],\n",
       "       [6.852],\n",
       "       [5.757],\n",
       "       [6.657],\n",
       "       [4.628],\n",
       "       [5.155],\n",
       "       [4.519],\n",
       "       [6.434],\n",
       "       [6.782],\n",
       "       [5.304],\n",
       "       [5.957],\n",
       "       [6.824],\n",
       "       [6.411],\n",
       "       [6.006],\n",
       "       [5.648],\n",
       "       [6.103],\n",
       "       [5.565],\n",
       "       [5.896],\n",
       "       [5.837],\n",
       "       [6.202],\n",
       "       [6.193],\n",
       "       [6.38 ],\n",
       "       [6.348],\n",
       "       [6.833],\n",
       "       [6.425],\n",
       "       [6.436],\n",
       "       [6.208],\n",
       "       [6.629],\n",
       "       [6.461],\n",
       "       [6.152],\n",
       "       [5.935],\n",
       "       [5.627],\n",
       "       [5.818],\n",
       "       [6.406],\n",
       "       [6.219],\n",
       "       [6.485],\n",
       "       [5.854],\n",
       "       [6.459],\n",
       "       [6.341],\n",
       "       [6.251],\n",
       "       [6.185],\n",
       "       [6.417],\n",
       "       [6.749],\n",
       "       [6.655],\n",
       "       [6.297],\n",
       "       [7.393],\n",
       "       [6.728],\n",
       "       [6.525],\n",
       "       [5.976],\n",
       "       [5.936],\n",
       "       [6.301],\n",
       "       [6.081],\n",
       "       [6.701],\n",
       "       [6.376],\n",
       "       [6.317],\n",
       "       [6.513],\n",
       "       [6.209],\n",
       "       [5.759],\n",
       "       [5.952],\n",
       "       [6.003],\n",
       "       [5.926],\n",
       "       [5.713],\n",
       "       [6.167],\n",
       "       [6.229],\n",
       "       [6.437],\n",
       "       [6.98 ],\n",
       "       [5.427],\n",
       "       [6.162],\n",
       "       [6.484],\n",
       "       [5.304],\n",
       "       [6.185],\n",
       "       [6.229],\n",
       "       [6.242],\n",
       "       [6.75 ],\n",
       "       [7.061],\n",
       "       [5.762],\n",
       "       [5.871],\n",
       "       [6.312],\n",
       "       [6.114],\n",
       "       [5.905],\n",
       "       [5.454],\n",
       "       [5.414],\n",
       "       [5.093],\n",
       "       [5.983],\n",
       "       [5.983],\n",
       "       [5.707],\n",
       "       [5.926],\n",
       "       [5.67 ],\n",
       "       [5.39 ],\n",
       "       [5.794],\n",
       "       [6.019],\n",
       "       [5.569],\n",
       "       [6.027],\n",
       "       [6.593],\n",
       "       [6.12 ],\n",
       "       [6.976],\n",
       "       [6.794],\n",
       "       [6.03 ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- `Variabel X` akan menampung suatu Array 2 dimensi seperti script diatas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Training Simple Linear Regression Model\n",
    "\n",
    "Sebelum melakukan **Training Simple Linear Regression Model** pertama-tama kita perlu untuk melakukan import dengan `from sklearn.linear_model import LinearRegression`, kemudian membuat objek model `LinearRegression()` yang ditampung di dalam variabel `model`. Model objek ini akan di Training dengan method fit `model.fit(X, y)` dengan 2 parameter yaitu `X` dan `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Visualisasi Simple Linear Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Sebelum melakukan Simple Linear Regression Model terlebih dahulu kita memastikan bahwa data yang disediakan harus berbentuk `2 dimensi` seperti langkah dibawah ini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_vis = np.array(boston_df[['RM', 'Price']]).reshape(-1, 1)\n",
    "y_vis = model.predict(X_vis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Pada dasarnya `Visualisasi Simple Linear Regression Model` ini adalah garis lurus, maka dibutuhkan 2 buah parameter yang ditampung pada variabel `X_vis` yaitu :\n",
    "\n",
    "- `np.array([0, 25])` atau Features dengan nilai 0 dan 25 \n",
    "- `reshape(-1, 1)` dengan nilai -1 dan 1\n",
    "\n",
    "Kemudian untuk selanjutnya akan melakukan prediksi dengan `model.predict(X_vis)` yang bernilai `X_vis` yang ditampung pada variabel `y_vis` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = boston_df.RM\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(boston_df['RM']).reshape(-1, 1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Mencari nilai slope\n",
    "\n",
    "Nilai slope pada Linear Regression bisa diperoleh dengan memanfaatkan formula berikut:\n",
    "\n",
    "$\\beta = \\frac{cov(x, y)}{var(x)}$\n",
    "\n",
    "- Nilai x akan merepresentasikan nilai `Features`\n",
    "- Nilai y akan merepresentasikan nilai `Target`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept: -34.670620776438554\n",
      "slope: [9.10210898]\n"
     ]
    }
   ],
   "source": [
    "X_vis = model.intercept_\n",
    "y_vis = model.coef_\n",
    "\n",
    "print(f'intercept: {X_vis}')\n",
    "print(f'slope: {y_vis}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Intercept akan merepresentasikan intercept yang bersentuhan dengan sumbu y (nilai pada sumbu y ketika nilai `x=0`)\n",
    "Untuk mendapatkan `Intercept` kita dapat melakukannya dengan script `f'intercept: {model.intercept_}'`\n",
    "\n",
    "- Slope adalah tingkat kemiringan garis yang terbentuk dimana garis tersebut adalah horizontal\n",
    "Untuk mendapatkan `Slope` kita dapat melakukannya dengan script `f'slope: {model.coef_}'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formula Linear Regression: $y = \\alpha + \\beta x$ \n",
    "- $y$: akan merepresentasikan response variable\n",
    "- $x$: akan merepresentasikan explanatory variable\n",
    "- $\\alpha$: akan merepresentasikan intercept yang bersentuhan dengan sumbu y (nilai pada sumbu y ketika nilai `x=0`)\n",
    "- $\\beta$: akan merepresentasikan slope (akan menghasilkan garis `Horizontal`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Pada dasarnya `Visualisasi Simple Linear Regression Model` ini adalah garis lurus, maka dibutuhkan 2 buah parameter dengan keterangan sebagai berikut :\n",
    "\n",
    "- `x = boston_df.RM` sebagai Features `boston_RM`  yang ditampung ke dalam variabel `x`\n",
    "- `y_vis*x + X_vis` sebagai nilai dari formula `y_vis` intercept dan `X_vis` slope.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(boston_dataset.data[:,5],boston_dataset.target)\n",
    "x = boston_df.RM\n",
    "\n",
    "plt.title('Perbandingan Jumlah Kamar Rumah (RM) dan Harga (Price)')\n",
    "plt.plot(x, y_vis*x + X_vis, 'r')\n",
    "plt.ylabel('Harga (Price) dalam $1000')\n",
    "plt.xlabel('Jumlah Kamar Rumah')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variance\n",
    "\n",
    "`varians` (dari bahasa Inggris: `variance`) atau ragam suatu peubah acak (atau distribusi probabilitas) adalah ukuran seberapa jauh sebuah kumpulan bilangan tersebar. Varians nol mengindikasikan bahwa semua nilai sama. Varians selalu bernilai non-negatif: varians yang rendah mengindikasikan bahwa titik data condong sangat dekat dengan nilai rerata (nilai ekspektasi) dan antara satu sama lainnya, sementara varians yang tinggi mengindikasikan bahwa titik data sangat tersebar disekitar rerata dan dari satu sama lainnya.\n",
    "\n",
    "Referensi : https://id.wikipedia.org/wiki/Varians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:\n",
      "[[6.575]\n",
      " [6.421]\n",
      " [7.185]\n",
      " [6.998]\n",
      " [7.147]\n",
      " [6.43 ]\n",
      " [6.012]\n",
      " [6.172]\n",
      " [5.631]\n",
      " [6.004]\n",
      " [6.377]\n",
      " [6.009]\n",
      " [5.889]\n",
      " [5.949]\n",
      " [6.096]\n",
      " [5.834]\n",
      " [5.935]\n",
      " [5.99 ]\n",
      " [5.456]\n",
      " [5.727]\n",
      " [5.57 ]\n",
      " [5.965]\n",
      " [6.142]\n",
      " [5.813]\n",
      " [5.924]\n",
      " [5.599]\n",
      " [5.813]\n",
      " [6.047]\n",
      " [6.495]\n",
      " [6.674]\n",
      " [5.713]\n",
      " [6.072]\n",
      " [5.95 ]\n",
      " [5.701]\n",
      " [6.096]\n",
      " [5.933]\n",
      " [5.841]\n",
      " [5.85 ]\n",
      " [5.966]\n",
      " [6.595]\n",
      " [7.024]\n",
      " [6.77 ]\n",
      " [6.169]\n",
      " [6.211]\n",
      " [6.069]\n",
      " [5.682]\n",
      " [5.786]\n",
      " [6.03 ]\n",
      " [5.399]\n",
      " [5.602]\n",
      " [5.963]\n",
      " [6.115]\n",
      " [6.511]\n",
      " [5.998]\n",
      " [5.888]\n",
      " [7.249]\n",
      " [6.383]\n",
      " [6.816]\n",
      " [6.145]\n",
      " [5.927]\n",
      " [5.741]\n",
      " [5.966]\n",
      " [6.456]\n",
      " [6.762]\n",
      " [7.104]\n",
      " [6.29 ]\n",
      " [5.787]\n",
      " [5.878]\n",
      " [5.594]\n",
      " [5.885]\n",
      " [6.417]\n",
      " [5.961]\n",
      " [6.065]\n",
      " [6.245]\n",
      " [6.273]\n",
      " [6.286]\n",
      " [6.279]\n",
      " [6.14 ]\n",
      " [6.232]\n",
      " [5.874]\n",
      " [6.727]\n",
      " [6.619]\n",
      " [6.302]\n",
      " [6.167]\n",
      " [6.389]\n",
      " [6.63 ]\n",
      " [6.015]\n",
      " [6.121]\n",
      " [7.007]\n",
      " [7.079]\n",
      " [6.417]\n",
      " [6.405]\n",
      " [6.442]\n",
      " [6.211]\n",
      " [6.249]\n",
      " [6.625]\n",
      " [6.163]\n",
      " [8.069]\n",
      " [7.82 ]\n",
      " [7.416]\n",
      " [6.727]\n",
      " [6.781]\n",
      " [6.405]\n",
      " [6.137]\n",
      " [6.167]\n",
      " [5.851]\n",
      " [5.836]\n",
      " [6.127]\n",
      " [6.474]\n",
      " [6.229]\n",
      " [6.195]\n",
      " [6.715]\n",
      " [5.913]\n",
      " [6.092]\n",
      " [6.254]\n",
      " [5.928]\n",
      " [6.176]\n",
      " [6.021]\n",
      " [5.872]\n",
      " [5.731]\n",
      " [5.87 ]\n",
      " [6.004]\n",
      " [5.961]\n",
      " [5.856]\n",
      " [5.879]\n",
      " [5.986]\n",
      " [5.613]\n",
      " [5.693]\n",
      " [6.431]\n",
      " [5.637]\n",
      " [6.458]\n",
      " [6.326]\n",
      " [6.372]\n",
      " [5.822]\n",
      " [5.757]\n",
      " [6.335]\n",
      " [5.942]\n",
      " [6.454]\n",
      " [5.857]\n",
      " [6.151]\n",
      " [6.174]\n",
      " [5.019]\n",
      " [5.403]\n",
      " [5.468]\n",
      " [4.903]\n",
      " [6.13 ]\n",
      " [5.628]\n",
      " [4.926]\n",
      " [5.186]\n",
      " [5.597]\n",
      " [6.122]\n",
      " [5.404]\n",
      " [5.012]\n",
      " [5.709]\n",
      " [6.129]\n",
      " [6.152]\n",
      " [5.272]\n",
      " [6.943]\n",
      " [6.066]\n",
      " [6.51 ]\n",
      " [6.25 ]\n",
      " [7.489]\n",
      " [7.802]\n",
      " [8.375]\n",
      " [5.854]\n",
      " [6.101]\n",
      " [7.929]\n",
      " [5.877]\n",
      " [6.319]\n",
      " [6.402]\n",
      " [5.875]\n",
      " [5.88 ]\n",
      " [5.572]\n",
      " [6.416]\n",
      " [5.859]\n",
      " [6.546]\n",
      " [6.02 ]\n",
      " [6.315]\n",
      " [6.86 ]\n",
      " [6.98 ]\n",
      " [7.765]\n",
      " [6.144]\n",
      " [7.155]\n",
      " [6.563]\n",
      " [5.604]\n",
      " [6.153]\n",
      " [7.831]\n",
      " [6.782]\n",
      " [6.556]\n",
      " [7.185]\n",
      " [6.951]\n",
      " [6.739]\n",
      " [7.178]\n",
      " [6.8  ]\n",
      " [6.604]\n",
      " [7.875]\n",
      " [7.287]\n",
      " [7.107]\n",
      " [7.274]\n",
      " [6.975]\n",
      " [7.135]\n",
      " [6.162]\n",
      " [7.61 ]\n",
      " [7.853]\n",
      " [8.034]\n",
      " [5.891]\n",
      " [6.326]\n",
      " [5.783]\n",
      " [6.064]\n",
      " [5.344]\n",
      " [5.96 ]\n",
      " [5.404]\n",
      " [5.807]\n",
      " [6.375]\n",
      " [5.412]\n",
      " [6.182]\n",
      " [5.888]\n",
      " [6.642]\n",
      " [5.951]\n",
      " [6.373]\n",
      " [6.951]\n",
      " [6.164]\n",
      " [6.879]\n",
      " [6.618]\n",
      " [8.266]\n",
      " [8.725]\n",
      " [8.04 ]\n",
      " [7.163]\n",
      " [7.686]\n",
      " [6.552]\n",
      " [5.981]\n",
      " [7.412]\n",
      " [8.337]\n",
      " [8.247]\n",
      " [6.726]\n",
      " [6.086]\n",
      " [6.631]\n",
      " [7.358]\n",
      " [6.481]\n",
      " [6.606]\n",
      " [6.897]\n",
      " [6.095]\n",
      " [6.358]\n",
      " [6.393]\n",
      " [5.593]\n",
      " [5.605]\n",
      " [6.108]\n",
      " [6.226]\n",
      " [6.433]\n",
      " [6.718]\n",
      " [6.487]\n",
      " [6.438]\n",
      " [6.957]\n",
      " [8.259]\n",
      " [6.108]\n",
      " [5.876]\n",
      " [7.454]\n",
      " [8.704]\n",
      " [7.333]\n",
      " [6.842]\n",
      " [7.203]\n",
      " [7.52 ]\n",
      " [8.398]\n",
      " [7.327]\n",
      " [7.206]\n",
      " [5.56 ]\n",
      " [7.014]\n",
      " [8.297]\n",
      " [7.47 ]\n",
      " [5.92 ]\n",
      " [5.856]\n",
      " [6.24 ]\n",
      " [6.538]\n",
      " [7.691]\n",
      " [6.758]\n",
      " [6.854]\n",
      " [7.267]\n",
      " [6.826]\n",
      " [6.482]\n",
      " [6.812]\n",
      " [7.82 ]\n",
      " [6.968]\n",
      " [7.645]\n",
      " [7.923]\n",
      " [7.088]\n",
      " [6.453]\n",
      " [6.23 ]\n",
      " [6.209]\n",
      " [6.315]\n",
      " [6.565]\n",
      " [6.861]\n",
      " [7.148]\n",
      " [6.63 ]\n",
      " [6.127]\n",
      " [6.009]\n",
      " [6.678]\n",
      " [6.549]\n",
      " [5.79 ]\n",
      " [6.345]\n",
      " [7.041]\n",
      " [6.871]\n",
      " [6.59 ]\n",
      " [6.495]\n",
      " [6.982]\n",
      " [7.236]\n",
      " [6.616]\n",
      " [7.42 ]\n",
      " [6.849]\n",
      " [6.635]\n",
      " [5.972]\n",
      " [4.973]\n",
      " [6.122]\n",
      " [6.023]\n",
      " [6.266]\n",
      " [6.567]\n",
      " [5.705]\n",
      " [5.914]\n",
      " [5.782]\n",
      " [6.382]\n",
      " [6.113]\n",
      " [6.426]\n",
      " [6.376]\n",
      " [6.041]\n",
      " [5.708]\n",
      " [6.415]\n",
      " [6.431]\n",
      " [6.312]\n",
      " [6.083]\n",
      " [5.868]\n",
      " [6.333]\n",
      " [6.144]\n",
      " [5.706]\n",
      " [6.031]\n",
      " [6.316]\n",
      " [6.31 ]\n",
      " [6.037]\n",
      " [5.869]\n",
      " [5.895]\n",
      " [6.059]\n",
      " [5.985]\n",
      " [5.968]\n",
      " [7.241]\n",
      " [6.54 ]\n",
      " [6.696]\n",
      " [6.874]\n",
      " [6.014]\n",
      " [5.898]\n",
      " [6.516]\n",
      " [6.635]\n",
      " [6.939]\n",
      " [6.49 ]\n",
      " [6.579]\n",
      " [5.884]\n",
      " [6.728]\n",
      " [5.663]\n",
      " [5.936]\n",
      " [6.212]\n",
      " [6.395]\n",
      " [6.127]\n",
      " [6.112]\n",
      " [6.398]\n",
      " [6.251]\n",
      " [5.362]\n",
      " [5.803]\n",
      " [8.78 ]\n",
      " [3.561]\n",
      " [4.963]\n",
      " [3.863]\n",
      " [4.97 ]\n",
      " [6.683]\n",
      " [7.016]\n",
      " [6.216]\n",
      " [5.875]\n",
      " [4.906]\n",
      " [4.138]\n",
      " [7.313]\n",
      " [6.649]\n",
      " [6.794]\n",
      " [6.38 ]\n",
      " [6.223]\n",
      " [6.968]\n",
      " [6.545]\n",
      " [5.536]\n",
      " [5.52 ]\n",
      " [4.368]\n",
      " [5.277]\n",
      " [4.652]\n",
      " [5.   ]\n",
      " [4.88 ]\n",
      " [5.39 ]\n",
      " [5.713]\n",
      " [6.051]\n",
      " [5.036]\n",
      " [6.193]\n",
      " [5.887]\n",
      " [6.471]\n",
      " [6.405]\n",
      " [5.747]\n",
      " [5.453]\n",
      " [5.852]\n",
      " [5.987]\n",
      " [6.343]\n",
      " [6.404]\n",
      " [5.349]\n",
      " [5.531]\n",
      " [5.683]\n",
      " [4.138]\n",
      " [5.608]\n",
      " [5.617]\n",
      " [6.852]\n",
      " [5.757]\n",
      " [6.657]\n",
      " [4.628]\n",
      " [5.155]\n",
      " [4.519]\n",
      " [6.434]\n",
      " [6.782]\n",
      " [5.304]\n",
      " [5.957]\n",
      " [6.824]\n",
      " [6.411]\n",
      " [6.006]\n",
      " [5.648]\n",
      " [6.103]\n",
      " [5.565]\n",
      " [5.896]\n",
      " [5.837]\n",
      " [6.202]\n",
      " [6.193]\n",
      " [6.38 ]\n",
      " [6.348]\n",
      " [6.833]\n",
      " [6.425]\n",
      " [6.436]\n",
      " [6.208]\n",
      " [6.629]\n",
      " [6.461]\n",
      " [6.152]\n",
      " [5.935]\n",
      " [5.627]\n",
      " [5.818]\n",
      " [6.406]\n",
      " [6.219]\n",
      " [6.485]\n",
      " [5.854]\n",
      " [6.459]\n",
      " [6.341]\n",
      " [6.251]\n",
      " [6.185]\n",
      " [6.417]\n",
      " [6.749]\n",
      " [6.655]\n",
      " [6.297]\n",
      " [7.393]\n",
      " [6.728]\n",
      " [6.525]\n",
      " [5.976]\n",
      " [5.936]\n",
      " [6.301]\n",
      " [6.081]\n",
      " [6.701]\n",
      " [6.376]\n",
      " [6.317]\n",
      " [6.513]\n",
      " [6.209]\n",
      " [5.759]\n",
      " [5.952]\n",
      " [6.003]\n",
      " [5.926]\n",
      " [5.713]\n",
      " [6.167]\n",
      " [6.229]\n",
      " [6.437]\n",
      " [6.98 ]\n",
      " [5.427]\n",
      " [6.162]\n",
      " [6.484]\n",
      " [5.304]\n",
      " [6.185]\n",
      " [6.229]\n",
      " [6.242]\n",
      " [6.75 ]\n",
      " [7.061]\n",
      " [5.762]\n",
      " [5.871]\n",
      " [6.312]\n",
      " [6.114]\n",
      " [5.905]\n",
      " [5.454]\n",
      " [5.414]\n",
      " [5.093]\n",
      " [5.983]\n",
      " [5.983]\n",
      " [5.707]\n",
      " [5.926]\n",
      " [5.67 ]\n",
      " [5.39 ]\n",
      " [5.794]\n",
      " [6.019]\n",
      " [5.569]\n",
      " [6.027]\n",
      " [6.593]\n",
      " [6.12 ]\n",
      " [6.976]\n",
      " [6.794]\n",
      " [6.03 ]]\n",
      "\n",
      "X flatten: [6.575 6.421 7.185 6.998 7.147 6.43  6.012 6.172 5.631 6.004 6.377 6.009\n",
      " 5.889 5.949 6.096 5.834 5.935 5.99  5.456 5.727 5.57  5.965 6.142 5.813\n",
      " 5.924 5.599 5.813 6.047 6.495 6.674 5.713 6.072 5.95  5.701 6.096 5.933\n",
      " 5.841 5.85  5.966 6.595 7.024 6.77  6.169 6.211 6.069 5.682 5.786 6.03\n",
      " 5.399 5.602 5.963 6.115 6.511 5.998 5.888 7.249 6.383 6.816 6.145 5.927\n",
      " 5.741 5.966 6.456 6.762 7.104 6.29  5.787 5.878 5.594 5.885 6.417 5.961\n",
      " 6.065 6.245 6.273 6.286 6.279 6.14  6.232 5.874 6.727 6.619 6.302 6.167\n",
      " 6.389 6.63  6.015 6.121 7.007 7.079 6.417 6.405 6.442 6.211 6.249 6.625\n",
      " 6.163 8.069 7.82  7.416 6.727 6.781 6.405 6.137 6.167 5.851 5.836 6.127\n",
      " 6.474 6.229 6.195 6.715 5.913 6.092 6.254 5.928 6.176 6.021 5.872 5.731\n",
      " 5.87  6.004 5.961 5.856 5.879 5.986 5.613 5.693 6.431 5.637 6.458 6.326\n",
      " 6.372 5.822 5.757 6.335 5.942 6.454 5.857 6.151 6.174 5.019 5.403 5.468\n",
      " 4.903 6.13  5.628 4.926 5.186 5.597 6.122 5.404 5.012 5.709 6.129 6.152\n",
      " 5.272 6.943 6.066 6.51  6.25  7.489 7.802 8.375 5.854 6.101 7.929 5.877\n",
      " 6.319 6.402 5.875 5.88  5.572 6.416 5.859 6.546 6.02  6.315 6.86  6.98\n",
      " 7.765 6.144 7.155 6.563 5.604 6.153 7.831 6.782 6.556 7.185 6.951 6.739\n",
      " 7.178 6.8   6.604 7.875 7.287 7.107 7.274 6.975 7.135 6.162 7.61  7.853\n",
      " 8.034 5.891 6.326 5.783 6.064 5.344 5.96  5.404 5.807 6.375 5.412 6.182\n",
      " 5.888 6.642 5.951 6.373 6.951 6.164 6.879 6.618 8.266 8.725 8.04  7.163\n",
      " 7.686 6.552 5.981 7.412 8.337 8.247 6.726 6.086 6.631 7.358 6.481 6.606\n",
      " 6.897 6.095 6.358 6.393 5.593 5.605 6.108 6.226 6.433 6.718 6.487 6.438\n",
      " 6.957 8.259 6.108 5.876 7.454 8.704 7.333 6.842 7.203 7.52  8.398 7.327\n",
      " 7.206 5.56  7.014 8.297 7.47  5.92  5.856 6.24  6.538 7.691 6.758 6.854\n",
      " 7.267 6.826 6.482 6.812 7.82  6.968 7.645 7.923 7.088 6.453 6.23  6.209\n",
      " 6.315 6.565 6.861 7.148 6.63  6.127 6.009 6.678 6.549 5.79  6.345 7.041\n",
      " 6.871 6.59  6.495 6.982 7.236 6.616 7.42  6.849 6.635 5.972 4.973 6.122\n",
      " 6.023 6.266 6.567 5.705 5.914 5.782 6.382 6.113 6.426 6.376 6.041 5.708\n",
      " 6.415 6.431 6.312 6.083 5.868 6.333 6.144 5.706 6.031 6.316 6.31  6.037\n",
      " 5.869 5.895 6.059 5.985 5.968 7.241 6.54  6.696 6.874 6.014 5.898 6.516\n",
      " 6.635 6.939 6.49  6.579 5.884 6.728 5.663 5.936 6.212 6.395 6.127 6.112\n",
      " 6.398 6.251 5.362 5.803 8.78  3.561 4.963 3.863 4.97  6.683 7.016 6.216\n",
      " 5.875 4.906 4.138 7.313 6.649 6.794 6.38  6.223 6.968 6.545 5.536 5.52\n",
      " 4.368 5.277 4.652 5.    4.88  5.39  5.713 6.051 5.036 6.193 5.887 6.471\n",
      " 6.405 5.747 5.453 5.852 5.987 6.343 6.404 5.349 5.531 5.683 4.138 5.608\n",
      " 5.617 6.852 5.757 6.657 4.628 5.155 4.519 6.434 6.782 5.304 5.957 6.824\n",
      " 6.411 6.006 5.648 6.103 5.565 5.896 5.837 6.202 6.193 6.38  6.348 6.833\n",
      " 6.425 6.436 6.208 6.629 6.461 6.152 5.935 5.627 5.818 6.406 6.219 6.485\n",
      " 5.854 6.459 6.341 6.251 6.185 6.417 6.749 6.655 6.297 7.393 6.728 6.525\n",
      " 5.976 5.936 6.301 6.081 6.701 6.376 6.317 6.513 6.209 5.759 5.952 6.003\n",
      " 5.926 5.713 6.167 6.229 6.437 6.98  5.427 6.162 6.484 5.304 6.185 6.229\n",
      " 6.242 6.75  7.061 5.762 5.871 6.312 6.114 5.905 5.454 5.414 5.093 5.983\n",
      " 5.983 5.707 5.926 5.67  5.39  5.794 6.019 5.569 6.027 6.593 6.12  6.976\n",
      " 6.794 6.03 ]\n",
      "\n",
      "y: [24.  21.6 34.7 33.4 36.2 28.7 22.9 27.1 16.5 18.9 15.  18.9 21.7 20.4\n",
      " 18.2 19.9 23.1 17.5 20.2 18.2 13.6 19.6 15.2 14.5 15.6 13.9 16.6 14.8\n",
      " 18.4 21.  12.7 14.5 13.2 13.1 13.5 18.9 20.  21.  24.7 30.8 34.9 26.6\n",
      " 25.3 24.7 21.2 19.3 20.  16.6 14.4 19.4 19.7 20.5 25.  23.4 18.9 35.4\n",
      " 24.7 31.6 23.3 19.6 18.7 16.  22.2 25.  33.  23.5 19.4 22.  17.4 20.9\n",
      " 24.2 21.7 22.8 23.4 24.1 21.4 20.  20.8 21.2 20.3 28.  23.9 24.8 22.9\n",
      " 23.9 26.6 22.5 22.2 23.6 28.7 22.6 22.  22.9 25.  20.6 28.4 21.4 38.7\n",
      " 43.8 33.2 27.5 26.5 18.6 19.3 20.1 19.5 19.5 20.4 19.8 19.4 21.7 22.8\n",
      " 18.8 18.7 18.5 18.3 21.2 19.2 20.4 19.3 22.  20.3 20.5 17.3 18.8 21.4\n",
      " 15.7 16.2 18.  14.3 19.2 19.6 23.  18.4 15.6 18.1 17.4 17.1 13.3 17.8\n",
      " 14.  14.4 13.4 15.6 11.8 13.8 15.6 14.6 17.8 15.4 21.5 19.6 15.3 19.4\n",
      " 17.  15.6 13.1 41.3 24.3 23.3 27.  50.  50.  50.  22.7 25.  50.  23.8\n",
      " 23.8 22.3 17.4 19.1 23.1 23.6 22.6 29.4 23.2 24.6 29.9 37.2 39.8 36.2\n",
      " 37.9 32.5 26.4 29.6 50.  32.  29.8 34.9 37.  30.5 36.4 31.1 29.1 50.\n",
      " 33.3 30.3 34.6 34.9 32.9 24.1 42.3 48.5 50.  22.6 24.4 22.5 24.4 20.\n",
      " 21.7 19.3 22.4 28.1 23.7 25.  23.3 28.7 21.5 23.  26.7 21.7 27.5 30.1\n",
      " 44.8 50.  37.6 31.6 46.7 31.5 24.3 31.7 41.7 48.3 29.  24.  25.1 31.5\n",
      " 23.7 23.3 22.  20.1 22.2 23.7 17.6 18.5 24.3 20.5 24.5 26.2 24.4 24.8\n",
      " 29.6 42.8 21.9 20.9 44.  50.  36.  30.1 33.8 43.1 48.8 31.  36.5 22.8\n",
      " 30.7 50.  43.5 20.7 21.1 25.2 24.4 35.2 32.4 32.  33.2 33.1 29.1 35.1\n",
      " 45.4 35.4 46.  50.  32.2 22.  20.1 23.2 22.3 24.8 28.5 37.3 27.9 23.9\n",
      " 21.7 28.6 27.1 20.3 22.5 29.  24.8 22.  26.4 33.1 36.1 28.4 33.4 28.2\n",
      " 22.8 20.3 16.1 22.1 19.4 21.6 23.8 16.2 17.8 19.8 23.1 21.  23.8 23.1\n",
      " 20.4 18.5 25.  24.6 23.  22.2 19.3 22.6 19.8 17.1 19.4 22.2 20.7 21.1\n",
      " 19.5 18.5 20.6 19.  18.7 32.7 16.5 23.9 31.2 17.5 17.2 23.1 24.5 26.6\n",
      " 22.9 24.1 18.6 30.1 18.2 20.6 17.8 21.7 22.7 22.6 25.  19.9 20.8 16.8\n",
      " 21.9 27.5 21.9 23.1 50.  50.  50.  50.  50.  13.8 13.8 15.  13.9 13.3\n",
      " 13.1 10.2 10.4 10.9 11.3 12.3  8.8  7.2 10.5  7.4 10.2 11.5 15.1 23.2\n",
      "  9.7 13.8 12.7 13.1 12.5  8.5  5.   6.3  5.6  7.2 12.1  8.3  8.5  5.\n",
      " 11.9 27.9 17.2 27.5 15.  17.2 17.9 16.3  7.   7.2  7.5 10.4  8.8  8.4\n",
      " 16.7 14.2 20.8 13.4 11.7  8.3 10.2 10.9 11.   9.5 14.5 14.1 16.1 14.3\n",
      " 11.7 13.4  9.6  8.7  8.4 12.8 10.5 17.1 18.4 15.4 10.8 11.8 14.9 12.6\n",
      " 14.1 13.  13.4 15.2 16.1 17.8 14.9 14.1 12.7 13.5 14.9 20.  16.4 17.7\n",
      " 19.5 20.2 21.4 19.9 19.  19.1 19.1 20.1 19.9 19.6 23.2 29.8 13.8 13.3\n",
      " 16.7 12.  14.6 21.4 23.  23.7 25.  21.8 20.6 21.2 19.1 20.6 15.2  7.\n",
      "  8.1 13.6 20.1 21.8 24.5 23.1 19.7 18.3 21.2 17.5 16.8 22.4 20.6 23.9\n",
      " 22.  11.9]\n"
     ]
    }
   ],
   "source": [
    "print(f'X:\\n{X}\\n')\n",
    "print(f'X flatten: {X.flatten()}\\n')\n",
    "print(f'y: {y}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Nilai `X` diatas merupakann reshape dua dimensi. Hal tersebut dapat di kembalikan dengan melakukan **X.flatten()** dengan 1 dimensi (meratakan kembali)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variance\n",
    "\n",
    "`varians` (dari bahasa Inggris: `variance`) atau ragam suatu peubah acak (atau distribusi probabilitas) adalah ukuran seberapa jauh sebuah kumpulan bilangan tersebar. Varians nol mengindikasikan bahwa semua nilai sama. Varians selalu bernilai non-negatif: varians yang rendah mengindikasikan bahwa titik data condong sangat dekat dengan nilai rerata (nilai ekspektasi) dan antara satu sama lainnya, sementara varians yang tinggi mengindikasikan bahwa titik data sangat tersebar disekitar rerata dan dari satu sama lainnya.\n",
    "\n",
    "Referensi : https://id.wikipedia.org/wiki/Varians"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Untuk mencari nilai `Variance` kita dapat melakukan `variance_x = np.var(X.flatten(), ddof=1)` variabel `variance_x` yang memiliki 2 parameter yaitu :\n",
    "\n",
    "- **X.flatten()** adalah nilai yang sudah diratakan kembali (1 dimensi)\n",
    "- **ddof=1** adalah degree of freedom yang bernilai 1\n",
    "\n",
    "Seperti script di bawah ini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variance: 0.49367085022110907\n"
     ]
    }
   ],
   "source": [
    "variance_x = np.var(X.flatten(), ddof=1)\n",
    "\n",
    "print(f'variance: {variance_x}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Covariance\n",
    "\n",
    "`Covariance` adalah ukuran variabilitas gabungan dari dua variabel acak . [1] Jika nilai yang lebih besar dari satu variabel terutama sesuai dengan nilai yang lebih besar dari variabel lain, dan hal yang sama berlaku untuk nilai yang lebih rendah (yaitu, variabel cenderung menunjukkan perilaku yang sama), kovariannya positif. [2] Dalam kasus sebaliknya, ketika nilai yang lebih besar dari satu variabel terutama sesuai dengan nilai yang lebih rendah dari yang lain, (yaitu, variabel cenderung menunjukkan perilaku yang berlawanan), kovariannya negatif. Oleh karena itu, tanda kovarian menunjukkan kecenderungan dalam hubungan linierantar variabel.\n",
    "\n",
    "Referensi : https://translate.google.com/translate?u=https://en.wikipedia.org/wiki/Covariance&hl=id&sl=en&tl=id&client=srp&prev=search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.49367085,  4.49344588],\n",
       "       [ 4.49344588, 84.58672359]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.cov(X.flatten(), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- `np.cov(X.flatten(), y)` akan menghasilkan covariance matrix yang terdiri atas 2 baris nilai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "covariance: 4.493445879544476\n"
     ]
    }
   ],
   "source": [
    "covariance_xy = np.cov(X.flatten(), y)[0][1]\n",
    "\n",
    "print(f'covariance: {covariance_xy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- `covariance_xy = np.cov(X.flatten(), y)[0][1]` akan menghasilkan covariance yang memiliki 2 parameter yaitu `X.flatten()` dan `y` yang ditampung pada variabel `covariance_xy`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slope\n",
    "\n",
    "`Slope` is calculated by finding the ratio of the \"vertical change\" to the \"horizontal change\" between (any) two distinct points on a line. Sometimes the ratio is expressed as a quotient (\"rise over run\"), giving the same number for every two distinct points on the same line. A line that is decreasing has a negative \"rise\". The line may be practical - as set by a road surveyor, or in a diagram that models a road or a roof either as a description or as a plan.\n",
    "\n",
    "The steepness, incline, or grade of a line is measured by the absolute value of the slope. A slope with a greater absolute value indicates a steeper line. The direction of a line is either increasing, decreasing, horizontal or vertical.\n",
    "\n",
    "- A line is increasing if it goes up from left to right. The slope is positive, i.e. {\\displaystyle m>0}m>0.\n",
    "- A line is decreasing if it goes down from left to right. The slope is negative, i.e. {\\displaystyle m<0}m<0.\n",
    "- If a line is horizontal the slope is zero. This is a constant function.\n",
    "- If a line is vertical the slope is undefined (see below).\n",
    "\n",
    "Referensi : https://en.wikipedia.org/wiki/Slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slope: 9.102108981180308\n"
     ]
    }
   ],
   "source": [
    "slope = covariance_xy / variance_x\n",
    "\n",
    "print(f'slope: {slope}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `covariance_xy` akan dibagi dengan `variance_x` yang ditampung dalam vaiabel slope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Mencari nilai intercept\n",
    "\n",
    "Nilai intercept pada Linear Regression bisa diperoleh dengan memanfaatkan formula berikut:\n",
    "\n",
    "$\\alpha = \\bar{y} - \\beta \\bar{x}$\n",
    "\n",
    "Berikut adalah cara mencari nilai `intercept` secara manual dengan `np.mean(y)` akan dikurangkan dengan nilai (`slope` yang dikalikan dengan `np.mean(X)`), kemudian di tampung dalam sebuah vaiabel `intercept`. \n",
    "Dapat dilihat pada script berikut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept: -34.670620776438554\n"
     ]
    }
   ],
   "source": [
    "intercept = np.mean(y) - slope * np.mean(X)\n",
    "\n",
    "print(f'intercept: {intercept}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Prediksi Harga Boston Housing \n",
    "\n",
    "Untuk melakukan prediksi nilai, pada kasus ini terlebih dahulu untuk mengubah tampilan feature dengan 2 dimensi. Berikut ada 3 cara untuk melakukan prediksi harga Boston Housing yaitu : \n",
    "\n",
    "- `RM_Jumlah_Kamar = np.array(boston_df[['RM']]).reshape(-1, 1)` dengan memberikan nilai parameter yaitu `RM` (Jumlah ruang kamar) dan reshape(-1, 1).\n",
    "- `prediksi_harga = model.predict(RM_Jumlah_Kamar)` prediksi ini melakukan dengan function `model.predict` dengan parameter `RM_Jumlah_Kamar`.\n",
    "- `for dmtr, hrg in zip(RM_Jumlah_Kamar, prediksi_harga):\n",
    "    print(f'RM_Jumlah_Kamar: {RM_Jumlah_Kamar} predilsi harga: {hrg}')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.575],\n",
       "       [6.421],\n",
       "       [7.185],\n",
       "       [6.998],\n",
       "       [7.147],\n",
       "       [6.43 ],\n",
       "       [6.012],\n",
       "       [6.172],\n",
       "       [5.631],\n",
       "       [6.004],\n",
       "       [6.377],\n",
       "       [6.009],\n",
       "       [5.889],\n",
       "       [5.949],\n",
       "       [6.096],\n",
       "       [5.834],\n",
       "       [5.935],\n",
       "       [5.99 ],\n",
       "       [5.456],\n",
       "       [5.727],\n",
       "       [5.57 ],\n",
       "       [5.965],\n",
       "       [6.142],\n",
       "       [5.813],\n",
       "       [5.924],\n",
       "       [5.599],\n",
       "       [5.813],\n",
       "       [6.047],\n",
       "       [6.495],\n",
       "       [6.674],\n",
       "       [5.713],\n",
       "       [6.072],\n",
       "       [5.95 ],\n",
       "       [5.701],\n",
       "       [6.096],\n",
       "       [5.933],\n",
       "       [5.841],\n",
       "       [5.85 ],\n",
       "       [5.966],\n",
       "       [6.595],\n",
       "       [7.024],\n",
       "       [6.77 ],\n",
       "       [6.169],\n",
       "       [6.211],\n",
       "       [6.069],\n",
       "       [5.682],\n",
       "       [5.786],\n",
       "       [6.03 ],\n",
       "       [5.399],\n",
       "       [5.602],\n",
       "       [5.963],\n",
       "       [6.115],\n",
       "       [6.511],\n",
       "       [5.998],\n",
       "       [5.888],\n",
       "       [7.249],\n",
       "       [6.383],\n",
       "       [6.816],\n",
       "       [6.145],\n",
       "       [5.927],\n",
       "       [5.741],\n",
       "       [5.966],\n",
       "       [6.456],\n",
       "       [6.762],\n",
       "       [7.104],\n",
       "       [6.29 ],\n",
       "       [5.787],\n",
       "       [5.878],\n",
       "       [5.594],\n",
       "       [5.885],\n",
       "       [6.417],\n",
       "       [5.961],\n",
       "       [6.065],\n",
       "       [6.245],\n",
       "       [6.273],\n",
       "       [6.286],\n",
       "       [6.279],\n",
       "       [6.14 ],\n",
       "       [6.232],\n",
       "       [5.874],\n",
       "       [6.727],\n",
       "       [6.619],\n",
       "       [6.302],\n",
       "       [6.167],\n",
       "       [6.389],\n",
       "       [6.63 ],\n",
       "       [6.015],\n",
       "       [6.121],\n",
       "       [7.007],\n",
       "       [7.079],\n",
       "       [6.417],\n",
       "       [6.405],\n",
       "       [6.442],\n",
       "       [6.211],\n",
       "       [6.249],\n",
       "       [6.625],\n",
       "       [6.163],\n",
       "       [8.069],\n",
       "       [7.82 ],\n",
       "       [7.416],\n",
       "       [6.727],\n",
       "       [6.781],\n",
       "       [6.405],\n",
       "       [6.137],\n",
       "       [6.167],\n",
       "       [5.851],\n",
       "       [5.836],\n",
       "       [6.127],\n",
       "       [6.474],\n",
       "       [6.229],\n",
       "       [6.195],\n",
       "       [6.715],\n",
       "       [5.913],\n",
       "       [6.092],\n",
       "       [6.254],\n",
       "       [5.928],\n",
       "       [6.176],\n",
       "       [6.021],\n",
       "       [5.872],\n",
       "       [5.731],\n",
       "       [5.87 ],\n",
       "       [6.004],\n",
       "       [5.961],\n",
       "       [5.856],\n",
       "       [5.879],\n",
       "       [5.986],\n",
       "       [5.613],\n",
       "       [5.693],\n",
       "       [6.431],\n",
       "       [5.637],\n",
       "       [6.458],\n",
       "       [6.326],\n",
       "       [6.372],\n",
       "       [5.822],\n",
       "       [5.757],\n",
       "       [6.335],\n",
       "       [5.942],\n",
       "       [6.454],\n",
       "       [5.857],\n",
       "       [6.151],\n",
       "       [6.174],\n",
       "       [5.019],\n",
       "       [5.403],\n",
       "       [5.468],\n",
       "       [4.903],\n",
       "       [6.13 ],\n",
       "       [5.628],\n",
       "       [4.926],\n",
       "       [5.186],\n",
       "       [5.597],\n",
       "       [6.122],\n",
       "       [5.404],\n",
       "       [5.012],\n",
       "       [5.709],\n",
       "       [6.129],\n",
       "       [6.152],\n",
       "       [5.272],\n",
       "       [6.943],\n",
       "       [6.066],\n",
       "       [6.51 ],\n",
       "       [6.25 ],\n",
       "       [7.489],\n",
       "       [7.802],\n",
       "       [8.375],\n",
       "       [5.854],\n",
       "       [6.101],\n",
       "       [7.929],\n",
       "       [5.877],\n",
       "       [6.319],\n",
       "       [6.402],\n",
       "       [5.875],\n",
       "       [5.88 ],\n",
       "       [5.572],\n",
       "       [6.416],\n",
       "       [5.859],\n",
       "       [6.546],\n",
       "       [6.02 ],\n",
       "       [6.315],\n",
       "       [6.86 ],\n",
       "       [6.98 ],\n",
       "       [7.765],\n",
       "       [6.144],\n",
       "       [7.155],\n",
       "       [6.563],\n",
       "       [5.604],\n",
       "       [6.153],\n",
       "       [7.831],\n",
       "       [6.782],\n",
       "       [6.556],\n",
       "       [7.185],\n",
       "       [6.951],\n",
       "       [6.739],\n",
       "       [7.178],\n",
       "       [6.8  ],\n",
       "       [6.604],\n",
       "       [7.875],\n",
       "       [7.287],\n",
       "       [7.107],\n",
       "       [7.274],\n",
       "       [6.975],\n",
       "       [7.135],\n",
       "       [6.162],\n",
       "       [7.61 ],\n",
       "       [7.853],\n",
       "       [8.034],\n",
       "       [5.891],\n",
       "       [6.326],\n",
       "       [5.783],\n",
       "       [6.064],\n",
       "       [5.344],\n",
       "       [5.96 ],\n",
       "       [5.404],\n",
       "       [5.807],\n",
       "       [6.375],\n",
       "       [5.412],\n",
       "       [6.182],\n",
       "       [5.888],\n",
       "       [6.642],\n",
       "       [5.951],\n",
       "       [6.373],\n",
       "       [6.951],\n",
       "       [6.164],\n",
       "       [6.879],\n",
       "       [6.618],\n",
       "       [8.266],\n",
       "       [8.725],\n",
       "       [8.04 ],\n",
       "       [7.163],\n",
       "       [7.686],\n",
       "       [6.552],\n",
       "       [5.981],\n",
       "       [7.412],\n",
       "       [8.337],\n",
       "       [8.247],\n",
       "       [6.726],\n",
       "       [6.086],\n",
       "       [6.631],\n",
       "       [7.358],\n",
       "       [6.481],\n",
       "       [6.606],\n",
       "       [6.897],\n",
       "       [6.095],\n",
       "       [6.358],\n",
       "       [6.393],\n",
       "       [5.593],\n",
       "       [5.605],\n",
       "       [6.108],\n",
       "       [6.226],\n",
       "       [6.433],\n",
       "       [6.718],\n",
       "       [6.487],\n",
       "       [6.438],\n",
       "       [6.957],\n",
       "       [8.259],\n",
       "       [6.108],\n",
       "       [5.876],\n",
       "       [7.454],\n",
       "       [8.704],\n",
       "       [7.333],\n",
       "       [6.842],\n",
       "       [7.203],\n",
       "       [7.52 ],\n",
       "       [8.398],\n",
       "       [7.327],\n",
       "       [7.206],\n",
       "       [5.56 ],\n",
       "       [7.014],\n",
       "       [8.297],\n",
       "       [7.47 ],\n",
       "       [5.92 ],\n",
       "       [5.856],\n",
       "       [6.24 ],\n",
       "       [6.538],\n",
       "       [7.691],\n",
       "       [6.758],\n",
       "       [6.854],\n",
       "       [7.267],\n",
       "       [6.826],\n",
       "       [6.482],\n",
       "       [6.812],\n",
       "       [7.82 ],\n",
       "       [6.968],\n",
       "       [7.645],\n",
       "       [7.923],\n",
       "       [7.088],\n",
       "       [6.453],\n",
       "       [6.23 ],\n",
       "       [6.209],\n",
       "       [6.315],\n",
       "       [6.565],\n",
       "       [6.861],\n",
       "       [7.148],\n",
       "       [6.63 ],\n",
       "       [6.127],\n",
       "       [6.009],\n",
       "       [6.678],\n",
       "       [6.549],\n",
       "       [5.79 ],\n",
       "       [6.345],\n",
       "       [7.041],\n",
       "       [6.871],\n",
       "       [6.59 ],\n",
       "       [6.495],\n",
       "       [6.982],\n",
       "       [7.236],\n",
       "       [6.616],\n",
       "       [7.42 ],\n",
       "       [6.849],\n",
       "       [6.635],\n",
       "       [5.972],\n",
       "       [4.973],\n",
       "       [6.122],\n",
       "       [6.023],\n",
       "       [6.266],\n",
       "       [6.567],\n",
       "       [5.705],\n",
       "       [5.914],\n",
       "       [5.782],\n",
       "       [6.382],\n",
       "       [6.113],\n",
       "       [6.426],\n",
       "       [6.376],\n",
       "       [6.041],\n",
       "       [5.708],\n",
       "       [6.415],\n",
       "       [6.431],\n",
       "       [6.312],\n",
       "       [6.083],\n",
       "       [5.868],\n",
       "       [6.333],\n",
       "       [6.144],\n",
       "       [5.706],\n",
       "       [6.031],\n",
       "       [6.316],\n",
       "       [6.31 ],\n",
       "       [6.037],\n",
       "       [5.869],\n",
       "       [5.895],\n",
       "       [6.059],\n",
       "       [5.985],\n",
       "       [5.968],\n",
       "       [7.241],\n",
       "       [6.54 ],\n",
       "       [6.696],\n",
       "       [6.874],\n",
       "       [6.014],\n",
       "       [5.898],\n",
       "       [6.516],\n",
       "       [6.635],\n",
       "       [6.939],\n",
       "       [6.49 ],\n",
       "       [6.579],\n",
       "       [5.884],\n",
       "       [6.728],\n",
       "       [5.663],\n",
       "       [5.936],\n",
       "       [6.212],\n",
       "       [6.395],\n",
       "       [6.127],\n",
       "       [6.112],\n",
       "       [6.398],\n",
       "       [6.251],\n",
       "       [5.362],\n",
       "       [5.803],\n",
       "       [8.78 ],\n",
       "       [3.561],\n",
       "       [4.963],\n",
       "       [3.863],\n",
       "       [4.97 ],\n",
       "       [6.683],\n",
       "       [7.016],\n",
       "       [6.216],\n",
       "       [5.875],\n",
       "       [4.906],\n",
       "       [4.138],\n",
       "       [7.313],\n",
       "       [6.649],\n",
       "       [6.794],\n",
       "       [6.38 ],\n",
       "       [6.223],\n",
       "       [6.968],\n",
       "       [6.545],\n",
       "       [5.536],\n",
       "       [5.52 ],\n",
       "       [4.368],\n",
       "       [5.277],\n",
       "       [4.652],\n",
       "       [5.   ],\n",
       "       [4.88 ],\n",
       "       [5.39 ],\n",
       "       [5.713],\n",
       "       [6.051],\n",
       "       [5.036],\n",
       "       [6.193],\n",
       "       [5.887],\n",
       "       [6.471],\n",
       "       [6.405],\n",
       "       [5.747],\n",
       "       [5.453],\n",
       "       [5.852],\n",
       "       [5.987],\n",
       "       [6.343],\n",
       "       [6.404],\n",
       "       [5.349],\n",
       "       [5.531],\n",
       "       [5.683],\n",
       "       [4.138],\n",
       "       [5.608],\n",
       "       [5.617],\n",
       "       [6.852],\n",
       "       [5.757],\n",
       "       [6.657],\n",
       "       [4.628],\n",
       "       [5.155],\n",
       "       [4.519],\n",
       "       [6.434],\n",
       "       [6.782],\n",
       "       [5.304],\n",
       "       [5.957],\n",
       "       [6.824],\n",
       "       [6.411],\n",
       "       [6.006],\n",
       "       [5.648],\n",
       "       [6.103],\n",
       "       [5.565],\n",
       "       [5.896],\n",
       "       [5.837],\n",
       "       [6.202],\n",
       "       [6.193],\n",
       "       [6.38 ],\n",
       "       [6.348],\n",
       "       [6.833],\n",
       "       [6.425],\n",
       "       [6.436],\n",
       "       [6.208],\n",
       "       [6.629],\n",
       "       [6.461],\n",
       "       [6.152],\n",
       "       [5.935],\n",
       "       [5.627],\n",
       "       [5.818],\n",
       "       [6.406],\n",
       "       [6.219],\n",
       "       [6.485],\n",
       "       [5.854],\n",
       "       [6.459],\n",
       "       [6.341],\n",
       "       [6.251],\n",
       "       [6.185],\n",
       "       [6.417],\n",
       "       [6.749],\n",
       "       [6.655],\n",
       "       [6.297],\n",
       "       [7.393],\n",
       "       [6.728],\n",
       "       [6.525],\n",
       "       [5.976],\n",
       "       [5.936],\n",
       "       [6.301],\n",
       "       [6.081],\n",
       "       [6.701],\n",
       "       [6.376],\n",
       "       [6.317],\n",
       "       [6.513],\n",
       "       [6.209],\n",
       "       [5.759],\n",
       "       [5.952],\n",
       "       [6.003],\n",
       "       [5.926],\n",
       "       [5.713],\n",
       "       [6.167],\n",
       "       [6.229],\n",
       "       [6.437],\n",
       "       [6.98 ],\n",
       "       [5.427],\n",
       "       [6.162],\n",
       "       [6.484],\n",
       "       [5.304],\n",
       "       [6.185],\n",
       "       [6.229],\n",
       "       [6.242],\n",
       "       [6.75 ],\n",
       "       [7.061],\n",
       "       [5.762],\n",
       "       [5.871],\n",
       "       [6.312],\n",
       "       [6.114],\n",
       "       [5.905],\n",
       "       [5.454],\n",
       "       [5.414],\n",
       "       [5.093],\n",
       "       [5.983],\n",
       "       [5.983],\n",
       "       [5.707],\n",
       "       [5.926],\n",
       "       [5.67 ],\n",
       "       [5.39 ],\n",
       "       [5.794],\n",
       "       [6.019],\n",
       "       [5.569],\n",
       "       [6.027],\n",
       "       [6.593],\n",
       "       [6.12 ],\n",
       "       [6.976],\n",
       "       [6.794],\n",
       "       [6.03 ]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RM_Jumlah_Kamar = np.array(boston_df[['RM']]).reshape(-1, 1)\n",
    "RM_Jumlah_Kamar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([25.17574577, 23.77402099, 30.72803225, 29.02593787, 30.38215211,\n",
       "       23.85593997, 20.05125842, 21.50759586, 16.5833549 , 19.97844155,\n",
       "       23.3735282 , 20.02395209, 18.93169901, 19.47782555, 20.81583557,\n",
       "       18.43108302, 19.35039603, 19.85101202, 14.99048582, 17.45715736,\n",
       "       16.02812625, 19.6234593 , 21.23453259, 18.23993873, 19.25027283,\n",
       "       16.29208741, 18.23993873, 20.36983223, 24.44757706, 26.07685456,\n",
       "       17.32972783, 20.59738496, 19.48692766, 17.22050253, 20.81583557,\n",
       "       19.33219181, 18.49479778, 18.57671676, 19.63256141, 25.35778795,\n",
       "       29.26259271, 26.95065703, 21.48028953, 21.86257811, 20.57007863,\n",
       "       17.04756245, 17.99418179, 20.21509638, 14.47166561, 16.31939374,\n",
       "       19.60525508, 20.98877564, 24.5932108 , 19.92382889, 18.9225969 ,\n",
       "       31.31056723, 23.42814085, 27.36935404, 21.26183891, 19.27757916,\n",
       "       17.58458688, 19.63256141, 24.09259481, 26.87784015, 29.99076143,\n",
       "       22.58164472, 18.0032839 , 18.83157581, 16.24657686, 18.89529058,\n",
       "       23.73761256, 19.58705086, 20.53367019, 22.17204981, 22.42690886,\n",
       "       22.54523628, 22.48152152, 21.21632837, 22.05372239, 18.79516738,\n",
       "       26.55926634, 25.57623857, 22.69087002, 21.46208531, 23.4827535 ,\n",
       "       25.67636177, 20.07856475, 21.0433883 , 29.10785685, 29.7632087 ,\n",
       "       23.73761256, 23.62838725, 23.96516528, 21.86257811, 22.20845825,\n",
       "       25.63085122, 21.42567687, 38.77429659, 36.50787146, 32.83061943,\n",
       "       26.55926634, 27.05078022, 23.62838725, 21.18902204, 21.46208531,\n",
       "       18.58581887, 18.44928724, 21.09800095, 24.25643277, 22.02641607,\n",
       "       21.71694436, 26.45004103, 19.15014963, 20.77942714, 22.25396879,\n",
       "       19.28668126, 21.54400429, 20.1331774 , 18.77696316, 17.49356579,\n",
       "       18.75875894, 19.97844155, 19.58705086, 18.63132942, 18.84067792,\n",
       "       19.81460358, 16.41951693, 17.14768565, 23.86504208, 16.63796755,\n",
       "       24.11079902, 22.90932064, 23.32801765, 18.32185771, 17.73022063,\n",
       "       22.99123962, 19.41411079, 24.07439059, 18.64043153, 21.31645157,\n",
       "       21.52580007, 11.0128642 , 14.50807405, 15.09971113,  9.95701956,\n",
       "       21.12530728, 16.55604857, 10.16636806, 12.5329164 , 16.27388319,\n",
       "       21.05249041, 14.51717616, 10.94914944, 17.2933194 , 21.11620517,\n",
       "       21.32555368, 13.31569777, 28.52532188, 20.5427723 , 24.58410869,\n",
       "       22.21756036, 33.49507338, 36.34403349, 41.55954194, 18.6131252 ,\n",
       "       20.86134612, 37.50000134, 18.82247371, 22.84560588, 23.60108092,\n",
       "       18.80426949, 18.84978003, 16.04633047, 23.72851045, 18.65863574,\n",
       "       24.91178461, 20.12407529, 22.80919744, 27.76984683, 28.86209991,\n",
       "       36.00725546, 21.2527368 , 30.45496898, 25.06652047, 16.33759795,\n",
       "       21.33465578, 36.60799466, 27.05988233, 25.0028057 , 30.72803225,\n",
       "       28.59813875, 26.66849165, 30.66431749, 27.2237203 , 25.43970694,\n",
       "       37.00848745, 31.65644737, 30.01806775, 31.53811995, 28.81658937,\n",
       "       30.2729268 , 21.41657477, 34.59642857, 36.80824105, 38.45572278,\n",
       "       18.94990323, 22.90932064, 17.96687546, 20.52456809, 13.97104962,\n",
       "       19.57794875, 14.51717616, 18.18532608, 23.35532398, 14.58999303,\n",
       "       21.59861695, 18.9225969 , 25.78558708, 19.49602977, 23.33711976,\n",
       "       28.59813875, 21.43477898, 27.94278691, 25.56713646, 40.56741206,\n",
       "       44.74528008, 38.51033543, 30.52778586, 35.28818885, 24.96639727,\n",
       "       19.76909304, 32.79421099, 41.2136618 , 40.39447199, 26.55016423,\n",
       "       20.72481448, 25.68546388, 32.30269711, 24.32014753, 25.45791115,\n",
       "       28.10662487, 20.80673346, 23.20058813, 23.51916194, 16.23747476,\n",
       "       16.34670006, 20.92506088, 21.99910974, 23.8832463 , 26.47734736,\n",
       "       24.37476018, 23.92875684, 28.65275141, 40.5036973 , 20.92506088,\n",
       "       18.8133716 , 33.17649957, 44.5541358 , 32.07514438, 27.60600887,\n",
       "       30.89187022, 33.77723876, 41.76889045, 32.02053173, 30.91917654,\n",
       "       15.93710516, 29.17157162, 40.84957744, 33.32213331, 19.21386439,\n",
       "       18.63132942, 22.12653927, 24.83896774, 35.3336994 , 26.84143172,\n",
       "       27.71523418, 31.47440519, 27.46037513, 24.32924964, 27.3329456 ,\n",
       "       36.50787146, 28.7528746 , 34.91500238, 37.44538868, 29.84512768,\n",
       "       24.06528848, 22.03551818, 21.84437389, 22.80919744, 25.08472469,\n",
       "       27.77894894, 30.39125422, 25.67636177, 21.09800095, 20.02395209,\n",
       "       26.113263  , 24.93909094, 18.03059022, 23.08226071, 29.41732856,\n",
       "       27.86997003, 25.31227741, 24.44757706, 28.88030413, 31.19223981,\n",
       "       25.54893224, 32.86702786, 27.66972364, 25.72187231, 19.68717406,\n",
       "       10.59416719, 21.05249041, 20.15138162, 22.3631941 , 25.1029289 ,\n",
       "       17.25691096, 19.15925174, 17.95777335, 23.41903874, 20.97057143,\n",
       "       23.81953154, 23.36442609, 20.31521958, 17.28421729, 23.71940834,\n",
       "       23.86504208, 22.78189111, 20.69750816, 18.74055473, 22.9730354 ,\n",
       "       21.2527368 , 17.26601307, 20.22419849, 22.81829955, 22.76368689,\n",
       "       20.27881114, 18.74965683, 18.98631167, 20.47905754, 19.80550148,\n",
       "       19.65076562, 31.23775036, 24.85717196, 26.27710096, 27.89727636,\n",
       "       20.06946264, 19.01361799, 24.63872134, 25.72187231, 28.48891344,\n",
       "       24.40206651, 25.21215421, 18.88618847, 26.56836845, 16.87462238,\n",
       "       19.35949814, 21.87168021, 23.53736616, 21.09800095, 20.96146932,\n",
       "       23.56467249, 22.22666246, 14.13488758, 18.14891764, 45.24589608,\n",
       "       -2.25801069, 10.5031461 ,  0.49082622, 10.56686086, 26.15877354,\n",
       "       29.18977584, 21.90808865, 18.80426949,  9.98432589,  2.99390619,\n",
       "       31.8931022 , 25.84930184, 27.16910764, 23.40083452, 21.97180341,\n",
       "       28.7528746 , 24.90268251, 15.71865454, 15.5730208 ,  5.08739125,\n",
       "       13.36120832,  7.6723902 , 10.83992413,  9.74767105, 14.38974663,\n",
       "       17.32972783, 20.40624067, 11.16760005, 21.69874014, 18.9134948 ,\n",
       "       24.22912644, 23.62838725, 17.63919954, 14.9631795 , 18.59492098,\n",
       "       19.82370569, 23.06405649, 23.61928514, 14.01656016, 15.673144  ,\n",
       "       17.05666456,  2.99390619, 16.37400639, 16.45592537, 27.69702996,\n",
       "       17.73022063, 25.92211871,  7.45393959, 12.25075102,  6.46180971,\n",
       "       23.89234841, 27.05988233, 13.60696526, 19.55064242, 27.44217091,\n",
       "       23.6829999 , 19.99664576, 16.73809075, 20.87955034, 15.9826157 ,\n",
       "       18.99541378, 18.45838935, 21.78065912, 21.69874014, 23.40083452,\n",
       "       23.10956704, 27.52408989, 23.81042943, 23.91055263, 21.83527178,\n",
       "       25.66725966, 24.13810535, 21.32555368, 19.35039603, 16.54694646,\n",
       "       18.28544928, 23.63748936, 21.93539498, 24.35655597, 18.6131252 ,\n",
       "       24.11990113, 23.04585227, 22.22666246, 21.62592327, 23.73761256,\n",
       "       26.75951274, 25.90391449, 22.64535948, 32.62127092, 26.56836845,\n",
       "       24.72064033, 19.7235825 , 19.35949814, 22.68176791, 20.67930394,\n",
       "       26.32261151, 23.36442609, 22.82740166, 24.61141502, 21.84437389,\n",
       "       17.74842485, 19.50513188, 19.96933944, 19.26847705, 17.32972783,\n",
       "       21.46208531, 22.02641607, 23.91965474, 28.86209991, 14.72652466,\n",
       "       21.41657477, 24.34745386, 13.60696526, 21.62592327, 22.02641607,\n",
       "       22.14474348, 26.76861485, 29.59937074, 17.77573117, 18.76786105,\n",
       "       22.78189111, 20.97967353, 19.07733276, 14.97228161, 14.60819725,\n",
       "       11.68642026, 19.78729726, 19.78729726, 17.27511518, 19.26847705,\n",
       "       16.93833715, 14.38974663, 18.06699866, 20.11497318, 16.01902414,\n",
       "       20.18779005, 25.33958374, 21.03428619, 28.82569148, 27.16910764,\n",
       "       20.21509638])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediksi_harga = model.predict(RM_Jumlah_Kamar)\n",
    "prediksi_harga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c: [6.575] prediksi harga: 25.17574577482197\n",
      "c: [6.421] prediksi harga: 23.774020991720207\n",
      "c: [7.185] prediksi harga: 30.72803225334195\n",
      "c: [6.998] prediksi harga: 29.025937873861245\n",
      "c: [7.147] prediksi harga: 30.382152112057113\n",
      "c: [6.43] prediksi harga: 23.85593997255082\n",
      "c: [6.012] prediksi harga: 20.051258418417454\n",
      "c: [6.172] prediksi harga: 21.507595855406308\n",
      "c: [5.631] prediksi harga: 16.583354896587764\n",
      "c: [6.004] prediksi harga: 19.978441546568014\n",
      "c: [6.377] prediksi harga: 23.37352819654827\n",
      "c: [6.009] prediksi harga: 20.023952091473923\n",
      "c: [5.889] prediksi harga: 18.931699013732285\n",
      "c: [5.949] prediksi harga: 19.4778255526031\n",
      "c: [6.096] prediksi harga: 20.815835572836605\n",
      "c: [5.834] prediksi harga: 18.431083019767357\n",
      "c: [5.935] prediksi harga: 19.35039602686657\n",
      "c: [5.99] prediksi harga: 19.85101202083149\n",
      "c: [5.456] prediksi harga: 14.990485824881212\n",
      "c: [5.727] prediksi harga: 17.457157358781075\n",
      "c: [5.57] prediksi harga: 16.028126248735767\n",
      "c: [5.965] prediksi harga: 19.62345929630198\n",
      "c: [6.142] prediksi harga: 21.234532585970904\n",
      "c: [5.813] prediksi harga: 18.239938731162574\n",
      "c: [5.924] prediksi harga: 19.25027282807359\n",
      "c: [5.599] prediksi harga: 16.29208740918999\n",
      "c: [5.813] prediksi harga: 18.239938731162574\n",
      "c: [6.047] prediksi harga: 20.369832232758768\n",
      "c: [6.495] prediksi harga: 24.447577056327546\n",
      "c: [6.674] prediksi harga: 26.076854563958825\n",
      "c: [5.713] prediksi harga: 17.329727833044544\n",
      "c: [6.072] prediksi harga: 20.597384957288277\n",
      "c: [5.95] prediksi harga: 19.486927661584282\n",
      "c: [5.701] prediksi harga: 17.220502525270376\n",
      "c: [6.096] prediksi harga: 20.815835572836605\n",
      "c: [5.933] prediksi harga: 19.332191808904213\n",
      "c: [5.841] prediksi harga: 18.49479778263563\n",
      "c: [5.85] prediksi harga: 18.576716763466244\n",
      "c: [5.966] prediksi harga: 19.632561405283163\n",
      "c: [6.595] prediksi harga: 25.357787954445577\n",
      "c: [7.024] prediksi harga: 29.26259270737193\n",
      "c: [6.77] prediksi harga: 26.95065702615213\n",
      "c: [6.169] prediksi harga: 21.480289528462762\n",
      "c: [6.211] prediksi harga: 21.86257810567234\n",
      "c: [6.069] prediksi harga: 20.57007863034473\n",
      "c: [5.682] prediksi harga: 17.047562454627958\n",
      "c: [5.786] prediksi harga: 17.9941817886707\n",
      "c: [6.03] prediksi harga: 20.215096380078705\n",
      "c: [5.399] prediksi harga: 14.471665612953927\n",
      "c: [5.602] prediksi harga: 16.319393736133534\n",
      "c: [5.963] prediksi harga: 19.605255078339624\n",
      "c: [6.115] prediksi harga: 20.98877564347903\n",
      "c: [6.511] prediksi harga: 24.593210800026434\n",
      "c: [5.998] prediksi harga: 19.923828892680937\n",
      "c: [5.888] prediksi harga: 18.922596904751096\n",
      "c: [7.249] prediksi harga: 31.3105672281375\n",
      "c: [6.383] prediksi harga: 23.428140850435355\n",
      "c: [6.816] prediksi harga: 27.36935403928642\n",
      "c: [6.145] prediksi harga: 21.261838912914435\n",
      "c: [5.927] prediksi harga: 19.27757915501713\n",
      "c: [5.741] prediksi harga: 17.58458688451759\n",
      "c: [5.966] prediksi harga: 19.632561405283163\n",
      "c: [6.456] prediksi harga: 24.09259480606152\n",
      "c: [6.762] prediksi harga: 26.87784015430268\n",
      "c: [7.104] prediksi harga: 29.990761425866353\n",
      "c: [6.29] prediksi harga: 22.581644715185583\n",
      "c: [5.787] prediksi harga: 18.00328389765189\n",
      "c: [5.878] prediksi harga: 18.8315758149393\n",
      "c: [5.594] prediksi harga: 16.246576864284094\n",
      "c: [5.885] prediksi harga: 18.895290577807557\n",
      "c: [6.417] prediksi harga: 23.73761255579548\n",
      "c: [5.961] prediksi harga: 19.587050860377268\n",
      "c: [6.065] prediksi harga: 20.53367019442002\n",
      "c: [6.245] prediksi harga: 22.172049811032473\n",
      "c: [6.273] prediksi harga: 22.426908862505513\n",
      "c: [6.286] prediksi harga: 22.545236279260855\n",
      "c: [6.279] prediksi harga: 22.481521516392597\n",
      "c: [6.14] prediksi harga: 21.216328368008533\n",
      "c: [6.232] prediksi harga: 22.05372239427713\n",
      "c: [5.874] prediksi harga: 18.795167379014572\n",
      "c: [6.727] prediksi harga: 26.559266339961383\n",
      "c: [6.619] prediksi harga: 25.576238569993905\n",
      "c: [6.302] prediksi harga: 22.690870022959743\n",
      "c: [6.167] prediksi harga: 21.462085310500406\n",
      "c: [6.389] prediksi harga: 23.48275350432244\n",
      "c: [6.63] prediksi harga: 25.67636176878689\n",
      "c: [6.015] prediksi harga: 20.078564745360993\n",
      "c: [6.121] prediksi harga: 21.043388297366114\n",
      "c: [7.007] prediksi harga: 29.10785685469186\n",
      "c: [7.079] prediksi harga: 29.76320870133685\n",
      "c: [6.417] prediksi harga: 23.73761255579548\n",
      "c: [6.405] prediksi harga: 23.62838724802132\n",
      "c: [6.442] prediksi harga: 23.96516528032499\n",
      "c: [6.211] prediksi harga: 21.86257810567234\n",
      "c: [6.249] prediksi harga: 22.208458246957186\n",
      "c: [6.625] prediksi harga: 25.63085122388099\n",
      "c: [6.163] prediksi harga: 21.425676874575686\n",
      "c: [8.069] prediksi harga: 38.774296592705355\n",
      "c: [7.82] prediksi harga: 36.507871456391456\n",
      "c: [7.416] prediksi harga: 32.83061942799462\n",
      "c: [6.727] prediksi harga: 26.559266339961383\n",
      "c: [6.781] prediksi harga: 27.050780224945115\n",
      "c: [6.405] prediksi harga: 23.62838724802132\n",
      "c: [6.137] prediksi harga: 21.189022041064995\n",
      "c: [6.167] prediksi harga: 21.462085310500406\n",
      "c: [5.851] prediksi harga: 18.585818872447426\n",
      "c: [5.836] prediksi harga: 18.449287237729727\n",
      "c: [6.127] prediksi harga: 21.09800095125319\n",
      "c: [6.474] prediksi harga: 24.256432767722764\n",
      "c: [6.229] prediksi harga: 22.026416067333585\n",
      "c: [6.195] prediksi harga: 21.716944361973454\n",
      "c: [6.715] prediksi harga: 26.450041032187215\n",
      "c: [5.913] prediksi harga: 19.150149629280612\n",
      "c: [6.092] prediksi harga: 20.779427136911877\n",
      "c: [6.254] prediksi harga: 22.253968791863088\n",
      "c: [5.928] prediksi harga: 19.28668126399831\n",
      "c: [6.176] prediksi harga: 21.544004291331028\n",
      "c: [6.021] prediksi harga: 20.133177399248076\n",
      "c: [5.872] prediksi harga: 18.776963161052215\n",
      "c: [5.731] prediksi harga: 17.493565794705788\n",
      "c: [5.87] prediksi harga: 18.758758943089852\n",
      "c: [6.004] prediksi harga: 19.978441546568014\n",
      "c: [5.961] prediksi harga: 19.587050860377268\n",
      "c: [5.856] prediksi harga: 18.631329417353328\n",
      "c: [5.879] prediksi harga: 18.840677923920474\n",
      "c: [5.986] prediksi harga: 19.81460358490677\n",
      "c: [5.613] prediksi harga: 16.41951693492652\n",
      "c: [5.693] prediksi harga: 17.147685653420936\n",
      "c: [6.431] prediksi harga: 23.86504208153201\n",
      "c: [5.637] prediksi harga: 16.63796755047484\n",
      "c: [6.458] prediksi harga: 24.110799024023876\n",
      "c: [6.326] prediksi harga: 22.90932063850807\n",
      "c: [6.372] prediksi harga: 23.32801765164237\n",
      "c: [5.822] prediksi harga: 18.321857711993196\n",
      "c: [5.757] prediksi harga: 17.73022062821648\n",
      "c: [6.335] prediksi harga: 22.9912396193387\n",
      "c: [5.942] prediksi harga: 19.414110789734835\n",
      "c: [6.454] prediksi harga: 24.07439058809915\n",
      "c: [5.857] prediksi harga: 18.64043152633451\n",
      "c: [6.151] prediksi harga: 21.31645156680152\n",
      "c: [6.174] prediksi harga: 21.52580007336867\n",
      "c: [5.019] prediksi harga: 11.012864200105412\n",
      "c: [5.403] prediksi harga: 14.508074048878647\n",
      "c: [5.468] prediksi harga: 15.099711132655372\n",
      "c: [4.903] prediksi harga: 9.957019558288493\n",
      "c: [6.13] prediksi harga: 21.125307278196736\n",
      "c: [5.628] prediksi harga: 16.55604856964422\n",
      "c: [4.926] prediksi harga: 10.166368064855646\n",
      "c: [5.186] prediksi harga: 12.532916399962524\n",
      "c: [5.597] prediksi harga: 16.273883191227632\n",
      "c: [6.122] prediksi harga: 21.05249040634729\n",
      "c: [5.404] prediksi harga: 14.51717615785983\n",
      "c: [5.012] prediksi harga: 10.949149437237146\n",
      "c: [5.709] prediksi harga: 17.293319397119824\n",
      "c: [6.129] prediksi harga: 21.116205169215547\n",
      "c: [6.152] prediksi harga: 21.3255536757827\n",
      "c: [5.272] prediksi harga: 13.31569777234403\n",
      "c: [6.943] prediksi harga: 28.525321879896318\n",
      "c: [6.066] prediksi harga: 20.542772303401193\n",
      "c: [6.51] prediksi harga: 24.58410869104525\n",
      "c: [6.25] prediksi harga: 22.217560355938375\n",
      "c: [7.489] prediksi harga: 33.49507338362078\n",
      "c: [7.802] prediksi harga: 36.34403349473021\n",
      "c: [8.375] prediksi harga: 41.55954194094653\n",
      "c: [5.854] prediksi harga: 18.61312519939097\n",
      "c: [6.101] prediksi harga: 20.861346117742507\n",
      "c: [7.929] prediksi harga: 37.500001335340116\n",
      "c: [5.877] prediksi harga: 18.822473705958117\n",
      "c: [6.319] prediksi harga: 22.845605875639812\n",
      "c: [6.402] prediksi harga: 23.60108092107778\n",
      "c: [5.875] prediksi harga: 18.804269487995754\n",
      "c: [5.88] prediksi harga: 18.849780032901656\n",
      "c: [5.572] prediksi harga: 16.046330466698123\n",
      "c: [6.416] prediksi harga: 23.728510446814305\n",
      "c: [5.859] prediksi harga: 18.658635744296873\n",
      "c: [6.546] prediksi harga: 24.911784614367747\n",
      "c: [6.02] prediksi harga: 20.124075290266894\n",
      "c: [6.315] prediksi harga: 22.809197439715092\n",
      "c: [6.86] prediksi harga: 27.769846834458363\n",
      "c: [6.98] prediksi harga: 28.8620999122\n",
      "c: [7.765] prediksi harga: 36.00725546242653\n",
      "c: [6.144] prediksi harga: 21.25273680393326\n",
      "c: [7.155] prediksi harga: 30.454968983906554\n",
      "c: [6.563] prediksi harga: 25.066520467047802\n",
      "c: [5.604] prediksi harga: 16.33759795409589\n",
      "c: [6.153] prediksi harga: 21.334655784763875\n",
      "c: [7.831] prediksi harga: 36.60799465518444\n",
      "c: [6.782] prediksi harga: 27.059882333926296\n",
      "c: [6.556] prediksi harga: 25.002805704179544\n",
      "c: [7.185] prediksi harga: 30.72803225334195\n",
      "c: [6.951] prediksi harga: 28.598138751745765\n",
      "c: [6.739] prediksi harga: 26.668491647735543\n",
      "c: [7.178] prediksi harga: 30.664317490473692\n",
      "c: [6.8] prediksi harga: 27.22372029558754\n",
      "c: [6.604] prediksi harga: 25.4397069352762\n",
      "c: [7.875] prediksi harga: 37.00848745035637\n",
      "c: [7.287] prediksi harga: 31.656447369422352\n",
      "c: [7.107] prediksi harga: 30.0180677528099\n",
      "c: [7.274] prediksi harga: 31.538119952667003\n",
      "c: [6.975] prediksi harga: 28.816589367294092\n",
      "c: [7.135] prediksi harga: 30.272926804282946\n",
      "c: [6.162] prediksi harga: 21.416574765594504\n",
      "c: [7.61] prediksi harga: 34.59642857034359\n",
      "c: [7.853] prediksi harga: 36.8082410527704\n",
      "c: [8.034] prediksi harga: 38.45572277836405\n",
      "c: [5.891] prediksi harga: 18.94990323169464\n",
      "c: [6.326] prediksi harga: 22.90932063850807\n",
      "c: [5.783] prediksi harga: 17.96687546172717\n",
      "c: [6.064] prediksi harga: 20.524568085438837\n",
      "c: [5.344] prediksi harga: 13.971049618989014\n",
      "c: [5.96] prediksi harga: 19.57794875139608\n",
      "c: [5.404] prediksi harga: 14.51717615785983\n",
      "c: [5.807] prediksi harga: 18.185326077275498\n",
      "c: [6.375] prediksi harga: 23.355323978585908\n",
      "c: [5.412] prediksi harga: 14.58999302970927\n",
      "c: [6.182] prediksi harga: 21.59861694521811\n",
      "c: [5.888] prediksi harga: 18.922596904751096\n",
      "c: [6.642] prediksi harga: 25.785587076561058\n",
      "c: [5.951] prediksi harga: 19.496029770565457\n",
      "c: [6.373] prediksi harga: 23.33711976062355\n",
      "c: [6.951] prediksi harga: 28.598138751745765\n",
      "c: [6.164] prediksi harga: 21.43477898355686\n",
      "c: [6.879] prediksi harga: 27.942786905100782\n",
      "c: [6.618] prediksi harga: 25.56713646101273\n",
      "c: [8.266] prediksi harga: 40.56741206199787\n",
      "c: [8.725] prediksi harga: 44.745280084359635\n",
      "c: [8.04] prediksi harga: 38.51033543225111\n",
      "c: [7.163] prediksi harga: 30.527785855755994\n",
      "c: [7.686] prediksi harga: 35.288188852913294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c: [6.552] prediksi harga: 24.966397268254823\n",
      "c: [5.981] prediksi harga: 19.769093040000868\n",
      "c: [7.412] prediksi harga: 32.79421099206989\n",
      "c: [8.337] prediksi harga: 41.213661799661665\n",
      "c: [8.247] prediksi harga: 40.394471991355445\n",
      "c: [6.726] prediksi harga: 26.5501642309802\n",
      "c: [6.086] prediksi harga: 20.7248144830248\n",
      "c: [6.631] prediksi harga: 25.685463877768072\n",
      "c: [7.358] prediksi harga: 32.302697107086146\n",
      "c: [6.481] prediksi harga: 24.320147530591022\n",
      "c: [6.606] prediksi harga: 25.457911153238562\n",
      "c: [6.897] prediksi harga: 28.106624866762033\n",
      "c: [6.095] prediksi harga: 20.806733463855423\n",
      "c: [6.358] prediksi harga: 23.20058812590584\n",
      "c: [6.393] prediksi harga: 23.51916194024715\n",
      "c: [5.593] prediksi harga: 16.237474755302905\n",
      "c: [5.605] prediksi harga: 16.346700063077073\n",
      "c: [6.108] prediksi harga: 20.925060880610765\n",
      "c: [6.226] prediksi harga: 21.999109740390047\n",
      "c: [6.433] prediksi harga: 23.883246299494367\n",
      "c: [6.718] prediksi harga: 26.477347359130754\n",
      "c: [6.487] prediksi harga: 24.374760184478106\n",
      "c: [6.438] prediksi harga: 23.92875684440027\n",
      "c: [6.957] prediksi harga: 28.65275140563285\n",
      "c: [8.259] prediksi harga: 40.50369729912961\n",
      "c: [6.108] prediksi harga: 20.925060880610765\n",
      "c: [5.876] prediksi harga: 18.813371596976936\n",
      "c: [7.454] prediksi harga: 33.17649956927946\n",
      "c: [8.704] prediksi harga: 44.554135795754846\n",
      "c: [7.333] prediksi harga: 32.075144382556644\n",
      "c: [6.842] prediksi harga: 27.606008872797112\n",
      "c: [7.203] prediksi harga: 30.89187021500321\n",
      "c: [7.52] prediksi harga: 33.777238762037356\n",
      "c: [8.398] prediksi harga: 41.76889044751367\n",
      "c: [7.327] prediksi harga: 32.02053172866957\n",
      "c: [7.206] prediksi harga: 30.919176541946754\n",
      "c: [5.56] prediksi harga: 15.937105158923956\n",
      "c: [7.014] prediksi harga: 29.171571617560126\n",
      "c: [8.297] prediksi harga: 40.849577440414464\n",
      "c: [7.47] prediksi harga: 33.32213331297834\n",
      "c: [5.92] prediksi harga: 19.21386439214887\n",
      "c: [5.856] prediksi harga: 18.631329417353328\n",
      "c: [6.24] prediksi harga: 22.12653926612657\n",
      "c: [6.538] prediksi harga: 24.8389677425183\n",
      "c: [7.691] prediksi harga: 35.33369939781919\n",
      "c: [6.758] prediksi harga: 26.84143171837797\n",
      "c: [6.854] prediksi harga: 27.71523418057128\n",
      "c: [7.267] prediksi harga: 31.474405189798745\n",
      "c: [6.826] prediksi harga: 27.460375129098225\n",
      "c: [6.482] prediksi harga: 24.329249639572204\n",
      "c: [6.812] prediksi harga: 27.332945603361708\n",
      "c: [7.82] prediksi harga: 36.507871456391456\n",
      "c: [6.968] prediksi harga: 28.752874604425834\n",
      "c: [7.645] prediksi harga: 34.9150023846849\n",
      "c: [7.923] prediksi harga: 37.445388681453025\n",
      "c: [7.088] prediksi harga: 29.845127682167472\n",
      "c: [6.453] prediksi harga: 24.065288479117974\n",
      "c: [6.23] prediksi harga: 22.035518176314767\n",
      "c: [6.209] prediksi harga: 21.844373887709978\n",
      "c: [6.315] prediksi harga: 22.809197439715092\n",
      "c: [6.565] prediksi harga: 25.084724685010173\n",
      "c: [6.861] prediksi harga: 27.778948943439538\n",
      "c: [7.148] prediksi harga: 30.39125422103828\n",
      "c: [6.63] prediksi harga: 25.67636176878689\n",
      "c: [6.127] prediksi harga: 21.09800095125319\n",
      "c: [6.009] prediksi harga: 20.023952091473923\n",
      "c: [6.678] prediksi harga: 26.113262999883545\n",
      "c: [6.549] prediksi harga: 24.939090941311285\n",
      "c: [5.79] prediksi harga: 18.03059022459543\n",
      "c: [6.345] prediksi harga: 23.082260709150496\n",
      "c: [7.041] prediksi harga: 29.417328560052\n",
      "c: [6.871] prediksi harga: 27.86997003325135\n",
      "c: [6.59] prediksi harga: 25.312277409539675\n",
      "c: [6.495] prediksi harga: 24.447577056327546\n",
      "c: [6.982] prediksi harga: 28.880304130162358\n",
      "c: [7.236] prediksi harga: 31.19223981138215\n",
      "c: [6.616] prediksi harga: 25.54893224305036\n",
      "c: [7.42] prediksi harga: 32.86702786391933\n",
      "c: [6.849] prediksi harga: 27.669723635665378\n",
      "c: [6.635] prediksi harga: 25.721872313692785\n",
      "c: [5.972] prediksi harga: 19.687174059170246\n",
      "c: [4.973] prediksi harga: 10.594167186971113\n",
      "c: [6.122] prediksi harga: 21.05249040634729\n",
      "c: [6.023] prediksi harga: 20.15138161721044\n",
      "c: [6.266] prediksi harga: 22.363194099637255\n",
      "c: [6.567] prediksi harga: 25.10292890297253\n",
      "c: [5.705] prediksi harga: 17.256910961195103\n",
      "c: [5.914] prediksi harga: 19.159251738261787\n",
      "c: [5.782] prediksi harga: 17.95777335274599\n",
      "c: [6.382] prediksi harga: 23.419038741454166\n",
      "c: [6.113] prediksi harga: 20.970571425516674\n",
      "c: [6.426] prediksi harga: 23.81953153662611\n",
      "c: [6.376] prediksi harga: 23.36442608756709\n",
      "c: [6.041] prediksi harga: 20.31521957887169\n",
      "c: [5.708] prediksi harga: 17.28421728813865\n",
      "c: [6.415] prediksi harga: 23.719408337833123\n",
      "c: [6.431] prediksi harga: 23.86504208153201\n",
      "c: [6.312] prediksi harga: 22.781891112771554\n",
      "c: [6.083] prediksi harga: 20.697508156081263\n",
      "c: [5.868] prediksi harga: 18.740554725127495\n",
      "c: [6.333] prediksi harga: 22.973035401376336\n",
      "c: [6.144] prediksi harga: 21.25273680393326\n",
      "c: [5.706] prediksi harga: 17.266013070176285\n",
      "c: [6.031] prediksi harga: 20.22419848905988\n",
      "c: [6.316] prediksi harga: 22.818299548696267\n",
      "c: [6.31] prediksi harga: 22.763686894809183\n",
      "c: [6.037] prediksi harga: 20.278811142946964\n",
      "c: [5.869] prediksi harga: 18.74965683410867\n",
      "c: [5.895] prediksi harga: 18.98631166761936\n",
      "c: [6.059] prediksi harga: 20.479057540532935\n",
      "c: [5.985] prediksi harga: 19.805501475925595\n",
      "c: [5.968] prediksi harga: 19.650765623245526\n",
      "c: [7.241] prediksi harga: 31.237750356288046\n",
      "c: [6.54] prediksi harga: 24.857171960480663\n",
      "c: [6.696] prediksi harga: 26.277100961544782\n",
      "c: [6.874] prediksi harga: 27.89727636019488\n",
      "c: [6.014] prediksi harga: 20.069462636379818\n",
      "c: [5.898] prediksi harga: 19.0136179945629\n",
      "c: [6.516] prediksi harga: 24.638721344932335\n",
      "c: [6.635] prediksi harga: 25.721872313692785\n",
      "c: [6.939] prediksi harga: 28.488913443971605\n",
      "c: [6.49] prediksi harga: 24.402066511421644\n",
      "c: [6.579] prediksi harga: 25.21215421074669\n",
      "c: [5.884] prediksi harga: 18.886188468826383\n",
      "c: [6.728] prediksi harga: 26.568368448942557\n",
      "c: [5.663] prediksi harga: 16.874622383985532\n",
      "c: [5.936] prediksi harga: 19.35949813584775\n",
      "c: [6.212] prediksi harga: 21.871680214653516\n",
      "c: [6.395] prediksi harga: 23.537366158209515\n",
      "c: [6.127] prediksi harga: 21.09800095125319\n",
      "c: [6.112] prediksi harga: 20.961469316535492\n",
      "c: [6.398] prediksi harga: 23.564672485153054\n",
      "c: [6.251] prediksi harga: 22.226662464919556\n",
      "c: [5.362] prediksi harga: 14.134887580650258\n",
      "c: [5.803] prediksi harga: 18.14891764135077\n",
      "c: [8.78] prediksi harga: 45.24589607832455\n",
      "c: [3.561] prediksi harga: -2.2580106944554785\n",
      "c: [4.963] prediksi harga: 10.503146097159316\n",
      "c: [3.863] prediksi harga: 0.49082621786097747\n",
      "c: [4.97] prediksi harga: 10.566860860027575\n",
      "c: [6.683] prediksi harga: 26.15877354478944\n",
      "c: [7.016] prediksi harga: 29.18977583552249\n",
      "c: [6.216] prediksi harga: 21.908088650578243\n",
      "c: [5.875] prediksi harga: 18.804269487995754\n",
      "c: [4.906] prediksi harga: 9.984325885232032\n",
      "c: [4.138] prediksi harga: 2.9939061876855604\n",
      "c: [7.313] prediksi harga: 31.893102202933036\n",
      "c: [6.649] prediksi harga: 25.849301839429316\n",
      "c: [6.794] prediksi harga: 27.169107641700457\n",
      "c: [6.38] prediksi harga: 23.40083452349181\n",
      "c: [6.223] prediksi harga: 21.9718034134465\n",
      "c: [6.968] prediksi harga: 28.752874604425834\n",
      "c: [6.545] prediksi harga: 24.902682505386558\n",
      "c: [5.536] prediksi harga: 15.718654543375628\n",
      "c: [5.52] prediksi harga: 15.57302079967674\n",
      "c: [4.368] prediksi harga: 5.087391253357033\n",
      "c: [5.277] prediksi harga: 13.361208317249933\n",
      "c: [4.652] prediksi harga: 7.672390204012238\n",
      "c: [5.] prediksi harga: 10.839924129462986\n",
      "c: [4.88] prediksi harga: 9.747671051721348\n",
      "c: [5.39] prediksi harga: 14.389746632123305\n",
      "c: [5.713] prediksi harga: 17.329727833044544\n",
      "c: [6.051] prediksi harga: 20.406240668683488\n",
      "c: [5.036] prediksi harga: 11.167600052785474\n",
      "c: [6.193] prediksi harga: 21.69874014401109\n",
      "c: [5.887] prediksi harga: 18.913494795769914\n",
      "c: [6.471] prediksi harga: 24.22912644077922\n",
      "c: [6.405] prediksi harga: 23.62838724802132\n",
      "c: [5.747] prediksi harga: 17.639199538404675\n",
      "c: [5.453] prediksi harga: 14.963179497937666\n",
      "c: [5.852] prediksi harga: 18.594920981428608\n",
      "c: [5.987] prediksi harga: 19.823705693887952\n",
      "c: [6.343] prediksi harga: 23.06405649118814\n",
      "c: [6.404] prediksi harga: 23.619285139040137\n",
      "c: [5.349] prediksi harga: 14.016560163894916\n",
      "c: [5.531] prediksi harga: 15.673143998469726\n",
      "c: [5.683] prediksi harga: 17.056664563609132\n",
      "c: [4.138] prediksi harga: 2.9939061876855604\n",
      "c: [5.608] prediksi harga: 16.37400639002061\n",
      "c: [5.617] prediksi harga: 16.455925370851233\n",
      "c: [6.852] prediksi harga: 27.697029962608916\n",
      "c: [5.757] prediksi harga: 17.73022062821648\n",
      "c: [6.657] prediksi harga: 25.922118711278756\n",
      "c: [4.628] prediksi harga: 7.453939588463911\n",
      "c: [5.155] prediksi harga: 12.250751021545938\n",
      "c: [4.519] prediksi harga: 6.461809709515258\n",
      "c: [6.434] prediksi harga: 23.89234840847555\n",
      "c: [6.782] prediksi harga: 27.059882333926296\n",
      "c: [5.304] prediksi harga: 13.606965259741806\n",
      "c: [5.957] prediksi harga: 19.55064242445254\n",
      "c: [6.824] prediksi harga: 27.442170911135868\n",
      "c: [6.411] prediksi harga: 23.682999901908396\n",
      "c: [6.006] prediksi harga: 19.996645764530378\n",
      "c: [5.648] prediksi harga: 16.738090749267826\n",
      "c: [6.103] prediksi harga: 20.879550335704863\n",
      "c: [5.565] prediksi harga: 15.982615703829865\n",
      "c: [5.896] prediksi harga: 18.995413776600543\n",
      "c: [5.837] prediksi harga: 18.458389346710902\n",
      "c: [6.202] prediksi harga: 21.78065912484172\n",
      "c: [6.193] prediksi harga: 21.69874014401109\n",
      "c: [6.38] prediksi harga: 23.40083452349181\n",
      "c: [6.348] prediksi harga: 23.10956703609404\n",
      "c: [6.833] prediksi harga: 27.52408989196649\n",
      "c: [6.425] prediksi harga: 23.810429427644927\n",
      "c: [6.436] prediksi harga: 23.910552626437905\n",
      "c: [6.208] prediksi harga: 21.835271778728803\n",
      "c: [6.629] prediksi harga: 25.6672596598057\n",
      "c: [6.461] prediksi harga: 24.13810535096742\n",
      "c: [6.152] prediksi harga: 21.3255536757827\n",
      "c: [5.935] prediksi harga: 19.35039602686657\n",
      "c: [5.627] prediksi harga: 16.546946460663037\n",
      "c: [5.818] prediksi harga: 18.285449276068476\n",
      "c: [6.406] prediksi harga: 23.637489357002494\n",
      "c: [6.219] prediksi harga: 21.93539497752178\n",
      "c: [6.485] prediksi harga: 24.35655596651575\n",
      "c: [5.854] prediksi harga: 18.61312519939097\n",
      "c: [6.459] prediksi harga: 24.11990113300505\n",
      "c: [6.341] prediksi harga: 23.045852273225783\n",
      "c: [6.251] prediksi harga: 22.226662464919556\n",
      "c: [6.185] prediksi harga: 21.62592327216165\n",
      "c: [6.417] prediksi harga: 23.73761255579548\n",
      "c: [6.749] prediksi harga: 26.75951273754734\n",
      "c: [6.655] prediksi harga: 25.9039144933164\n",
      "c: [6.297] prediksi harga: 22.64535947805384\n",
      "c: [7.393] prediksi harga: 32.62127092142747\n",
      "c: [6.728] prediksi harga: 26.568368448942557\n",
      "c: [6.525] prediksi harga: 24.720640325762957\n",
      "c: [5.976] prediksi harga: 19.723582495094966\n",
      "c: [5.936] prediksi harga: 19.35949813584775\n",
      "c: [6.301] prediksi harga: 22.681767913978568\n",
      "c: [6.081] prediksi harga: 20.679303938118906\n",
      "c: [6.701] prediksi harga: 26.322611506450684\n",
      "c: [6.376] prediksi harga: 23.36442608756709\n",
      "c: [6.317] prediksi harga: 22.827401657677456\n",
      "c: [6.513] prediksi harga: 24.61141501798879\n",
      "c: [6.209] prediksi harga: 21.844373887709978\n",
      "c: [5.759] prediksi harga: 17.748424846178843\n",
      "c: [5.952] prediksi harga: 19.50513187954664\n",
      "c: [6.003] prediksi harga: 19.96933943758684\n",
      "c: [5.926] prediksi harga: 19.268477046035954\n",
      "c: [5.713] prediksi harga: 17.329727833044544\n",
      "c: [6.167] prediksi harga: 21.462085310500406\n",
      "c: [6.229] prediksi harga: 22.026416067333585\n",
      "c: [6.437] prediksi harga: 23.919654735419094\n",
      "c: [6.98] prediksi harga: 28.8620999122\n",
      "c: [5.427] prediksi harga: 14.726524664426975\n",
      "c: [6.162] prediksi harga: 21.416574765594504\n",
      "c: [6.484] prediksi harga: 24.34745385753456\n",
      "c: [5.304] prediksi harga: 13.606965259741806\n",
      "c: [6.185] prediksi harga: 21.62592327216165\n",
      "c: [6.229] prediksi harga: 22.026416067333585\n",
      "c: [6.242] prediksi harga: 22.144743484088927\n",
      "c: [6.75] prediksi harga: 26.76861484652852\n",
      "c: [7.061] prediksi harga: 29.599370739675607\n",
      "c: [5.762] prediksi harga: 17.775731173122374\n",
      "c: [5.871] prediksi harga: 18.76786105207104\n",
      "c: [6.312] prediksi harga: 22.781891112771554\n",
      "c: [6.114] prediksi harga: 20.97967353449785\n",
      "c: [5.905] prediksi harga: 19.077332757431165\n",
      "c: [5.454] prediksi harga: 14.972281606918841\n",
      "c: [5.414] prediksi harga: 14.608197247671633\n",
      "c: [5.093] prediksi harga: 11.686420264712751\n",
      "c: [5.983] prediksi harga: 19.787297257963225\n",
      "c: [5.983] prediksi harga: 19.787297257963225\n",
      "c: [5.707] prediksi harga: 17.27511517915746\n",
      "c: [5.926] prediksi harga: 19.268477046035954\n",
      "c: [5.67] prediksi harga: 16.93833714685379\n",
      "c: [5.39] prediksi harga: 14.389746632123305\n",
      "c: [5.794] prediksi harga: 18.06699866052015\n",
      "c: [6.019] prediksi harga: 20.11497318128572\n",
      "c: [5.569] prediksi harga: 16.019024139754578\n",
      "c: [6.027] prediksi harga: 20.187790053135167\n",
      "c: [6.593] prediksi harga: 25.339583736483213\n",
      "c: [6.12] prediksi harga: 21.034286188384932\n",
      "c: [6.976] prediksi harga: 28.825691476275274\n",
      "c: [6.794] prediksi harga: 27.169107641700457\n",
      "c: [6.03] prediksi harga: 20.215096380078705\n"
     ]
    }
   ],
   "source": [
    "for RM_Jumlah_Kamar, hrg in zip(RM_Jumlah_Kamar, prediksi_harga):\n",
    "    print(f'c: {RM_Jumlah_Kamar} prediksi harga: {hrg}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Evaluasi Simple Linear Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "#### Training & Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(boston_df[['RM']]).reshape(-1, 1)\n",
    "y_train = np.array(boston_df[['Price']])\n",
    "\n",
    "\n",
    "X_test = np.array(boston_df[['RM']]).reshape(-1, 1)\n",
    "y_test = np.array(boston_df[['Price']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**TRAINING SET**\n",
    "- **X_train = np.array(boston_df_knn[['RM']]).reshape(-1, 1)** `Features` dengan `reshape` bernilai (-1, 1)\n",
    "- **y_train = np.array(boston_df_knn[['Price']])** `Target` dengan nilai array([Price])\n",
    "\n",
    "**TESTING SET**\n",
    "- X_test = np.array(boston_df[['RM']]).reshape(-1, 1)\n",
    "- y_test = np.array(boston_df[['Price']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Simple Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluasi Linear Regression Model dengan Coefficient of Determination atau R-squared ($R^2$)\n",
    "\n",
    "`Coefficient of Determination`, denoted R2 or r2 and pronounced \"R squared\", is the proportion of the variance in the dependent variable that is predictable from the independent variable(s).\n",
    "\n",
    "It is a statistic used in the context of statistical models whose main purpose is either the prediction of future outcomes or the testing of hypotheses, on the basis of other related information. It provides a measure of how well observed outcomes are replicated by the model, based on the proportion of total variation of outcomes explained by the model.[1][2][3]\n",
    "\n",
    "There are several definitions of R2 that are only sometimes equivalent. One class of such cases includes that of simple linear regression where r2 is used instead of R2. When an intercept is included, then r2 is simply the square of the sample correlation coefficient (i.e., r) between the observed outcomes and the observed predictor values.[4] If additional regressors are included, R2 is the square of the coefficient of multiple correlation. In both such cases, the coefficient of determination normally ranges from 0 to 1.\n",
    "\n",
    "Referensi: [https://en.wikipedia.org/wiki/Coefficient_of_determination](https://en.wikipedia.org/wiki/Coefficient_of_determination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.48352545599133423\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "r_squared = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'R-squared: {r_squared}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Sebelum melakukan **Coefficient of Determination atau R-squared ( 𝑅2 )**  terlebih dahulu kita melakukan import dengan `from sklearn.metrics import r2_score` dengan 2 variabel berikut :\n",
    "\n",
    "- `y_pred = model.predict(X_test)` untuk melakukan prediksi dengan variabel `y_pred` dengan parameter `X-test` dari `model.predict`\n",
    "\n",
    "- `r_squared = r2_score(y_test, y_pred)` jika hasilnya mendekati angka 1 maka akan lebih baik, sebaliknya jika nilai yang dihasilkan mendekati nilai 0 maka makin buruk.\n",
    "\n",
    "print(f'R-squared: {r_squared}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Mencari nilai R-squared ($R^2$)\n",
    "\n",
    "R-squared (R2) is a statistical measure that represents the proportion of the variance for a dependent variable that's explained by an independent variable or variables in a regression model. Whereas correlation explains the strength of the relationship between an independent and dependent variable, R-squared explains to what extent the variance of one variable explains the variance of the second variable. So, if the R2 of a model is 0.50, then approximately half of the observed variation can be explained by the model's inputs.\n",
    "\n",
    "\n",
    "$R^{2} = 1 - \\frac{SS_{res}}{SS_{tot}}$\n",
    "\n",
    "\n",
    "$SS_{res} =  \\sum_{i=1}^{n}(y_i - f(x_i))^2$\n",
    "\n",
    "\n",
    "$SS_{tot} =  \\sum_{i=1}^{n}(y_i - \\bar{y})^2$\n",
    "\n",
    "\n",
    "Referensi : https://www.investopedia.com/terms/r/r-squared.asp#:~:text=R%2Dsquared%20(R2),variables%20in%20a%20regression%20model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $SS_{res}$\n",
    "\n",
    "`Residual Sum of Squares (RSS)`, also known as the sum of squared residuals (SSR) or the sum of squared estimate of errors (SSE), is the sum of the squares of residuals (deviations predicted from actual empirical values of data). It is a measure of the discrepancy between the data and an estimation model, such as a linear regression. A small RSS indicates a tight fit of the model to the data. It is used as an optimality criterion in parameter selection and model selection.\n",
    "\n",
    "\n",
    "$SS_{res} =  \\sum_{i=1}^{n}(y_i - f(x_i))^2$\n",
    "\n",
    "\n",
    "\n",
    "Referensi : https://en.wikipedia.org/wiki/Residual_sum_of_squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ss_res: [22061.87919621]\n"
     ]
    }
   ],
   "source": [
    "ss_res = sum([(y_i - model.predict(x_i.reshape(-1, 1))[0])**2\n",
    "              for x_i, y_i in zip(X_test, y_test)])\n",
    "\n",
    "print(f'ss_res: {ss_res}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $SS_{tot}$\n",
    "\n",
    "total sum of squares (TSS or SST) is a quantity that appears as part of a standard way of presenting results of such analyses. For a set of observations {\\displaystyle y_{i},i\\leq n}{\\displaystyle y_{i},i\\leq n}, it is defined as the sum over all squared differences between the observations and their overall mean\n",
    "\n",
    "$SS_{tot} =  \\sum_{i=1}^{n}(y_i - \\bar{y})^2$\n",
    "\n",
    "\n",
    "Referensi : https://en.wikipedia.org/wiki/Total_sum_of_squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ss_tot: [42716.29541502]\n"
     ]
    }
   ],
   "source": [
    "mean_y = np.mean(y_test)\n",
    "ss_tot = sum([(y_i - mean_y)**2 for y_i in y_test])\n",
    "\n",
    "print(f'ss_tot: {ss_tot}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $R^2$\n",
    "\n",
    "R-squared (R2) is a statistical measure that represents the proportion of the variance for a dependent variable that's explained by an independent variable or variables in a regression model. Whereas correlation explains the strength of the relationship between an independent and dependent variable, R-squared explains to what extent the variance of one variable explains the variance of the second variable. So, if the R2 of a model is 0.50, then approximately half of the observed variation can be explained by the model's inputs.\n",
    "\n",
    "$R^{2} = 1 - \\frac{SS_{res}}{SS_{tot}}$\n",
    "\n",
    "\n",
    "Referensi : https://www.investopedia.com/terms/r/r-squared.asp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: [0.48352546]\n"
     ]
    }
   ],
   "source": [
    "r_squared = 1 - (ss_res / ss_tot)\n",
    "\n",
    "print(f'R-squared: {r_squared}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 02 Multiple Linear Regression\n",
    "\n",
    "**Multiple Linear Regression** merupakan salah satu pengembangan dari `Simple Linear Regression`.\n",
    "\n",
    "- **`Multiple Linear Regression`** bertujuan untuk mengestimasi hubungan antara dua atau lebih variabel `independen` dan satu variabel `dependen` serta digunakan jika ingin mengetahui seberapa kuat hubungan antara dua atau lebih variabel `independen` dan satu variabel `dependen` (Misalnya curah hujan, suhu, dll).\n",
    "Referensi : https://www.scribbr.com/statistics/multiple-linear-regression/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Pilihan Features\n",
    "\n",
    "Pada kasus kali ini memilih **`RM`** (Jumlah Kamar Rumah) dan **`AGE`** (Usia) sebagai Features, dan **`Price`** (Harga) sebagai Target. Pemilihan tersebut dikarenakan banyaknya permintaan umum seperti Jumlah Kamar dan Usia yang menempati rumah, maka permintaan tersebut akan sangat memengaruhi Price (Harga) yang di tentukan dari Sample Dataset.\n",
    "\n",
    "Untuk Keterangan yang dipilih adalah sebagai berikut :\n",
    "- **RM** adalah Jumlah kamar setiap rumah sebagai **`Features`**.\n",
    "- **AGE** adalah Usia dari setiap rumah sebagai **`Features`**.\n",
    "- **Price** adalah harga sebagai **`Target`**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n",
       "         4.9800e+00],\n",
       "        [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n",
       "         9.1400e+00],\n",
       "        [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n",
       "         4.0300e+00],\n",
       "        ...,\n",
       "        [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "         5.6400e+00],\n",
       "        [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n",
       "         6.4800e+00],\n",
       "        [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "         7.8800e+00]]),\n",
       " 'target': array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
       "        18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
       "        15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
       "        13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
       "        21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
       "        35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
       "        19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
       "        20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
       "        23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
       "        33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
       "        21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
       "        20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
       "        23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
       "        15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
       "        17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
       "        25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
       "        23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
       "        32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
       "        34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
       "        20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
       "        26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
       "        31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
       "        22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
       "        42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
       "        36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
       "        32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
       "        20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
       "        20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
       "        22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
       "        21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
       "        19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
       "        32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
       "        18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
       "        16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
       "        13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
       "         7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
       "        12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
       "        27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
       "         8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
       "         9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
       "        10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
       "        15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
       "        19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
       "        29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
       "        20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
       "        23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9]),\n",
       " 'feature_names': array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
       "        'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='<U7'),\n",
       " 'DESCR': \".. _boston_dataset:\\n\\nBoston house prices dataset\\n---------------------------\\n\\n**Data Set Characteristics:**  \\n\\n    :Number of Instances: 506 \\n\\n    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\\n\\n    :Attribute Information (in order):\\n        - CRIM     per capita crime rate by town\\n        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\\n        - INDUS    proportion of non-retail business acres per town\\n        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\\n        - NOX      nitric oxides concentration (parts per 10 million)\\n        - RM       average number of rooms per dwelling\\n        - AGE      proportion of owner-occupied units built prior to 1940\\n        - DIS      weighted distances to five Boston employment centres\\n        - RAD      index of accessibility to radial highways\\n        - TAX      full-value property-tax rate per $10,000\\n        - PTRATIO  pupil-teacher ratio by town\\n        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\\n        - LSTAT    % lower status of the population\\n        - MEDV     Median value of owner-occupied homes in $1000's\\n\\n    :Missing Attribute Values: None\\n\\n    :Creator: Harrison, D. and Rubinfeld, D.L.\\n\\nThis is a copy of UCI ML housing dataset.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/housing/\\n\\n\\nThis dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\\n\\nThe Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\\nprices and the demand for clean air', J. Environ. Economics & Management,\\nvol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\\n...', Wiley, 1980.   N.B. Various transformations are used in the table on\\npages 244-261 of the latter.\\n\\nThe Boston house-price data has been used in many machine learning papers that address regression\\nproblems.   \\n     \\n.. topic:: References\\n\\n   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\\n   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\\n\",\n",
       " 'filename': 'C:\\\\Users\\\\User\\\\anaconda3\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\boston_house_prices.csv'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston_dataset = load_boston()\n",
    "\n",
    "boston_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...    ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786  1.0  273.0   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875  1.0  273.0   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675  1.0  273.0   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889  1.0  273.0   \n",
       "505  0.04741   0.0  11.93   0.0  0.573  6.030  80.8  2.5050  1.0  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  \n",
       "0       15.3  396.90   4.98  \n",
       "1       17.8  396.90   9.14  \n",
       "2       17.8  392.83   4.03  \n",
       "3       18.7  394.63   2.94  \n",
       "4       18.7  396.90   5.33  \n",
       "..       ...     ...    ...  \n",
       "501     21.0  391.99   9.67  \n",
       "502     21.0  396.90   9.08  \n",
       "503     21.0  396.90   5.64  \n",
       "504     21.0  393.45   6.48  \n",
       "505     21.0  396.90   7.88  \n",
       "\n",
       "[506 rows x 13 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "boston_df = pd.DataFrame(boston_dataset.data, columns=boston_dataset.feature_names)\n",
    "boston_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...    ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786  1.0  273.0   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875  1.0  273.0   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675  1.0  273.0   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889  1.0  273.0   \n",
       "505  0.04741   0.0  11.93   0.0  0.573  6.030  80.8  2.5050  1.0  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  Price  \n",
       "0       15.3  396.90   4.98   24.0  \n",
       "1       17.8  396.90   9.14   21.6  \n",
       "2       17.8  392.83   4.03   34.7  \n",
       "3       18.7  394.63   2.94   33.4  \n",
       "4       18.7  396.90   5.33   36.2  \n",
       "..       ...     ...    ...    ...  \n",
       "501     21.0  391.99   9.67   22.4  \n",
       "502     21.0  396.90   9.08   20.6  \n",
       "503     21.0  396.90   5.64   23.9  \n",
       "504     21.0  393.45   6.48   22.0  \n",
       "505     21.0  396.90   7.88   11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_df['Price'] = boston_dataset.target\n",
    "boston_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Selanjutnya kita juga dapat mengambil dan menampilkan hanya beberapa dataset yang tersedia seperti script dibawah ini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        RM   AGE  Price\n",
       "0    6.575  65.2   24.0\n",
       "1    6.421  78.9   21.6\n",
       "2    7.185  61.1   34.7\n",
       "3    6.998  45.8   33.4\n",
       "4    7.147  54.2   36.2\n",
       "..     ...   ...    ...\n",
       "501  6.593  69.1   22.4\n",
       "502  6.120  76.7   20.6\n",
       "503  6.976  91.0   23.9\n",
       "504  6.794  89.3   22.0\n",
       "505  6.030  80.8   11.9\n",
       "\n",
       "[506 rows x 3 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_df[[\"RM\",\"AGE\", \"Price\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing Dataset\n",
    "\n",
    "**Testing set** digunakan untuk mengukur sejauh mana classifier berhasil melakukan klasifikasi dengan benar. Karena itu, data yang ada pada testing set seharusnya tidak boleh ada pada training set sehingga dapat diketahui apakah model classifier sudah “pintar” dalam melakukan klasifikasi. Selanjutnya kita melakukan hal yang sama pada `Training Dataset` dengan `Testing Dataset`, hanya sedikit berbeda dengan nilai parameter yang dimiliki.\n",
    "\n",
    "Sample Dataset yang digunakan adalah `boston_dataset` sebagai variabel dengan format pandas `DataFrame` yang terdiri dari 3 buah `keys` sebagai berikut :\n",
    "- `RM` dan `AGE` sebagai **Features**\n",
    "- `Price` sebagai **Target**\n",
    "\n",
    "Referensi : https://philips.wordpress.com/2006/08/10/training-set-testing-set-dan-validation-set/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Preprocessing Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Tahap `Preprocessing Dataset` kita perlu untuk melakukan import module dengan `import numpy as np` yang ditampung ke dalam array sebagai `np.array` dengan keterangan berikut :\n",
    "\n",
    "- `X_train = np.array(boston_df[['RM', 'AGE']])` Variabel `X_train` sebagai sekumpulan nilai Features untuk **Training Set** berisikan `RM` dan `AGE`. Kemudian untuk bagian ini akan menampilkan `numpy array` 2 dimensi.\n",
    "\n",
    "- `y_train = np.array(boston_df['Price'])` Variabel `y_train` sebagai sekumpulan nilai Target untuk **Training Set**. Kemudian untuk bagian ini akan menampilkan `numpy array` 1 dimensi.\n",
    "\n",
    "\n",
    "Untuk Keterangan yang dipilih adalah sebagai berikut :\n",
    "- **RM** adalah Jumlah kamar setiap rumah sebagai **`Features`**.\n",
    "- **AGE** adalah Usia dari setiap rumah sebagai **`Features`**.\n",
    "- **Price** adalah harga sebagai **`Target`**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:\n",
      "[[ 6.575 65.2  ]\n",
      " [ 6.421 78.9  ]\n",
      " [ 7.185 61.1  ]\n",
      " ...\n",
      " [ 6.976 91.   ]\n",
      " [ 6.794 89.3  ]\n",
      " [ 6.03  80.8  ]]\n",
      "\n",
      "y_train: [24.  21.6 34.7 33.4 36.2 28.7 22.9 27.1 16.5 18.9 15.  18.9 21.7 20.4\n",
      " 18.2 19.9 23.1 17.5 20.2 18.2 13.6 19.6 15.2 14.5 15.6 13.9 16.6 14.8\n",
      " 18.4 21.  12.7 14.5 13.2 13.1 13.5 18.9 20.  21.  24.7 30.8 34.9 26.6\n",
      " 25.3 24.7 21.2 19.3 20.  16.6 14.4 19.4 19.7 20.5 25.  23.4 18.9 35.4\n",
      " 24.7 31.6 23.3 19.6 18.7 16.  22.2 25.  33.  23.5 19.4 22.  17.4 20.9\n",
      " 24.2 21.7 22.8 23.4 24.1 21.4 20.  20.8 21.2 20.3 28.  23.9 24.8 22.9\n",
      " 23.9 26.6 22.5 22.2 23.6 28.7 22.6 22.  22.9 25.  20.6 28.4 21.4 38.7\n",
      " 43.8 33.2 27.5 26.5 18.6 19.3 20.1 19.5 19.5 20.4 19.8 19.4 21.7 22.8\n",
      " 18.8 18.7 18.5 18.3 21.2 19.2 20.4 19.3 22.  20.3 20.5 17.3 18.8 21.4\n",
      " 15.7 16.2 18.  14.3 19.2 19.6 23.  18.4 15.6 18.1 17.4 17.1 13.3 17.8\n",
      " 14.  14.4 13.4 15.6 11.8 13.8 15.6 14.6 17.8 15.4 21.5 19.6 15.3 19.4\n",
      " 17.  15.6 13.1 41.3 24.3 23.3 27.  50.  50.  50.  22.7 25.  50.  23.8\n",
      " 23.8 22.3 17.4 19.1 23.1 23.6 22.6 29.4 23.2 24.6 29.9 37.2 39.8 36.2\n",
      " 37.9 32.5 26.4 29.6 50.  32.  29.8 34.9 37.  30.5 36.4 31.1 29.1 50.\n",
      " 33.3 30.3 34.6 34.9 32.9 24.1 42.3 48.5 50.  22.6 24.4 22.5 24.4 20.\n",
      " 21.7 19.3 22.4 28.1 23.7 25.  23.3 28.7 21.5 23.  26.7 21.7 27.5 30.1\n",
      " 44.8 50.  37.6 31.6 46.7 31.5 24.3 31.7 41.7 48.3 29.  24.  25.1 31.5\n",
      " 23.7 23.3 22.  20.1 22.2 23.7 17.6 18.5 24.3 20.5 24.5 26.2 24.4 24.8\n",
      " 29.6 42.8 21.9 20.9 44.  50.  36.  30.1 33.8 43.1 48.8 31.  36.5 22.8\n",
      " 30.7 50.  43.5 20.7 21.1 25.2 24.4 35.2 32.4 32.  33.2 33.1 29.1 35.1\n",
      " 45.4 35.4 46.  50.  32.2 22.  20.1 23.2 22.3 24.8 28.5 37.3 27.9 23.9\n",
      " 21.7 28.6 27.1 20.3 22.5 29.  24.8 22.  26.4 33.1 36.1 28.4 33.4 28.2\n",
      " 22.8 20.3 16.1 22.1 19.4 21.6 23.8 16.2 17.8 19.8 23.1 21.  23.8 23.1\n",
      " 20.4 18.5 25.  24.6 23.  22.2 19.3 22.6 19.8 17.1 19.4 22.2 20.7 21.1\n",
      " 19.5 18.5 20.6 19.  18.7 32.7 16.5 23.9 31.2 17.5 17.2 23.1 24.5 26.6\n",
      " 22.9 24.1 18.6 30.1 18.2 20.6 17.8 21.7 22.7 22.6 25.  19.9 20.8 16.8\n",
      " 21.9 27.5 21.9 23.1 50.  50.  50.  50.  50.  13.8 13.8 15.  13.9 13.3\n",
      " 13.1 10.2 10.4 10.9 11.3 12.3  8.8  7.2 10.5  7.4 10.2 11.5 15.1 23.2\n",
      "  9.7 13.8 12.7 13.1 12.5  8.5  5.   6.3  5.6  7.2 12.1  8.3  8.5  5.\n",
      " 11.9 27.9 17.2 27.5 15.  17.2 17.9 16.3  7.   7.2  7.5 10.4  8.8  8.4\n",
      " 16.7 14.2 20.8 13.4 11.7  8.3 10.2 10.9 11.   9.5 14.5 14.1 16.1 14.3\n",
      " 11.7 13.4  9.6  8.7  8.4 12.8 10.5 17.1 18.4 15.4 10.8 11.8 14.9 12.6\n",
      " 14.1 13.  13.4 15.2 16.1 17.8 14.9 14.1 12.7 13.5 14.9 20.  16.4 17.7\n",
      " 19.5 20.2 21.4 19.9 19.  19.1 19.1 20.1 19.9 19.6 23.2 29.8 13.8 13.3\n",
      " 16.7 12.  14.6 21.4 23.  23.7 25.  21.8 20.6 21.2 19.1 20.6 15.2  7.\n",
      "  8.1 13.6 20.1 21.8 24.5 23.1 19.7 18.3 21.2 17.5 16.8 22.4 20.6 23.9\n",
      " 22.  11.9]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train = np.array(boston_df[['RM', 'AGE']])\n",
    "y_train = np.array(boston_df['Price'])\n",
    "\n",
    "print(f'X_train:\\n{X_train}\\n')\n",
    "print(f'y_train: {y_train}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test:\n",
      "[[ 6.575 65.2  ]\n",
      " [ 6.421 78.9  ]\n",
      " [ 7.185 61.1  ]\n",
      " ...\n",
      " [ 6.976 91.   ]\n",
      " [ 6.794 89.3  ]\n",
      " [ 6.03  80.8  ]]\n",
      "\n",
      "y_test: [24.  21.6 34.7 33.4 36.2 28.7 22.9 27.1 16.5 18.9 15.  18.9 21.7 20.4\n",
      " 18.2 19.9 23.1 17.5 20.2 18.2 13.6 19.6 15.2 14.5 15.6 13.9 16.6 14.8\n",
      " 18.4 21.  12.7 14.5 13.2 13.1 13.5 18.9 20.  21.  24.7 30.8 34.9 26.6\n",
      " 25.3 24.7 21.2 19.3 20.  16.6 14.4 19.4 19.7 20.5 25.  23.4 18.9 35.4\n",
      " 24.7 31.6 23.3 19.6 18.7 16.  22.2 25.  33.  23.5 19.4 22.  17.4 20.9\n",
      " 24.2 21.7 22.8 23.4 24.1 21.4 20.  20.8 21.2 20.3 28.  23.9 24.8 22.9\n",
      " 23.9 26.6 22.5 22.2 23.6 28.7 22.6 22.  22.9 25.  20.6 28.4 21.4 38.7\n",
      " 43.8 33.2 27.5 26.5 18.6 19.3 20.1 19.5 19.5 20.4 19.8 19.4 21.7 22.8\n",
      " 18.8 18.7 18.5 18.3 21.2 19.2 20.4 19.3 22.  20.3 20.5 17.3 18.8 21.4\n",
      " 15.7 16.2 18.  14.3 19.2 19.6 23.  18.4 15.6 18.1 17.4 17.1 13.3 17.8\n",
      " 14.  14.4 13.4 15.6 11.8 13.8 15.6 14.6 17.8 15.4 21.5 19.6 15.3 19.4\n",
      " 17.  15.6 13.1 41.3 24.3 23.3 27.  50.  50.  50.  22.7 25.  50.  23.8\n",
      " 23.8 22.3 17.4 19.1 23.1 23.6 22.6 29.4 23.2 24.6 29.9 37.2 39.8 36.2\n",
      " 37.9 32.5 26.4 29.6 50.  32.  29.8 34.9 37.  30.5 36.4 31.1 29.1 50.\n",
      " 33.3 30.3 34.6 34.9 32.9 24.1 42.3 48.5 50.  22.6 24.4 22.5 24.4 20.\n",
      " 21.7 19.3 22.4 28.1 23.7 25.  23.3 28.7 21.5 23.  26.7 21.7 27.5 30.1\n",
      " 44.8 50.  37.6 31.6 46.7 31.5 24.3 31.7 41.7 48.3 29.  24.  25.1 31.5\n",
      " 23.7 23.3 22.  20.1 22.2 23.7 17.6 18.5 24.3 20.5 24.5 26.2 24.4 24.8\n",
      " 29.6 42.8 21.9 20.9 44.  50.  36.  30.1 33.8 43.1 48.8 31.  36.5 22.8\n",
      " 30.7 50.  43.5 20.7 21.1 25.2 24.4 35.2 32.4 32.  33.2 33.1 29.1 35.1\n",
      " 45.4 35.4 46.  50.  32.2 22.  20.1 23.2 22.3 24.8 28.5 37.3 27.9 23.9\n",
      " 21.7 28.6 27.1 20.3 22.5 29.  24.8 22.  26.4 33.1 36.1 28.4 33.4 28.2\n",
      " 22.8 20.3 16.1 22.1 19.4 21.6 23.8 16.2 17.8 19.8 23.1 21.  23.8 23.1\n",
      " 20.4 18.5 25.  24.6 23.  22.2 19.3 22.6 19.8 17.1 19.4 22.2 20.7 21.1\n",
      " 19.5 18.5 20.6 19.  18.7 32.7 16.5 23.9 31.2 17.5 17.2 23.1 24.5 26.6\n",
      " 22.9 24.1 18.6 30.1 18.2 20.6 17.8 21.7 22.7 22.6 25.  19.9 20.8 16.8\n",
      " 21.9 27.5 21.9 23.1 50.  50.  50.  50.  50.  13.8 13.8 15.  13.9 13.3\n",
      " 13.1 10.2 10.4 10.9 11.3 12.3  8.8  7.2 10.5  7.4 10.2 11.5 15.1 23.2\n",
      "  9.7 13.8 12.7 13.1 12.5  8.5  5.   6.3  5.6  7.2 12.1  8.3  8.5  5.\n",
      " 11.9 27.9 17.2 27.5 15.  17.2 17.9 16.3  7.   7.2  7.5 10.4  8.8  8.4\n",
      " 16.7 14.2 20.8 13.4 11.7  8.3 10.2 10.9 11.   9.5 14.5 14.1 16.1 14.3\n",
      " 11.7 13.4  9.6  8.7  8.4 12.8 10.5 17.1 18.4 15.4 10.8 11.8 14.9 12.6\n",
      " 14.1 13.  13.4 15.2 16.1 17.8 14.9 14.1 12.7 13.5 14.9 20.  16.4 17.7\n",
      " 19.5 20.2 21.4 19.9 19.  19.1 19.1 20.1 19.9 19.6 23.2 29.8 13.8 13.3\n",
      " 16.7 12.  14.6 21.4 23.  23.7 25.  21.8 20.6 21.2 19.1 20.6 15.2  7.\n",
      "  8.1 13.6 20.1 21.8 24.5 23.1 19.7 18.3 21.2 17.5 16.8 22.4 20.6 23.9\n",
      " 22.  11.9]\n"
     ]
    }
   ],
   "source": [
    "X_test = np.array(boston_df[['RM', 'AGE']])\n",
    "y_test = np.array(boston_df['Price'])\n",
    "\n",
    "print(f'X_test:\\n{X_test}\\n')\n",
    "print(f'y_test: {y_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Multiple Linear Regression \n",
    "\n",
    "Linear Regression adalah pendekatan linier untuk memodelkan hubungan antara respons skalar dan satu atau lebih variabel penjelas (juga dikenal sebagai variabel dependen dan independen). Kasus satu variabel penjelas disebut `Simple Linear Regression`; untuk lebih dari satu, proses tersebut disebut `Multiple Linear Regression`. Istilah ini berbeda dari regresi linier multivariat, di mana beberapa variabel dependen yang berkorelasi diprediksi, daripada variabel skalar tunggal.\n",
    "\n",
    "**Multiple Linear Regression** merupakan generalisasi dari Simple Linear Regression yang memungkinkan untuk menggunakan beberapa explanatory variables.\n",
    "\n",
    "$y = \\alpha + \\beta_1x_1 + \\beta_2x_2 + \\dots + \\beta_nx_n$\n",
    "\n",
    "Referensi: [https://en.wikipedia.org/wiki/Linear_regression](https://en.wikipedia.org/wiki/Linear_regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Pada tahap `Multiple Linear Regression` ini pertama-tama kita untuk melakukan import module dengan `from sklearn.linear_model import LinearRegression` dan import metrics dengan `from sklearn.metrics import r2_score` yang berisikan keterangan sebagai berikut :\n",
    "\n",
    "- `model = LinearRegression()` memanggil `LinearRegression()` ditampung ke dalam variabel `model`.\n",
    "- `model.fit(X_train, y_train)` sebagai training model dengan 2 parameter yaitu `X_train` dan `y_train`.\n",
    "- `y_pred = model.predict(X_test)` sebagai prediksi model dari testing set dengan parameter `X_test` yang ditampung ke dalam variabel `y_pred`\n",
    "- `print(f'r_squared: {r2_score(y_test, y_pred)}')` sebagai pengukur performa model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r_squared: 0.5302754804141959\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "    \n",
    "print(f'r_squared: {r2_score(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Pada tahapan diatas dapat dikatakan bahwa sebenarnya tidak ada perbedaan antara implementasi `Simple Linear Regression` dengan `Multiple Linear Regression`, hanya saja perbedaannya adalah pada jumlah `Feature` yang dilewatkan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 03 Polynomial Regression\n",
    "\n",
    "**Polynomial Regression** merupakan salah satu pengembangan dari `Simple Linear Regression`.\n",
    "\n",
    "- **`Polynomial Regression`** bertujuan untuk mengetahui apakah kumpulan data yang berkorelasi tetapi hubungannya tidak terlihat linear, akan tetapi bergantung pada jenis apa data yang dimiliki. Kita dapat melakukan `polynomial regressiona` pada data agar sesuai dengan persamaan polynomial.\n",
    "\n",
    "\n",
    "Referensi : https://towardsdatascience.com/introduction-to-linear-regression-and-polynomial-regression-f8adc96f31cb\n",
    "Referensi: https://en.wikipedia.org/wiki/Polynomial_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Pilihan Features\n",
    "\n",
    "Pada kasus kali ini memilih **`RM`** (Jumlah Kamar Rumah) sebagai Feature dan **`Price`** (Harga) sebagai Target. Pemilihan tersebut dikarenakan banyaknya permintaan umum seperti Jumlah Kamar yang ada di dalam rumah, maka permintaan tersebut akan sangat memengaruhi Price ((Harga) yang di tentukan dari Sample Dataset untuk diprediksi.\n",
    "\n",
    "Untuk Keterangan yang dipilih adalah sebagai berikut :\n",
    "- **RM** adalah Jumlah kamar setiap rumah sebagai **`Features`**.\n",
    "- **Price** adalah harga sebagai **`Target`**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Preprocessing Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Tahap `Preprocessing Dataset` kita perlu untuk menampung Dataset ke dalam `Training Dataset` dengan import module `import numpy as np` sebagai berikut :\n",
    "\n",
    "- `X_train = np.array(boston_df['RM']).reshape(-1, 1)` Variabel `X_train` sebagai sekumpulan nilai `Features` untuk **Training Set** berisikan `diameter`. Kemudian untuk bagian ini akan menampilkan `numpy array` 1 dimensi, pada `X_train` ditambahkan `reshape(-1, 1)` karena pada scikir learn untuk Featuresnya harus berada dalam array 2 dimensi sedangkan kita hanya memiliki satu buah kolom parameter saja.\n",
    "\n",
    "- `y_train = np.array(boston_df['Price'])` Variabel `y_train` sebagai sekumpulan nilai Target untuk **Training Set**. Kemudian untuk bagian ini akan menampilkan `numpy array` 1 dimensi.\n",
    "\n",
    "Untuk menampilkan hasilnya kita dapat mengikuti langkah dibawah ini :\n",
    "- `print(f'X_train:\\n{X_train}\\n')`\n",
    "- `print(f'y_train: {y_train}')`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Sample Dataset Load Boston Housing Price\n",
    "\n",
    "Pada tahap `Sample Dataset` terlebih dahulu kita untuk melakukan `from sklearn.datasets import load_boston` dengan mempersiapkan `sample dataset` yang akan di olah yaitu `load_boston()` dan ditampung ke dalam variabel `boston_dataset` seperti script dibawah ini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n",
       "         4.9800e+00],\n",
       "        [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n",
       "         9.1400e+00],\n",
       "        [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n",
       "         4.0300e+00],\n",
       "        ...,\n",
       "        [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "         5.6400e+00],\n",
       "        [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n",
       "         6.4800e+00],\n",
       "        [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "         7.8800e+00]]),\n",
       " 'target': array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
       "        18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
       "        15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
       "        13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
       "        21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
       "        35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
       "        19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
       "        20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
       "        23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
       "        33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
       "        21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
       "        20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
       "        23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
       "        15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
       "        17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
       "        25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
       "        23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
       "        32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
       "        34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
       "        20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
       "        26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
       "        31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
       "        22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
       "        42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
       "        36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
       "        32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
       "        20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
       "        20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
       "        22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
       "        21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
       "        19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
       "        32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
       "        18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
       "        16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
       "        13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
       "         7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
       "        12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
       "        27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
       "         8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
       "         9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
       "        10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
       "        15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
       "        19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
       "        29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
       "        20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
       "        23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9]),\n",
       " 'feature_names': array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
       "        'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='<U7'),\n",
       " 'DESCR': \".. _boston_dataset:\\n\\nBoston house prices dataset\\n---------------------------\\n\\n**Data Set Characteristics:**  \\n\\n    :Number of Instances: 506 \\n\\n    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\\n\\n    :Attribute Information (in order):\\n        - CRIM     per capita crime rate by town\\n        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\\n        - INDUS    proportion of non-retail business acres per town\\n        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\\n        - NOX      nitric oxides concentration (parts per 10 million)\\n        - RM       average number of rooms per dwelling\\n        - AGE      proportion of owner-occupied units built prior to 1940\\n        - DIS      weighted distances to five Boston employment centres\\n        - RAD      index of accessibility to radial highways\\n        - TAX      full-value property-tax rate per $10,000\\n        - PTRATIO  pupil-teacher ratio by town\\n        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\\n        - LSTAT    % lower status of the population\\n        - MEDV     Median value of owner-occupied homes in $1000's\\n\\n    :Missing Attribute Values: None\\n\\n    :Creator: Harrison, D. and Rubinfeld, D.L.\\n\\nThis is a copy of UCI ML housing dataset.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/housing/\\n\\n\\nThis dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\\n\\nThe Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\\nprices and the demand for clean air', J. Environ. Economics & Management,\\nvol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\\n...', Wiley, 1980.   N.B. Various transformations are used in the table on\\npages 244-261 of the latter.\\n\\nThe Boston house-price data has been used in many machine learning papers that address regression\\nproblems.   \\n     \\n.. topic:: References\\n\\n   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\\n   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\\n\",\n",
       " 'filename': 'C:\\\\Users\\\\User\\\\anaconda3\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\boston_house_prices.csv'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston_dataset = load_boston()\n",
    "\n",
    "boston_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Untuk mengetahui harga rumah dari sample dataset yang disediakan, kita dapat menambahkan kolom harga sebagai `Price` seperti tampilan script dibawah ini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...    ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786  1.0  273.0   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875  1.0  273.0   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675  1.0  273.0   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889  1.0  273.0   \n",
       "505  0.04741   0.0  11.93   0.0  0.573  6.030  80.8  2.5050  1.0  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  Price  \n",
       "0       15.3  396.90   4.98   24.0  \n",
       "1       17.8  396.90   9.14   21.6  \n",
       "2       17.8  392.83   4.03   34.7  \n",
       "3       18.7  394.63   2.94   33.4  \n",
       "4       18.7  396.90   5.33   36.2  \n",
       "..       ...     ...    ...    ...  \n",
       "501     21.0  391.99   9.67   22.4  \n",
       "502     21.0  396.90   9.08   20.6  \n",
       "503     21.0  396.90   5.64   23.9  \n",
       "504     21.0  393.45   6.48   22.0  \n",
       "505     21.0  396.90   7.88   11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_df['Price'] = boston_dataset.target\n",
    "boston_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Selanjutnya kita juga dapat mengambil dan menampilkan hanya beberapa dataset yang tersedia seperti script dibawah ini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RM</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.575</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.421</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.185</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.998</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.147</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>6.593</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>6.120</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>6.976</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>6.794</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>6.030</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        RM  Price\n",
       "0    6.575   24.0\n",
       "1    6.421   21.6\n",
       "2    7.185   34.7\n",
       "3    6.998   33.4\n",
       "4    7.147   36.2\n",
       "..     ...    ...\n",
       "501  6.593   22.4\n",
       "502  6.120   20.6\n",
       "503  6.976   23.9\n",
       "504  6.794   22.0\n",
       "505  6.030   11.9\n",
       "\n",
       "[506 rows x 2 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_df[[\"RM\", \"Price\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:\n",
      "[[6.575]\n",
      " [6.421]\n",
      " [7.185]\n",
      " [6.998]\n",
      " [7.147]\n",
      " [6.43 ]\n",
      " [6.012]\n",
      " [6.172]\n",
      " [5.631]\n",
      " [6.004]\n",
      " [6.377]\n",
      " [6.009]\n",
      " [5.889]\n",
      " [5.949]\n",
      " [6.096]\n",
      " [5.834]\n",
      " [5.935]\n",
      " [5.99 ]\n",
      " [5.456]\n",
      " [5.727]\n",
      " [5.57 ]\n",
      " [5.965]\n",
      " [6.142]\n",
      " [5.813]\n",
      " [5.924]\n",
      " [5.599]\n",
      " [5.813]\n",
      " [6.047]\n",
      " [6.495]\n",
      " [6.674]\n",
      " [5.713]\n",
      " [6.072]\n",
      " [5.95 ]\n",
      " [5.701]\n",
      " [6.096]\n",
      " [5.933]\n",
      " [5.841]\n",
      " [5.85 ]\n",
      " [5.966]\n",
      " [6.595]\n",
      " [7.024]\n",
      " [6.77 ]\n",
      " [6.169]\n",
      " [6.211]\n",
      " [6.069]\n",
      " [5.682]\n",
      " [5.786]\n",
      " [6.03 ]\n",
      " [5.399]\n",
      " [5.602]\n",
      " [5.963]\n",
      " [6.115]\n",
      " [6.511]\n",
      " [5.998]\n",
      " [5.888]\n",
      " [7.249]\n",
      " [6.383]\n",
      " [6.816]\n",
      " [6.145]\n",
      " [5.927]\n",
      " [5.741]\n",
      " [5.966]\n",
      " [6.456]\n",
      " [6.762]\n",
      " [7.104]\n",
      " [6.29 ]\n",
      " [5.787]\n",
      " [5.878]\n",
      " [5.594]\n",
      " [5.885]\n",
      " [6.417]\n",
      " [5.961]\n",
      " [6.065]\n",
      " [6.245]\n",
      " [6.273]\n",
      " [6.286]\n",
      " [6.279]\n",
      " [6.14 ]\n",
      " [6.232]\n",
      " [5.874]\n",
      " [6.727]\n",
      " [6.619]\n",
      " [6.302]\n",
      " [6.167]\n",
      " [6.389]\n",
      " [6.63 ]\n",
      " [6.015]\n",
      " [6.121]\n",
      " [7.007]\n",
      " [7.079]\n",
      " [6.417]\n",
      " [6.405]\n",
      " [6.442]\n",
      " [6.211]\n",
      " [6.249]\n",
      " [6.625]\n",
      " [6.163]\n",
      " [8.069]\n",
      " [7.82 ]\n",
      " [7.416]\n",
      " [6.727]\n",
      " [6.781]\n",
      " [6.405]\n",
      " [6.137]\n",
      " [6.167]\n",
      " [5.851]\n",
      " [5.836]\n",
      " [6.127]\n",
      " [6.474]\n",
      " [6.229]\n",
      " [6.195]\n",
      " [6.715]\n",
      " [5.913]\n",
      " [6.092]\n",
      " [6.254]\n",
      " [5.928]\n",
      " [6.176]\n",
      " [6.021]\n",
      " [5.872]\n",
      " [5.731]\n",
      " [5.87 ]\n",
      " [6.004]\n",
      " [5.961]\n",
      " [5.856]\n",
      " [5.879]\n",
      " [5.986]\n",
      " [5.613]\n",
      " [5.693]\n",
      " [6.431]\n",
      " [5.637]\n",
      " [6.458]\n",
      " [6.326]\n",
      " [6.372]\n",
      " [5.822]\n",
      " [5.757]\n",
      " [6.335]\n",
      " [5.942]\n",
      " [6.454]\n",
      " [5.857]\n",
      " [6.151]\n",
      " [6.174]\n",
      " [5.019]\n",
      " [5.403]\n",
      " [5.468]\n",
      " [4.903]\n",
      " [6.13 ]\n",
      " [5.628]\n",
      " [4.926]\n",
      " [5.186]\n",
      " [5.597]\n",
      " [6.122]\n",
      " [5.404]\n",
      " [5.012]\n",
      " [5.709]\n",
      " [6.129]\n",
      " [6.152]\n",
      " [5.272]\n",
      " [6.943]\n",
      " [6.066]\n",
      " [6.51 ]\n",
      " [6.25 ]\n",
      " [7.489]\n",
      " [7.802]\n",
      " [8.375]\n",
      " [5.854]\n",
      " [6.101]\n",
      " [7.929]\n",
      " [5.877]\n",
      " [6.319]\n",
      " [6.402]\n",
      " [5.875]\n",
      " [5.88 ]\n",
      " [5.572]\n",
      " [6.416]\n",
      " [5.859]\n",
      " [6.546]\n",
      " [6.02 ]\n",
      " [6.315]\n",
      " [6.86 ]\n",
      " [6.98 ]\n",
      " [7.765]\n",
      " [6.144]\n",
      " [7.155]\n",
      " [6.563]\n",
      " [5.604]\n",
      " [6.153]\n",
      " [7.831]\n",
      " [6.782]\n",
      " [6.556]\n",
      " [7.185]\n",
      " [6.951]\n",
      " [6.739]\n",
      " [7.178]\n",
      " [6.8  ]\n",
      " [6.604]\n",
      " [7.875]\n",
      " [7.287]\n",
      " [7.107]\n",
      " [7.274]\n",
      " [6.975]\n",
      " [7.135]\n",
      " [6.162]\n",
      " [7.61 ]\n",
      " [7.853]\n",
      " [8.034]\n",
      " [5.891]\n",
      " [6.326]\n",
      " [5.783]\n",
      " [6.064]\n",
      " [5.344]\n",
      " [5.96 ]\n",
      " [5.404]\n",
      " [5.807]\n",
      " [6.375]\n",
      " [5.412]\n",
      " [6.182]\n",
      " [5.888]\n",
      " [6.642]\n",
      " [5.951]\n",
      " [6.373]\n",
      " [6.951]\n",
      " [6.164]\n",
      " [6.879]\n",
      " [6.618]\n",
      " [8.266]\n",
      " [8.725]\n",
      " [8.04 ]\n",
      " [7.163]\n",
      " [7.686]\n",
      " [6.552]\n",
      " [5.981]\n",
      " [7.412]\n",
      " [8.337]\n",
      " [8.247]\n",
      " [6.726]\n",
      " [6.086]\n",
      " [6.631]\n",
      " [7.358]\n",
      " [6.481]\n",
      " [6.606]\n",
      " [6.897]\n",
      " [6.095]\n",
      " [6.358]\n",
      " [6.393]\n",
      " [5.593]\n",
      " [5.605]\n",
      " [6.108]\n",
      " [6.226]\n",
      " [6.433]\n",
      " [6.718]\n",
      " [6.487]\n",
      " [6.438]\n",
      " [6.957]\n",
      " [8.259]\n",
      " [6.108]\n",
      " [5.876]\n",
      " [7.454]\n",
      " [8.704]\n",
      " [7.333]\n",
      " [6.842]\n",
      " [7.203]\n",
      " [7.52 ]\n",
      " [8.398]\n",
      " [7.327]\n",
      " [7.206]\n",
      " [5.56 ]\n",
      " [7.014]\n",
      " [8.297]\n",
      " [7.47 ]\n",
      " [5.92 ]\n",
      " [5.856]\n",
      " [6.24 ]\n",
      " [6.538]\n",
      " [7.691]\n",
      " [6.758]\n",
      " [6.854]\n",
      " [7.267]\n",
      " [6.826]\n",
      " [6.482]\n",
      " [6.812]\n",
      " [7.82 ]\n",
      " [6.968]\n",
      " [7.645]\n",
      " [7.923]\n",
      " [7.088]\n",
      " [6.453]\n",
      " [6.23 ]\n",
      " [6.209]\n",
      " [6.315]\n",
      " [6.565]\n",
      " [6.861]\n",
      " [7.148]\n",
      " [6.63 ]\n",
      " [6.127]\n",
      " [6.009]\n",
      " [6.678]\n",
      " [6.549]\n",
      " [5.79 ]\n",
      " [6.345]\n",
      " [7.041]\n",
      " [6.871]\n",
      " [6.59 ]\n",
      " [6.495]\n",
      " [6.982]\n",
      " [7.236]\n",
      " [6.616]\n",
      " [7.42 ]\n",
      " [6.849]\n",
      " [6.635]\n",
      " [5.972]\n",
      " [4.973]\n",
      " [6.122]\n",
      " [6.023]\n",
      " [6.266]\n",
      " [6.567]\n",
      " [5.705]\n",
      " [5.914]\n",
      " [5.782]\n",
      " [6.382]\n",
      " [6.113]\n",
      " [6.426]\n",
      " [6.376]\n",
      " [6.041]\n",
      " [5.708]\n",
      " [6.415]\n",
      " [6.431]\n",
      " [6.312]\n",
      " [6.083]\n",
      " [5.868]\n",
      " [6.333]\n",
      " [6.144]\n",
      " [5.706]\n",
      " [6.031]\n",
      " [6.316]\n",
      " [6.31 ]\n",
      " [6.037]\n",
      " [5.869]\n",
      " [5.895]\n",
      " [6.059]\n",
      " [5.985]\n",
      " [5.968]\n",
      " [7.241]\n",
      " [6.54 ]\n",
      " [6.696]\n",
      " [6.874]\n",
      " [6.014]\n",
      " [5.898]\n",
      " [6.516]\n",
      " [6.635]\n",
      " [6.939]\n",
      " [6.49 ]\n",
      " [6.579]\n",
      " [5.884]\n",
      " [6.728]\n",
      " [5.663]\n",
      " [5.936]\n",
      " [6.212]\n",
      " [6.395]\n",
      " [6.127]\n",
      " [6.112]\n",
      " [6.398]\n",
      " [6.251]\n",
      " [5.362]\n",
      " [5.803]\n",
      " [8.78 ]\n",
      " [3.561]\n",
      " [4.963]\n",
      " [3.863]\n",
      " [4.97 ]\n",
      " [6.683]\n",
      " [7.016]\n",
      " [6.216]\n",
      " [5.875]\n",
      " [4.906]\n",
      " [4.138]\n",
      " [7.313]\n",
      " [6.649]\n",
      " [6.794]\n",
      " [6.38 ]\n",
      " [6.223]\n",
      " [6.968]\n",
      " [6.545]\n",
      " [5.536]\n",
      " [5.52 ]\n",
      " [4.368]\n",
      " [5.277]\n",
      " [4.652]\n",
      " [5.   ]\n",
      " [4.88 ]\n",
      " [5.39 ]\n",
      " [5.713]\n",
      " [6.051]\n",
      " [5.036]\n",
      " [6.193]\n",
      " [5.887]\n",
      " [6.471]\n",
      " [6.405]\n",
      " [5.747]\n",
      " [5.453]\n",
      " [5.852]\n",
      " [5.987]\n",
      " [6.343]\n",
      " [6.404]\n",
      " [5.349]\n",
      " [5.531]\n",
      " [5.683]\n",
      " [4.138]\n",
      " [5.608]\n",
      " [5.617]\n",
      " [6.852]\n",
      " [5.757]\n",
      " [6.657]\n",
      " [4.628]\n",
      " [5.155]\n",
      " [4.519]\n",
      " [6.434]\n",
      " [6.782]\n",
      " [5.304]\n",
      " [5.957]\n",
      " [6.824]\n",
      " [6.411]\n",
      " [6.006]\n",
      " [5.648]\n",
      " [6.103]\n",
      " [5.565]\n",
      " [5.896]\n",
      " [5.837]\n",
      " [6.202]\n",
      " [6.193]\n",
      " [6.38 ]\n",
      " [6.348]\n",
      " [6.833]\n",
      " [6.425]\n",
      " [6.436]\n",
      " [6.208]\n",
      " [6.629]\n",
      " [6.461]\n",
      " [6.152]\n",
      " [5.935]\n",
      " [5.627]\n",
      " [5.818]\n",
      " [6.406]\n",
      " [6.219]\n",
      " [6.485]\n",
      " [5.854]\n",
      " [6.459]\n",
      " [6.341]\n",
      " [6.251]\n",
      " [6.185]\n",
      " [6.417]\n",
      " [6.749]\n",
      " [6.655]\n",
      " [6.297]\n",
      " [7.393]\n",
      " [6.728]\n",
      " [6.525]\n",
      " [5.976]\n",
      " [5.936]\n",
      " [6.301]\n",
      " [6.081]\n",
      " [6.701]\n",
      " [6.376]\n",
      " [6.317]\n",
      " [6.513]\n",
      " [6.209]\n",
      " [5.759]\n",
      " [5.952]\n",
      " [6.003]\n",
      " [5.926]\n",
      " [5.713]\n",
      " [6.167]\n",
      " [6.229]\n",
      " [6.437]\n",
      " [6.98 ]\n",
      " [5.427]\n",
      " [6.162]\n",
      " [6.484]\n",
      " [5.304]\n",
      " [6.185]\n",
      " [6.229]\n",
      " [6.242]\n",
      " [6.75 ]\n",
      " [7.061]\n",
      " [5.762]\n",
      " [5.871]\n",
      " [6.312]\n",
      " [6.114]\n",
      " [5.905]\n",
      " [5.454]\n",
      " [5.414]\n",
      " [5.093]\n",
      " [5.983]\n",
      " [5.983]\n",
      " [5.707]\n",
      " [5.926]\n",
      " [5.67 ]\n",
      " [5.39 ]\n",
      " [5.794]\n",
      " [6.019]\n",
      " [5.569]\n",
      " [6.027]\n",
      " [6.593]\n",
      " [6.12 ]\n",
      " [6.976]\n",
      " [6.794]\n",
      " [6.03 ]]\n",
      "\n",
      "y_train: [24.  21.6 34.7 33.4 36.2 28.7 22.9 27.1 16.5 18.9 15.  18.9 21.7 20.4\n",
      " 18.2 19.9 23.1 17.5 20.2 18.2 13.6 19.6 15.2 14.5 15.6 13.9 16.6 14.8\n",
      " 18.4 21.  12.7 14.5 13.2 13.1 13.5 18.9 20.  21.  24.7 30.8 34.9 26.6\n",
      " 25.3 24.7 21.2 19.3 20.  16.6 14.4 19.4 19.7 20.5 25.  23.4 18.9 35.4\n",
      " 24.7 31.6 23.3 19.6 18.7 16.  22.2 25.  33.  23.5 19.4 22.  17.4 20.9\n",
      " 24.2 21.7 22.8 23.4 24.1 21.4 20.  20.8 21.2 20.3 28.  23.9 24.8 22.9\n",
      " 23.9 26.6 22.5 22.2 23.6 28.7 22.6 22.  22.9 25.  20.6 28.4 21.4 38.7\n",
      " 43.8 33.2 27.5 26.5 18.6 19.3 20.1 19.5 19.5 20.4 19.8 19.4 21.7 22.8\n",
      " 18.8 18.7 18.5 18.3 21.2 19.2 20.4 19.3 22.  20.3 20.5 17.3 18.8 21.4\n",
      " 15.7 16.2 18.  14.3 19.2 19.6 23.  18.4 15.6 18.1 17.4 17.1 13.3 17.8\n",
      " 14.  14.4 13.4 15.6 11.8 13.8 15.6 14.6 17.8 15.4 21.5 19.6 15.3 19.4\n",
      " 17.  15.6 13.1 41.3 24.3 23.3 27.  50.  50.  50.  22.7 25.  50.  23.8\n",
      " 23.8 22.3 17.4 19.1 23.1 23.6 22.6 29.4 23.2 24.6 29.9 37.2 39.8 36.2\n",
      " 37.9 32.5 26.4 29.6 50.  32.  29.8 34.9 37.  30.5 36.4 31.1 29.1 50.\n",
      " 33.3 30.3 34.6 34.9 32.9 24.1 42.3 48.5 50.  22.6 24.4 22.5 24.4 20.\n",
      " 21.7 19.3 22.4 28.1 23.7 25.  23.3 28.7 21.5 23.  26.7 21.7 27.5 30.1\n",
      " 44.8 50.  37.6 31.6 46.7 31.5 24.3 31.7 41.7 48.3 29.  24.  25.1 31.5\n",
      " 23.7 23.3 22.  20.1 22.2 23.7 17.6 18.5 24.3 20.5 24.5 26.2 24.4 24.8\n",
      " 29.6 42.8 21.9 20.9 44.  50.  36.  30.1 33.8 43.1 48.8 31.  36.5 22.8\n",
      " 30.7 50.  43.5 20.7 21.1 25.2 24.4 35.2 32.4 32.  33.2 33.1 29.1 35.1\n",
      " 45.4 35.4 46.  50.  32.2 22.  20.1 23.2 22.3 24.8 28.5 37.3 27.9 23.9\n",
      " 21.7 28.6 27.1 20.3 22.5 29.  24.8 22.  26.4 33.1 36.1 28.4 33.4 28.2\n",
      " 22.8 20.3 16.1 22.1 19.4 21.6 23.8 16.2 17.8 19.8 23.1 21.  23.8 23.1\n",
      " 20.4 18.5 25.  24.6 23.  22.2 19.3 22.6 19.8 17.1 19.4 22.2 20.7 21.1\n",
      " 19.5 18.5 20.6 19.  18.7 32.7 16.5 23.9 31.2 17.5 17.2 23.1 24.5 26.6\n",
      " 22.9 24.1 18.6 30.1 18.2 20.6 17.8 21.7 22.7 22.6 25.  19.9 20.8 16.8\n",
      " 21.9 27.5 21.9 23.1 50.  50.  50.  50.  50.  13.8 13.8 15.  13.9 13.3\n",
      " 13.1 10.2 10.4 10.9 11.3 12.3  8.8  7.2 10.5  7.4 10.2 11.5 15.1 23.2\n",
      "  9.7 13.8 12.7 13.1 12.5  8.5  5.   6.3  5.6  7.2 12.1  8.3  8.5  5.\n",
      " 11.9 27.9 17.2 27.5 15.  17.2 17.9 16.3  7.   7.2  7.5 10.4  8.8  8.4\n",
      " 16.7 14.2 20.8 13.4 11.7  8.3 10.2 10.9 11.   9.5 14.5 14.1 16.1 14.3\n",
      " 11.7 13.4  9.6  8.7  8.4 12.8 10.5 17.1 18.4 15.4 10.8 11.8 14.9 12.6\n",
      " 14.1 13.  13.4 15.2 16.1 17.8 14.9 14.1 12.7 13.5 14.9 20.  16.4 17.7\n",
      " 19.5 20.2 21.4 19.9 19.  19.1 19.1 20.1 19.9 19.6 23.2 29.8 13.8 13.3\n",
      " 16.7 12.  14.6 21.4 23.  23.7 25.  21.8 20.6 21.2 19.1 20.6 15.2  7.\n",
      "  8.1 13.6 20.1 21.8 24.5 23.1 19.7 18.3 21.2 17.5 16.8 22.4 20.6 23.9\n",
      " 22.  11.9]\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array(boston_df['RM']).reshape(-1, 1)\n",
    "y_train = np.array(boston_df['Price'])\n",
    "\n",
    "print(f'X_train:\\n{X_train}\\n')\n",
    "print(f'y_train: {y_train}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Hasil script diatas menunjukkan bahwa variabel `X_train` menampilkan array 2 dimensi dengan 1 parameter, hal tersebut karena kita memanggil fungsi `reshape(-1,1)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Polynomial Regression: Quadratic\n",
    "\n",
    "Pada tahap ini kita akan mempelajari `Polynomial Regression: Quadratic` implementasi dari scikit learn dengan derajat polynomial 2 atau yang disebut dengan `Qudratic`. Berikut adalah formula untuk Polynomial Regression: Quadratic :\n",
    "\n",
    "$y = \\alpha + \\beta_1x + \\beta_2x^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Polynomial Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada tahap ini pertama-tama kita melakukan import module dengan `from sklearn.preprocessing import PolynomialFeatures` kemudian kita akan membuat objeknya dengan memanggil `PolynomialFeatures` dengan parameter `degree=2` yang ditampung ke dalam variabel `quadratic_feature`. Selanjutnya kita melakukan transform pada quadratic dengan memanggil `quadratic_feature.fit_transform` dengan parameter `X_train` yang ditampung ke dalam variabel `X_train_quadratic` yang berisikan Features.\n",
    "\n",
    "- `print(f'X_train_quadratic:\\n{X_train_quadratic}\\n')` bertujuan untuk menampilkan hasil dari `X_train_quadratic`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_quadratic:\n",
      "[[ 1.        6.575    43.230625]\n",
      " [ 1.        6.421    41.229241]\n",
      " [ 1.        7.185    51.624225]\n",
      " ...\n",
      " [ 1.        6.976    48.664576]\n",
      " [ 1.        6.794    46.158436]\n",
      " [ 1.        6.03     36.3609  ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "quadratic_feature = PolynomialFeatures(degree=2)\n",
    "X_train_quadratic = quadratic_feature.fit_transform(X_train)\n",
    "\n",
    "print(f'X_train_quadratic:\\n{X_train_quadratic}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Diatas memiliki 3 hasil yang merupakan hasil implementasi dari berikut : \n",
    "\n",
    "$y = \\alpha + \\beta_1x + \\beta_2x^2$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selanjutnya pada tahap `Training Model` pertama-tama kita akan membentuk objek model nya dengan memanggil `LinearRegression()` yang ditampung ke dalam variabel `model`, kemudian objek model tersebut kita akan Training dengan memanfaatkan `model.fit` dengan 2 parameter yaitu `X_train_quadratic` dan `y_train` dengan script sebagai berikut. Proses dari transformasi `Polynomial` tersebut dikenakan pada **`Features`** dan tidak dikenakan pada **`Traget`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train_quadratic, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Hasil diatas menunjukkan bahwa ada scikit learn tidak ada perbedaan antara implementasi `Linear Regression` dan `Ploynomial Regression`. Perbedaannya adalah pada Ploynomial Regression kita perlu melakukan transformasi Features ke dalam Polynomial sebelum melakukan proses **Training Model**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisasi Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada tahap `Visualisasi Model` ini pertama-tama kita melakukan import modelu `import matplotlib.pyplot as plt` dengan sebagai berikut :\n",
    "\n",
    "- `X_vis = np.linspace(0, 25, 100).reshape(-1, 1)` sebagai deret bilangan dari angka 0 sampai 25 sebanyak 100 data poin, data poin tersebut akan dimasukkan ke dalam variabel `X_vis`.\n",
    "- `X_vis_quadratic = quadratic_feature.transform(X_vis)` bertujuan untuk melakukan transformasi dengan menggunakan `quadratic_feature.transform` dengan parameter `X_vis` yang ditampung ke dalam `X_vis_quadratic`.\n",
    "- `y_vis_quadratic = model.predict(X_vis_quadratic)` untuk melakukan prediksi terhadap `X_vis_quadratic` dengan memanggil `model.predict` yang ditampung pada variabel `y_vis_quadratic`.\n",
    "\n",
    "Untuk melakukan visualisasi ada 2 hal yaitu :\n",
    "- `plt.scatter(X_train, y_train)` sebagai plot scatter dengan parameter `X_train` dan `y_train`.\n",
    "- `plt.plot(X_vis, y_vis_quadratic, '-r')` untuk melakukan plotting dengan parameter `X_vis`, `y_vis_quadratic`, dan `-r` (warna merah)\n",
    "\n",
    "Berikut keterangan tambahan :\n",
    "- `plt.title('Perbandingan Jumlah Kamar Rumah (RM) dan Harga (Price)')` sebagai judul\n",
    "- `plt.xlabel('Jumlah Kamar Rumah (RM)')` sebagai X label\n",
    "- `plt.ylabel('Harga (Price)')` sebagai Y label\n",
    "- `plt.xlim(0, 25)` sebagai batasan X\n",
    "- `plt.ylim(0, 25)` sebagai batasan Y\n",
    "- `plt.grid(True)` sebagai tampilan grid pada gambar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_quadratic:\n",
      "[[ 1.        6.575    43.230625]\n",
      " [ 1.        6.421    41.229241]\n",
      " [ 1.        7.185    51.624225]\n",
      " ...\n",
      " [ 1.        6.976    48.664576]\n",
      " [ 1.        6.794    46.158436]\n",
      " [ 1.        6.03     36.3609  ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "quadratic_feature = PolynomialFeatures(degree=2)\n",
    "X_train_quadratic = quadratic_feature.fit_transform(X_train)\n",
    "\n",
    "print(f'X_train_quadratic:\\n{X_train_quadratic}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1518, 1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X_train_quadratic.reshape(-1, 1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:\n",
      "[[6.575]\n",
      " [6.421]\n",
      " [7.185]\n",
      " [6.998]\n",
      " [7.147]\n",
      " [6.43 ]\n",
      " [6.012]\n",
      " [6.172]\n",
      " [5.631]\n",
      " [6.004]\n",
      " [6.377]\n",
      " [6.009]\n",
      " [5.889]\n",
      " [5.949]\n",
      " [6.096]\n",
      " [5.834]\n",
      " [5.935]\n",
      " [5.99 ]\n",
      " [5.456]\n",
      " [5.727]\n",
      " [5.57 ]\n",
      " [5.965]\n",
      " [6.142]\n",
      " [5.813]\n",
      " [5.924]\n",
      " [5.599]\n",
      " [5.813]\n",
      " [6.047]\n",
      " [6.495]\n",
      " [6.674]\n",
      " [5.713]\n",
      " [6.072]\n",
      " [5.95 ]\n",
      " [5.701]\n",
      " [6.096]\n",
      " [5.933]\n",
      " [5.841]\n",
      " [5.85 ]\n",
      " [5.966]\n",
      " [6.595]\n",
      " [7.024]\n",
      " [6.77 ]\n",
      " [6.169]\n",
      " [6.211]\n",
      " [6.069]\n",
      " [5.682]\n",
      " [5.786]\n",
      " [6.03 ]\n",
      " [5.399]\n",
      " [5.602]\n",
      " [5.963]\n",
      " [6.115]\n",
      " [6.511]\n",
      " [5.998]\n",
      " [5.888]\n",
      " [7.249]\n",
      " [6.383]\n",
      " [6.816]\n",
      " [6.145]\n",
      " [5.927]\n",
      " [5.741]\n",
      " [5.966]\n",
      " [6.456]\n",
      " [6.762]\n",
      " [7.104]\n",
      " [6.29 ]\n",
      " [5.787]\n",
      " [5.878]\n",
      " [5.594]\n",
      " [5.885]\n",
      " [6.417]\n",
      " [5.961]\n",
      " [6.065]\n",
      " [6.245]\n",
      " [6.273]\n",
      " [6.286]\n",
      " [6.279]\n",
      " [6.14 ]\n",
      " [6.232]\n",
      " [5.874]\n",
      " [6.727]\n",
      " [6.619]\n",
      " [6.302]\n",
      " [6.167]\n",
      " [6.389]\n",
      " [6.63 ]\n",
      " [6.015]\n",
      " [6.121]\n",
      " [7.007]\n",
      " [7.079]\n",
      " [6.417]\n",
      " [6.405]\n",
      " [6.442]\n",
      " [6.211]\n",
      " [6.249]\n",
      " [6.625]\n",
      " [6.163]\n",
      " [8.069]\n",
      " [7.82 ]\n",
      " [7.416]\n",
      " [6.727]\n",
      " [6.781]\n",
      " [6.405]\n",
      " [6.137]\n",
      " [6.167]\n",
      " [5.851]\n",
      " [5.836]\n",
      " [6.127]\n",
      " [6.474]\n",
      " [6.229]\n",
      " [6.195]\n",
      " [6.715]\n",
      " [5.913]\n",
      " [6.092]\n",
      " [6.254]\n",
      " [5.928]\n",
      " [6.176]\n",
      " [6.021]\n",
      " [5.872]\n",
      " [5.731]\n",
      " [5.87 ]\n",
      " [6.004]\n",
      " [5.961]\n",
      " [5.856]\n",
      " [5.879]\n",
      " [5.986]\n",
      " [5.613]\n",
      " [5.693]\n",
      " [6.431]\n",
      " [5.637]\n",
      " [6.458]\n",
      " [6.326]\n",
      " [6.372]\n",
      " [5.822]\n",
      " [5.757]\n",
      " [6.335]\n",
      " [5.942]\n",
      " [6.454]\n",
      " [5.857]\n",
      " [6.151]\n",
      " [6.174]\n",
      " [5.019]\n",
      " [5.403]\n",
      " [5.468]\n",
      " [4.903]\n",
      " [6.13 ]\n",
      " [5.628]\n",
      " [4.926]\n",
      " [5.186]\n",
      " [5.597]\n",
      " [6.122]\n",
      " [5.404]\n",
      " [5.012]\n",
      " [5.709]\n",
      " [6.129]\n",
      " [6.152]\n",
      " [5.272]\n",
      " [6.943]\n",
      " [6.066]\n",
      " [6.51 ]\n",
      " [6.25 ]\n",
      " [7.489]\n",
      " [7.802]\n",
      " [8.375]\n",
      " [5.854]\n",
      " [6.101]\n",
      " [7.929]\n",
      " [5.877]\n",
      " [6.319]\n",
      " [6.402]\n",
      " [5.875]\n",
      " [5.88 ]\n",
      " [5.572]\n",
      " [6.416]\n",
      " [5.859]\n",
      " [6.546]\n",
      " [6.02 ]\n",
      " [6.315]\n",
      " [6.86 ]\n",
      " [6.98 ]\n",
      " [7.765]\n",
      " [6.144]\n",
      " [7.155]\n",
      " [6.563]\n",
      " [5.604]\n",
      " [6.153]\n",
      " [7.831]\n",
      " [6.782]\n",
      " [6.556]\n",
      " [7.185]\n",
      " [6.951]\n",
      " [6.739]\n",
      " [7.178]\n",
      " [6.8  ]\n",
      " [6.604]\n",
      " [7.875]\n",
      " [7.287]\n",
      " [7.107]\n",
      " [7.274]\n",
      " [6.975]\n",
      " [7.135]\n",
      " [6.162]\n",
      " [7.61 ]\n",
      " [7.853]\n",
      " [8.034]\n",
      " [5.891]\n",
      " [6.326]\n",
      " [5.783]\n",
      " [6.064]\n",
      " [5.344]\n",
      " [5.96 ]\n",
      " [5.404]\n",
      " [5.807]\n",
      " [6.375]\n",
      " [5.412]\n",
      " [6.182]\n",
      " [5.888]\n",
      " [6.642]\n",
      " [5.951]\n",
      " [6.373]\n",
      " [6.951]\n",
      " [6.164]\n",
      " [6.879]\n",
      " [6.618]\n",
      " [8.266]\n",
      " [8.725]\n",
      " [8.04 ]\n",
      " [7.163]\n",
      " [7.686]\n",
      " [6.552]\n",
      " [5.981]\n",
      " [7.412]\n",
      " [8.337]\n",
      " [8.247]\n",
      " [6.726]\n",
      " [6.086]\n",
      " [6.631]\n",
      " [7.358]\n",
      " [6.481]\n",
      " [6.606]\n",
      " [6.897]\n",
      " [6.095]\n",
      " [6.358]\n",
      " [6.393]\n",
      " [5.593]\n",
      " [5.605]\n",
      " [6.108]\n",
      " [6.226]\n",
      " [6.433]\n",
      " [6.718]\n",
      " [6.487]\n",
      " [6.438]\n",
      " [6.957]\n",
      " [8.259]\n",
      " [6.108]\n",
      " [5.876]\n",
      " [7.454]\n",
      " [8.704]\n",
      " [7.333]\n",
      " [6.842]\n",
      " [7.203]\n",
      " [7.52 ]\n",
      " [8.398]\n",
      " [7.327]\n",
      " [7.206]\n",
      " [5.56 ]\n",
      " [7.014]\n",
      " [8.297]\n",
      " [7.47 ]\n",
      " [5.92 ]\n",
      " [5.856]\n",
      " [6.24 ]\n",
      " [6.538]\n",
      " [7.691]\n",
      " [6.758]\n",
      " [6.854]\n",
      " [7.267]\n",
      " [6.826]\n",
      " [6.482]\n",
      " [6.812]\n",
      " [7.82 ]\n",
      " [6.968]\n",
      " [7.645]\n",
      " [7.923]\n",
      " [7.088]\n",
      " [6.453]\n",
      " [6.23 ]\n",
      " [6.209]\n",
      " [6.315]\n",
      " [6.565]\n",
      " [6.861]\n",
      " [7.148]\n",
      " [6.63 ]\n",
      " [6.127]\n",
      " [6.009]\n",
      " [6.678]\n",
      " [6.549]\n",
      " [5.79 ]\n",
      " [6.345]\n",
      " [7.041]\n",
      " [6.871]\n",
      " [6.59 ]\n",
      " [6.495]\n",
      " [6.982]\n",
      " [7.236]\n",
      " [6.616]\n",
      " [7.42 ]\n",
      " [6.849]\n",
      " [6.635]\n",
      " [5.972]\n",
      " [4.973]\n",
      " [6.122]\n",
      " [6.023]\n",
      " [6.266]\n",
      " [6.567]\n",
      " [5.705]\n",
      " [5.914]\n",
      " [5.782]\n",
      " [6.382]\n",
      " [6.113]\n",
      " [6.426]\n",
      " [6.376]\n",
      " [6.041]\n",
      " [5.708]\n",
      " [6.415]\n",
      " [6.431]\n",
      " [6.312]\n",
      " [6.083]\n",
      " [5.868]\n",
      " [6.333]\n",
      " [6.144]\n",
      " [5.706]\n",
      " [6.031]\n",
      " [6.316]\n",
      " [6.31 ]\n",
      " [6.037]\n",
      " [5.869]\n",
      " [5.895]\n",
      " [6.059]\n",
      " [5.985]\n",
      " [5.968]\n",
      " [7.241]\n",
      " [6.54 ]\n",
      " [6.696]\n",
      " [6.874]\n",
      " [6.014]\n",
      " [5.898]\n",
      " [6.516]\n",
      " [6.635]\n",
      " [6.939]\n",
      " [6.49 ]\n",
      " [6.579]\n",
      " [5.884]\n",
      " [6.728]\n",
      " [5.663]\n",
      " [5.936]\n",
      " [6.212]\n",
      " [6.395]\n",
      " [6.127]\n",
      " [6.112]\n",
      " [6.398]\n",
      " [6.251]\n",
      " [5.362]\n",
      " [5.803]\n",
      " [8.78 ]\n",
      " [3.561]\n",
      " [4.963]\n",
      " [3.863]\n",
      " [4.97 ]\n",
      " [6.683]\n",
      " [7.016]\n",
      " [6.216]\n",
      " [5.875]\n",
      " [4.906]\n",
      " [4.138]\n",
      " [7.313]\n",
      " [6.649]\n",
      " [6.794]\n",
      " [6.38 ]\n",
      " [6.223]\n",
      " [6.968]\n",
      " [6.545]\n",
      " [5.536]\n",
      " [5.52 ]\n",
      " [4.368]\n",
      " [5.277]\n",
      " [4.652]\n",
      " [5.   ]\n",
      " [4.88 ]\n",
      " [5.39 ]\n",
      " [5.713]\n",
      " [6.051]\n",
      " [5.036]\n",
      " [6.193]\n",
      " [5.887]\n",
      " [6.471]\n",
      " [6.405]\n",
      " [5.747]\n",
      " [5.453]\n",
      " [5.852]\n",
      " [5.987]\n",
      " [6.343]\n",
      " [6.404]\n",
      " [5.349]\n",
      " [5.531]\n",
      " [5.683]\n",
      " [4.138]\n",
      " [5.608]\n",
      " [5.617]\n",
      " [6.852]\n",
      " [5.757]\n",
      " [6.657]\n",
      " [4.628]\n",
      " [5.155]\n",
      " [4.519]\n",
      " [6.434]\n",
      " [6.782]\n",
      " [5.304]\n",
      " [5.957]\n",
      " [6.824]\n",
      " [6.411]\n",
      " [6.006]\n",
      " [5.648]\n",
      " [6.103]\n",
      " [5.565]\n",
      " [5.896]\n",
      " [5.837]\n",
      " [6.202]\n",
      " [6.193]\n",
      " [6.38 ]\n",
      " [6.348]\n",
      " [6.833]\n",
      " [6.425]\n",
      " [6.436]\n",
      " [6.208]\n",
      " [6.629]\n",
      " [6.461]\n",
      " [6.152]\n",
      " [5.935]\n",
      " [5.627]\n",
      " [5.818]\n",
      " [6.406]\n",
      " [6.219]\n",
      " [6.485]\n",
      " [5.854]\n",
      " [6.459]\n",
      " [6.341]\n",
      " [6.251]\n",
      " [6.185]\n",
      " [6.417]\n",
      " [6.749]\n",
      " [6.655]\n",
      " [6.297]\n",
      " [7.393]\n",
      " [6.728]\n",
      " [6.525]\n",
      " [5.976]\n",
      " [5.936]\n",
      " [6.301]\n",
      " [6.081]\n",
      " [6.701]\n",
      " [6.376]\n",
      " [6.317]\n",
      " [6.513]\n",
      " [6.209]\n",
      " [5.759]\n",
      " [5.952]\n",
      " [6.003]\n",
      " [5.926]\n",
      " [5.713]\n",
      " [6.167]\n",
      " [6.229]\n",
      " [6.437]\n",
      " [6.98 ]\n",
      " [5.427]\n",
      " [6.162]\n",
      " [6.484]\n",
      " [5.304]\n",
      " [6.185]\n",
      " [6.229]\n",
      " [6.242]\n",
      " [6.75 ]\n",
      " [7.061]\n",
      " [5.762]\n",
      " [5.871]\n",
      " [6.312]\n",
      " [6.114]\n",
      " [5.905]\n",
      " [5.454]\n",
      " [5.414]\n",
      " [5.093]\n",
      " [5.983]\n",
      " [5.983]\n",
      " [5.707]\n",
      " [5.926]\n",
      " [5.67 ]\n",
      " [5.39 ]\n",
      " [5.794]\n",
      " [6.019]\n",
      " [5.569]\n",
      " [6.027]\n",
      " [6.593]\n",
      " [6.12 ]\n",
      " [6.976]\n",
      " [6.794]\n",
      " [6.03 ]]\n",
      "\n",
      "y_train: [24.  21.6 34.7 33.4 36.2 28.7 22.9 27.1 16.5 18.9 15.  18.9 21.7 20.4\n",
      " 18.2 19.9 23.1 17.5 20.2 18.2 13.6 19.6 15.2 14.5 15.6 13.9 16.6 14.8\n",
      " 18.4 21.  12.7 14.5 13.2 13.1 13.5 18.9 20.  21.  24.7 30.8 34.9 26.6\n",
      " 25.3 24.7 21.2 19.3 20.  16.6 14.4 19.4 19.7 20.5 25.  23.4 18.9 35.4\n",
      " 24.7 31.6 23.3 19.6 18.7 16.  22.2 25.  33.  23.5 19.4 22.  17.4 20.9\n",
      " 24.2 21.7 22.8 23.4 24.1 21.4 20.  20.8 21.2 20.3 28.  23.9 24.8 22.9\n",
      " 23.9 26.6 22.5 22.2 23.6 28.7 22.6 22.  22.9 25.  20.6 28.4 21.4 38.7\n",
      " 43.8 33.2 27.5 26.5 18.6 19.3 20.1 19.5 19.5 20.4 19.8 19.4 21.7 22.8\n",
      " 18.8 18.7 18.5 18.3 21.2 19.2 20.4 19.3 22.  20.3 20.5 17.3 18.8 21.4\n",
      " 15.7 16.2 18.  14.3 19.2 19.6 23.  18.4 15.6 18.1 17.4 17.1 13.3 17.8\n",
      " 14.  14.4 13.4 15.6 11.8 13.8 15.6 14.6 17.8 15.4 21.5 19.6 15.3 19.4\n",
      " 17.  15.6 13.1 41.3 24.3 23.3 27.  50.  50.  50.  22.7 25.  50.  23.8\n",
      " 23.8 22.3 17.4 19.1 23.1 23.6 22.6 29.4 23.2 24.6 29.9 37.2 39.8 36.2\n",
      " 37.9 32.5 26.4 29.6 50.  32.  29.8 34.9 37.  30.5 36.4 31.1 29.1 50.\n",
      " 33.3 30.3 34.6 34.9 32.9 24.1 42.3 48.5 50.  22.6 24.4 22.5 24.4 20.\n",
      " 21.7 19.3 22.4 28.1 23.7 25.  23.3 28.7 21.5 23.  26.7 21.7 27.5 30.1\n",
      " 44.8 50.  37.6 31.6 46.7 31.5 24.3 31.7 41.7 48.3 29.  24.  25.1 31.5\n",
      " 23.7 23.3 22.  20.1 22.2 23.7 17.6 18.5 24.3 20.5 24.5 26.2 24.4 24.8\n",
      " 29.6 42.8 21.9 20.9 44.  50.  36.  30.1 33.8 43.1 48.8 31.  36.5 22.8\n",
      " 30.7 50.  43.5 20.7 21.1 25.2 24.4 35.2 32.4 32.  33.2 33.1 29.1 35.1\n",
      " 45.4 35.4 46.  50.  32.2 22.  20.1 23.2 22.3 24.8 28.5 37.3 27.9 23.9\n",
      " 21.7 28.6 27.1 20.3 22.5 29.  24.8 22.  26.4 33.1 36.1 28.4 33.4 28.2\n",
      " 22.8 20.3 16.1 22.1 19.4 21.6 23.8 16.2 17.8 19.8 23.1 21.  23.8 23.1\n",
      " 20.4 18.5 25.  24.6 23.  22.2 19.3 22.6 19.8 17.1 19.4 22.2 20.7 21.1\n",
      " 19.5 18.5 20.6 19.  18.7 32.7 16.5 23.9 31.2 17.5 17.2 23.1 24.5 26.6\n",
      " 22.9 24.1 18.6 30.1 18.2 20.6 17.8 21.7 22.7 22.6 25.  19.9 20.8 16.8\n",
      " 21.9 27.5 21.9 23.1 50.  50.  50.  50.  50.  13.8 13.8 15.  13.9 13.3\n",
      " 13.1 10.2 10.4 10.9 11.3 12.3  8.8  7.2 10.5  7.4 10.2 11.5 15.1 23.2\n",
      "  9.7 13.8 12.7 13.1 12.5  8.5  5.   6.3  5.6  7.2 12.1  8.3  8.5  5.\n",
      " 11.9 27.9 17.2 27.5 15.  17.2 17.9 16.3  7.   7.2  7.5 10.4  8.8  8.4\n",
      " 16.7 14.2 20.8 13.4 11.7  8.3 10.2 10.9 11.   9.5 14.5 14.1 16.1 14.3\n",
      " 11.7 13.4  9.6  8.7  8.4 12.8 10.5 17.1 18.4 15.4 10.8 11.8 14.9 12.6\n",
      " 14.1 13.  13.4 15.2 16.1 17.8 14.9 14.1 12.7 13.5 14.9 20.  16.4 17.7\n",
      " 19.5 20.2 21.4 19.9 19.  19.1 19.1 20.1 19.9 19.6 23.2 29.8 13.8 13.3\n",
      " 16.7 12.  14.6 21.4 23.  23.7 25.  21.8 20.6 21.2 19.1 20.6 15.2  7.\n",
      "  8.1 13.6 20.1 21.8 24.5 23.1 19.7 18.3 21.2 17.5 16.8 22.4 20.6 23.9\n",
      " 22.  11.9]\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array(boston_df['RM']).reshape(-1, 1)\n",
    "y_train = np.array(boston_df['Price'])\n",
    "\n",
    "print(f'X_train:\\n{X_train}\\n')\n",
    "print(f'y_train: {y_train}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X_vis = np.linspace(0, 10, 100).reshape(-1, 1)\n",
    "X_vis_quadratic = quadratic_feature.transform(X_vis)\n",
    "y_vis_quadratic = model.predict(X_vis_quadratic)\n",
    "\n",
    "plt.scatter(boston_dataset.data[:,5],boston_dataset.target)\n",
    "x = boston_df.RM\n",
    "plt.plot(X_vis, y_vis_quadratic, '-r')\n",
    "\n",
    "plt.title('Perbandingan Jumlah Kamar Rumah (RM) dan Harga (Price)')\n",
    "plt.ylabel('Harga (Price) dalam $1000')\n",
    "plt.xlabel('Jumlah Kamar Rumah')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Polynomial Regression: Quadratic vs Cubic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada tahap ini kita ada banding antara Polynomial Regression `Quadratic` dengan `Cubic`.\n",
    "\n",
    "Tahap awal kita lakukan `Training Set` dengan scatter plot dari `X_train` dan `y_train`.\n",
    "\n",
    "- **`Linear`** pertama-tama kita memanggil `LinearRegression()` yang ditampung ke dalam variabel `model`, kemudian melakukan training model dengan 2 parameter `X_train` dan `y_train` dengan deretan angka dari `0` sampai `25` sebanyak `100` jumlah data poin di dalam variabel `X_vis`. Selanjutnya melakukan model prediksi `model.predict` dari `X_vis` yang ditampung ke dalam variabel `y_vis` dengan keterangan tambahan plotting `(X_vis, y_vis, '--r', label='linear')`.\n",
    "\n",
    "- **`Quadratic`** dengan memanggil `PolynomialFeatures` dari parameter `degree=2` yang ditampung pada variabel `quadratic_feature` lalu melakukan training set transformasi fit quadratic `quadratic_feature.fit_transform` dari `X_train` di dalam variabel  `X_train_quadratic`. Berikutnya memanggil `LinearRegression()` di dalam varibel `model` dengan model fit dengan 2 parameter yaitu `X_train_quadratic` dan `y_train`, selanjutnya dengan melakukan transformasi `quadratic_feature.transform` dari `X_vis` di dalam variabel `X_vis_quadratic` kemudian melakukan model prediksi `model.predict` dari `X_vis_quadratic` yang ditampung ke dalam variabel `y_vis` dengan keterangan tambahan plotting `(X_vis, y_vis, '--g', label='quadratic')`.\n",
    "\n",
    "- **`Cubic`** pertama-tama memanggil `PolynomialFeatures` dari parameter `degree=3` yang ditampung pada variabel `cubic_feature` lalu melakukan training set transformasi fit quadratic `cubic_feature.fit_transform` dari `X_train` di dalam variabel  `X_train_cubic`. Berikutnya memanggil `LinearRegression()` di dalam varibel `model` dengan model fit dengan 2 parameter yaitu `X_train_cubic` dan `y_train`, selanjutnya dengan melakukan transformasi `cubic_feature.transform` dari `X_vis` di dalam variabel `X_vis_cubic` kemudian melakukan model prediksi `model.predict` dari `X_vis_cubic` yang ditampung ke dalam variabel `y_vis` dengan keterangan tambahan plotting `(X_vis, y_vis, '--y', label='cubic')`.\n",
    "\n",
    "Dengan keterangan tambahan sebagai berikut :\n",
    "\n",
    "- `plt.title('Perbandingan Jumlah Kamar Rumah (RM) dan Harga (Price)')` sebagai judul\n",
    "- `plt.xlabel('Jumlah Kamar Rumah (RM)')` sebagai X label\n",
    "- `plt.ylabel('Harga (Price)')` sebagai Y label\n",
    "- `plt.xlim(0, 25)` sebagai batasan X\n",
    "- `plt.ylim(0, 25)` sebagai batasan Y\n",
    "- `plt.grid(True)` sebagai tampilan grid pada gambar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training Set\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Linear\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "X_vis = np.linspace(4, 10, 100).reshape(-1, 1)\n",
    "y_vis = model.predict(X_vis)\n",
    "plt.plot(X_vis, y_vis, '--r', label='linear')\n",
    "\n",
    "\n",
    "\n",
    "# Quadratic\n",
    "quadratic_feature = PolynomialFeatures(degree=2)\n",
    "X_train_quadratic = quadratic_feature.fit_transform(X_train)\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_quadratic, y_train)\n",
    "\n",
    "X_vis = np.linspace(4, 10, 100).reshape(-1, 1)\n",
    "X_vis_quadratic = quadratic_feature.transform(X_vis)\n",
    "y_vis_quadratic = model.predict(X_vis_quadratic)\n",
    "\n",
    "plt.scatter(boston_dataset.data[:,5],boston_dataset.target)\n",
    "x = boston_df.RM\n",
    "plt.plot(X_vis, y_vis_quadratic, '--b', label='Quadratic')\n",
    "\n",
    "\n",
    "\n",
    "# Cubic\n",
    "cubic_feature = PolynomialFeatures(degree=3)\n",
    "X_train_cubic = cubic_feature.fit_transform(X_train)\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_cubic, y_train)\n",
    "X_vis_cubic = cubic_feature.transform(X_vis)\n",
    "y_vis = model.predict(X_vis_cubic)\n",
    "plt.plot(X_vis, y_vis, '--y', label='cubic')\n",
    "\n",
    "\n",
    "# Keterangan\n",
    "plt.title('Perbandingan Jumlah Kamar Rumah (RM) dan Harga (Price)')\n",
    "plt.ylabel('Harga (Price) dalam $1000')\n",
    "plt.xlabel('Jumlah Kamar Rumah')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 04 Regression Algorithm dengan KNN (K Nearest Neighbours)\n",
    "\n",
    "\n",
    "Dalam **Regression K Nearest Neighbours (KNN)** digunakan untuk mengestimasi variable berkelanjutan atau kontinu. Salah satu algoritma tersebut menggunakan rata-rata `KNN`, yang dibobotkan oleh kebalikan jarak dari mereka. Algoritma ini bekerja sebagai berikut :\n",
    "\n",
    "`1`. Hitung jarak Euclidean atau Mahalanobis dari contoh query ke contoh berlabel.\n",
    "\n",
    "`2`. Mengurutkan contoh berlabel dengan menambah jarak.\n",
    "\n",
    "`3`. Menemukan jumlah `KNN` yang optimal secara heuristik, berdasarkan RMSE. Ini dilakukan dengan menggunakan validasi silang.\n",
    "\n",
    "`4`. Menghitung rata-rata tertimbang jarak terbalik dengan k-nearest multivariate neighbors.\n",
    "\n",
    "- KNN adalah model machine learning yang dapat digunakan untuk melakukan prediksi berdasarkan kedekatan karakteristik dengan sejumlah tetangga terdekat.\n",
    "- Prediksi yang dilakukan dapat diterapkan baik pada classification maupun regression tasks.\n",
    "\n",
    "Referensi: [https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...    ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786  1.0  273.0   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875  1.0  273.0   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675  1.0  273.0   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889  1.0  273.0   \n",
       "505  0.04741   0.0  11.93   0.0  0.573  6.030  80.8  2.5050  1.0  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  \n",
       "0       15.3  396.90   4.98  \n",
       "1       17.8  396.90   9.14  \n",
       "2       17.8  392.83   4.03  \n",
       "3       18.7  394.63   2.94  \n",
       "4       18.7  396.90   5.33  \n",
       "..       ...     ...    ...  \n",
       "501     21.0  391.99   9.67  \n",
       "502     21.0  396.90   9.08  \n",
       "503     21.0  396.90   5.64  \n",
       "504     21.0  393.45   6.48  \n",
       "505     21.0  396.90   7.88  \n",
       "\n",
       "[506 rows x 13 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "boston_df_knn = pd.DataFrame(boston_dataset.data, columns=boston_dataset.feature_names)\n",
    "boston_df_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Untuk mengetahui harga rumah dari sample dataset yang disediakan, kita dapat menambahkan kolom harga sebagai `Price` seperti tampilan script dibawah ini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...    ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786  1.0  273.0   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875  1.0  273.0   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675  1.0  273.0   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889  1.0  273.0   \n",
       "505  0.04741   0.0  11.93   0.0  0.573  6.030  80.8  2.5050  1.0  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  Price  \n",
       "0       15.3  396.90   4.98   24.0  \n",
       "1       17.8  396.90   9.14   21.6  \n",
       "2       17.8  392.83   4.03   34.7  \n",
       "3       18.7  394.63   2.94   33.4  \n",
       "4       18.7  396.90   5.33   36.2  \n",
       "..       ...     ...    ...    ...  \n",
       "501     21.0  391.99   9.67   22.4  \n",
       "502     21.0  396.90   9.08   20.6  \n",
       "503     21.0  396.90   5.64   23.9  \n",
       "504     21.0  393.45   6.48   22.0  \n",
       "505     21.0  396.90   7.88   11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_df_knn['Price'] = boston_dataset.target\n",
    "boston_df_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Pilihan Features\n",
    "\n",
    "Pada kasus kali ini memilih **`RM`** (Jumlah Kamar Rumah) dan **`AGE`** (Usia) sebagai Features, dan **`Price`** (Harga) sebagai Target. Pemilihan tersebut dikarenakan banyaknya permintaan umum seperti Jumlah Kamar dan Usia yang menempati rumah, maka permintaan tersebut akan sangat memengaruhi Price ((Harga) yang di tentukan dari Sample Dataset.\n",
    "\n",
    "Untuk Keterangan yang dipilih adalah sebagai berikut :\n",
    "- **RM** adalah number of rooms in the dwelling (Jumlah kamar setiap rumah sebagai) **`Features`**.\n",
    "- **AGE** adalah Usia dari setiap rumah sebagai **`Features`**.\n",
    "- **Price** adalah harga sebagai **`Target`**.\n",
    "\n",
    "**Kita juga dapat mengambil dan mengambil lebih dari satu kolom data** dengan menggunakan `double bracket` **[[]]** seperti script dibawah ini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        RM   AGE  Price\n",
       "0    6.575  65.2   24.0\n",
       "1    6.421  78.9   21.6\n",
       "2    7.185  61.1   34.7\n",
       "3    6.998  45.8   33.4\n",
       "4    7.147  54.2   36.2\n",
       "..     ...   ...    ...\n",
       "501  6.593  69.1   22.4\n",
       "502  6.120  76.7   20.6\n",
       "503  6.976  91.0   23.9\n",
       "504  6.794  89.3   22.0\n",
       "505  6.030  80.8   11.9\n",
       "\n",
       "[506 rows x 3 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_df_knn[[\"RM\",\"AGE\",\"Price\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Regression dengan KNN\n",
    "\n",
    "\n",
    "Pada tahap ini kita akan coba untuk melakukan estimasi prediksi terhadap nilai `Price`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Features & Target\n",
    "\n",
    "Sebelum melakukan **Training Model** kita akan kelompokkan terlebih dahulu sekumpulan nilai `Features` dan `Target` dari Dataset yang dimiliki. Pada tahap ini dikonversikan ke dalam `numpy` (np.array) array dengan melakukan `import numpy as np`.\n",
    "- `X_train` sebagai Features untuk training set yang  berisikan `RM` dan `AGE`.\n",
    "- `y_train` sebagai Features untuk training set yang  berisikan `Price`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:\n",
      "[[ 6.575 65.2  ]\n",
      " [ 6.421 78.9  ]\n",
      " [ 7.185 61.1  ]\n",
      " ...\n",
      " [ 6.976 91.   ]\n",
      " [ 6.794 89.3  ]\n",
      " [ 6.03  80.8  ]]\n",
      "\n",
      "y_train: [24.  21.6 34.7 33.4 36.2 28.7 22.9 27.1 16.5 18.9 15.  18.9 21.7 20.4\n",
      " 18.2 19.9 23.1 17.5 20.2 18.2 13.6 19.6 15.2 14.5 15.6 13.9 16.6 14.8\n",
      " 18.4 21.  12.7 14.5 13.2 13.1 13.5 18.9 20.  21.  24.7 30.8 34.9 26.6\n",
      " 25.3 24.7 21.2 19.3 20.  16.6 14.4 19.4 19.7 20.5 25.  23.4 18.9 35.4\n",
      " 24.7 31.6 23.3 19.6 18.7 16.  22.2 25.  33.  23.5 19.4 22.  17.4 20.9\n",
      " 24.2 21.7 22.8 23.4 24.1 21.4 20.  20.8 21.2 20.3 28.  23.9 24.8 22.9\n",
      " 23.9 26.6 22.5 22.2 23.6 28.7 22.6 22.  22.9 25.  20.6 28.4 21.4 38.7\n",
      " 43.8 33.2 27.5 26.5 18.6 19.3 20.1 19.5 19.5 20.4 19.8 19.4 21.7 22.8\n",
      " 18.8 18.7 18.5 18.3 21.2 19.2 20.4 19.3 22.  20.3 20.5 17.3 18.8 21.4\n",
      " 15.7 16.2 18.  14.3 19.2 19.6 23.  18.4 15.6 18.1 17.4 17.1 13.3 17.8\n",
      " 14.  14.4 13.4 15.6 11.8 13.8 15.6 14.6 17.8 15.4 21.5 19.6 15.3 19.4\n",
      " 17.  15.6 13.1 41.3 24.3 23.3 27.  50.  50.  50.  22.7 25.  50.  23.8\n",
      " 23.8 22.3 17.4 19.1 23.1 23.6 22.6 29.4 23.2 24.6 29.9 37.2 39.8 36.2\n",
      " 37.9 32.5 26.4 29.6 50.  32.  29.8 34.9 37.  30.5 36.4 31.1 29.1 50.\n",
      " 33.3 30.3 34.6 34.9 32.9 24.1 42.3 48.5 50.  22.6 24.4 22.5 24.4 20.\n",
      " 21.7 19.3 22.4 28.1 23.7 25.  23.3 28.7 21.5 23.  26.7 21.7 27.5 30.1\n",
      " 44.8 50.  37.6 31.6 46.7 31.5 24.3 31.7 41.7 48.3 29.  24.  25.1 31.5\n",
      " 23.7 23.3 22.  20.1 22.2 23.7 17.6 18.5 24.3 20.5 24.5 26.2 24.4 24.8\n",
      " 29.6 42.8 21.9 20.9 44.  50.  36.  30.1 33.8 43.1 48.8 31.  36.5 22.8\n",
      " 30.7 50.  43.5 20.7 21.1 25.2 24.4 35.2 32.4 32.  33.2 33.1 29.1 35.1\n",
      " 45.4 35.4 46.  50.  32.2 22.  20.1 23.2 22.3 24.8 28.5 37.3 27.9 23.9\n",
      " 21.7 28.6 27.1 20.3 22.5 29.  24.8 22.  26.4 33.1 36.1 28.4 33.4 28.2\n",
      " 22.8 20.3 16.1 22.1 19.4 21.6 23.8 16.2 17.8 19.8 23.1 21.  23.8 23.1\n",
      " 20.4 18.5 25.  24.6 23.  22.2 19.3 22.6 19.8 17.1 19.4 22.2 20.7 21.1\n",
      " 19.5 18.5 20.6 19.  18.7 32.7 16.5 23.9 31.2 17.5 17.2 23.1 24.5 26.6\n",
      " 22.9 24.1 18.6 30.1 18.2 20.6 17.8 21.7 22.7 22.6 25.  19.9 20.8 16.8\n",
      " 21.9 27.5 21.9 23.1 50.  50.  50.  50.  50.  13.8 13.8 15.  13.9 13.3\n",
      " 13.1 10.2 10.4 10.9 11.3 12.3  8.8  7.2 10.5  7.4 10.2 11.5 15.1 23.2\n",
      "  9.7 13.8 12.7 13.1 12.5  8.5  5.   6.3  5.6  7.2 12.1  8.3  8.5  5.\n",
      " 11.9 27.9 17.2 27.5 15.  17.2 17.9 16.3  7.   7.2  7.5 10.4  8.8  8.4\n",
      " 16.7 14.2 20.8 13.4 11.7  8.3 10.2 10.9 11.   9.5 14.5 14.1 16.1 14.3\n",
      " 11.7 13.4  9.6  8.7  8.4 12.8 10.5 17.1 18.4 15.4 10.8 11.8 14.9 12.6\n",
      " 14.1 13.  13.4 15.2 16.1 17.8 14.9 14.1 12.7 13.5 14.9 20.  16.4 17.7\n",
      " 19.5 20.2 21.4 19.9 19.  19.1 19.1 20.1 19.9 19.6 23.2 29.8 13.8 13.3\n",
      " 16.7 12.  14.6 21.4 23.  23.7 25.  21.8 20.6 21.2 19.1 20.6 15.2  7.\n",
      "  8.1 13.6 20.1 21.8 24.5 23.1 19.7 18.3 21.2 17.5 16.8 22.4 20.6 23.9\n",
      " 22.  11.9]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train = np.array(boston_df_knn[['RM', 'AGE']])\n",
    "y_train = np.array(boston_df_knn['Price'])\n",
    "\n",
    "print(f'X_train:\\n{X_train}\\n')\n",
    "print(f'y_train: {y_train}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Training KNN Regression Model\n",
    "\n",
    "Setelah **Training Set** sudah disiapkan selanjutnya kita akan melakukan **Training Model** dengan `KNN`. Regression taks juga sering kali dikenal dengan istilah **Regressor**.\n",
    "\n",
    "Pertama-tama kita melakukan import dengan `from sklearn.neighbors import KNeighborsRegressor` dengan keterangan sebagai berikut :\n",
    "- `K` memiliki nilai `3`\n",
    "- `model = KNeighborsRegressor(n_neighbors=K)` sebagai objek model `KNeighborsRegressor` dengan parameter `n_neighbors=K` yang ditampung ke dalam variabel `mdoel`.\n",
    "- `model.fit(X_train, y_train)` sebagai training model dengan `X_train` dan `y_train` sebagai parameternya dengan `model.fit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(n_neighbors=3)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "K = 3\n",
    "model = KNeighborsRegressor(n_neighbors=K)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Prediksi Harga dengan Jumlah Kamar (RM)\n",
    "\n",
    "Tahapan ini kita akan melakukan Prediksi Harga dengan Jumlah Kamar (RM) berdasarkan `Price` dan `RM`, pada kasus ini kita siapkan data baru dengan `X_new` sebagai variabel dan `np.array(boston_df_knn[['Price', 'RM']])` memiliki parameter `**Price**` (Harga) dan `**RM**` (Jumlah Kamar Rumah)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[24.   ,  6.575],\n",
       "       [21.6  ,  6.421],\n",
       "       [34.7  ,  7.185],\n",
       "       ...,\n",
       "       [23.9  ,  6.976],\n",
       "       [22.   ,  6.794],\n",
       "       [11.9  ,  6.03 ]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = np.array(boston_df_knn[['Price', 'RM']])\n",
    "X_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Tahap berikutnya kita akan memprediksi berat badan dengan memanfaatkan `KNN Regressor` yang sudah ditraining sebelumnya dengan menggunakan `model.predict` dengan parameter `X_new` yang ditampung ke dalam variabel `y_pred`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([33.8       , 33.8       , 33.8       , 33.8       , 33.8       ,\n",
       "       33.8       , 33.8       , 33.8       , 33.        , 32.2       ,\n",
       "       32.2       , 32.2       , 33.8       , 33.8       , 32.2       ,\n",
       "       33.        , 33.8       , 32.2       , 33.        , 33.        ,\n",
       "       32.2       , 33.        , 32.2       , 32.2       , 32.2       ,\n",
       "       32.2       , 32.2       , 32.2       , 33.8       , 33.8       ,\n",
       "       32.2       , 32.2       , 32.2       , 32.2       , 32.2       ,\n",
       "       32.2       , 33.        , 33.        , 33.8       , 33.8       ,\n",
       "       33.8       , 33.8       , 33.8       , 33.8       , 33.8       ,\n",
       "       33.        , 33.        , 32.2       , 33.        , 33.        ,\n",
       "       33.8       , 33.8       , 33.8       , 33.8       , 33.        ,\n",
       "       33.8       , 33.8       , 33.8       , 33.8       , 33.        ,\n",
       "       33.        , 32.2       , 33.8       , 33.8       , 33.8       ,\n",
       "       33.8       , 33.        , 33.8       , 33.        , 33.        ,\n",
       "       33.8       , 33.8       , 33.8       , 33.8       , 33.8       ,\n",
       "       33.8       , 33.8       , 33.8       , 33.8       , 33.        ,\n",
       "       33.8       , 33.8       , 33.8       , 33.8       , 33.8       ,\n",
       "       33.8       , 33.8       , 33.8       , 33.8       , 33.8       ,\n",
       "       33.8       , 33.8       , 33.8       , 33.8       , 33.8       ,\n",
       "       33.8       , 33.8       , 33.8       , 33.8       , 33.8       ,\n",
       "       33.8       , 33.8       , 33.8       , 33.8       , 33.8       ,\n",
       "       33.        , 33.        , 33.8       , 33.8       , 33.8       ,\n",
       "       33.8       , 33.8       , 33.        , 32.2       , 33.8       ,\n",
       "       32.2       , 33.8       , 33.8       , 33.        , 33.        ,\n",
       "       33.        , 33.8       , 33.8       , 32.2       , 33.        ,\n",
       "       33.8       , 33.        , 32.2       , 33.8       , 32.2       ,\n",
       "       33.8       , 33.8       , 33.8       , 33.        , 32.2       ,\n",
       "       33.8       , 32.2       , 33.8       , 32.2       , 32.2       ,\n",
       "       32.2       , 33.        , 32.2       , 33.        , 33.        ,\n",
       "       32.2       , 32.2       , 33.        , 33.        , 32.2       ,\n",
       "       33.8       , 33.        , 33.        , 33.        , 32.2       ,\n",
       "       32.2       , 33.        , 33.8       , 33.8       , 33.8       ,\n",
       "       33.8       , 33.8       , 33.8       , 38.03333333, 33.8       ,\n",
       "       33.8       , 33.8       , 33.8       , 33.8       , 33.8       ,\n",
       "       32.2       , 33.        , 33.        , 33.8       , 33.8       ,\n",
       "       33.8       , 33.8       , 33.8       , 33.8       , 33.8       ,\n",
       "       33.8       , 33.8       , 33.8       , 33.8       , 33.        ,\n",
       "       33.8       , 33.8       , 33.8       , 33.8       , 33.8       ,\n",
       "       33.8       , 33.8       , 33.8       , 33.8       , 33.8       ,\n",
       "       33.8       , 33.8       , 33.8       , 33.8       , 33.8       ,\n",
       "       33.8       , 33.8       , 33.8       , 33.8       , 33.8       ,\n",
       "       33.8       , 33.8       , 33.        , 33.8       , 33.        ,\n",
       "       33.8       , 33.        , 33.        , 33.8       , 33.        ,\n",
       "       33.8       , 33.8       , 33.8       , 33.8       , 33.8       ,\n",
       "       33.8       , 33.8       , 33.8       , 33.8       , 33.8       ,\n",
       "       38.03333333, 33.8       , 33.8       , 33.8       , 33.8       ,\n",
       "       33.8       , 33.8       , 33.8       , 38.03333333, 33.8       ,\n",
       "       33.8       , 33.8       , 33.8       , 33.8       , 33.8       ,\n",
       "       33.8       , 33.8       , 33.8       , 33.8       , 33.        ,\n",
       "       33.        , 33.8       , 33.8       , 33.8       , 33.8       ,\n",
       "       33.8       , 33.8       , 33.8       , 33.8       , 33.8       ,\n",
       "       33.        , 33.8       , 38.03333333, 33.8       , 33.8       ,\n",
       "       33.8       , 33.8       , 38.03333333, 33.8       , 33.8       ,\n",
       "       33.        , 33.8       , 38.03333333, 33.8       , 33.        ,\n",
       "       33.        , 33.8       , 33.8       , 33.8       , 33.8       ,\n",
       "       33.8       , 33.8       , 33.8       , 33.8       , 33.8       ,\n",
       "       33.8       , 33.8       , 33.8       , 33.8       , 33.8       ,\n",
       "       33.8       , 33.8       , 33.8       , 33.8       , 33.8       ,\n",
       "       33.8       , 33.8       , 33.8       , 33.8       , 33.8       ,\n",
       "       33.8       , 33.8       , 33.        , 33.8       , 33.8       ,\n",
       "       33.8       , 33.8       , 33.8       , 33.8       , 33.8       ,\n",
       "       33.8       , 33.8       , 33.8       , 33.8       , 33.8       ,\n",
       "       33.        , 33.8       , 33.8       , 33.8       , 33.8       ,\n",
       "       32.2       , 32.2       , 33.        , 33.8       , 33.8       ,\n",
       "       33.8       , 33.8       , 33.8       , 33.        , 33.8       ,\n",
       "       33.8       , 33.8       , 33.8       , 33.        , 33.8       ,\n",
       "       33.8       , 33.        , 33.8       , 33.8       , 33.8       ,\n",
       "       33.8       , 33.        , 32.2       , 33.8       , 32.2       ,\n",
       "       32.2       , 33.8       , 33.8       , 33.8       , 33.8       ,\n",
       "       32.2       , 32.2       , 33.8       , 33.8       , 33.8       ,\n",
       "       33.8       , 33.8       , 33.        , 33.8       , 33.        ,\n",
       "       33.8       , 32.2       , 33.8       , 33.8       , 33.8       ,\n",
       "       33.8       , 33.8       , 33.        , 32.2       , 33.8       ,\n",
       "       33.        , 33.        , 33.        , 33.8       , 33.8       ,\n",
       "       33.8       , 33.8       , 33.8       , 33.        , 33.        ,\n",
       "       33.8       , 32.2       , 32.2       , 32.2       , 32.2       ,\n",
       "       32.2       , 32.2       , 32.2       , 32.2       , 26.76666667,\n",
       "       23.9       , 33.        , 25.7       , 33.        , 32.2       ,\n",
       "       32.2       , 33.8       , 26.76666667, 32.2       , 32.2       ,\n",
       "       32.2       , 32.2       , 25.96666667, 24.06666667, 24.06666667,\n",
       "       24.06666667, 25.73333333, 32.2       , 25.7       , 25.96666667,\n",
       "       24.06666667, 33.        , 33.        , 33.        , 33.8       ,\n",
       "       32.2       , 33.8       , 33.        , 33.        , 24.7       ,\n",
       "       25.73333333, 26.16666667, 32.16666667, 32.2       , 32.2       ,\n",
       "       32.2       , 32.2       , 33.        , 32.2       , 32.2       ,\n",
       "       25.96666667, 32.2       , 32.2       , 32.2       , 32.2       ,\n",
       "       32.2       , 32.2       , 32.2       , 32.2       , 32.2       ,\n",
       "       32.2       , 32.2       , 32.2       , 25.96666667, 32.2       ,\n",
       "       32.2       , 33.8       , 33.8       , 32.2       , 32.2       ,\n",
       "       32.2       , 32.2       , 32.2       , 32.2       , 32.2       ,\n",
       "       32.2       , 32.2       , 32.2       , 33.8       , 32.2       ,\n",
       "       32.2       , 32.2       , 32.2       , 32.2       , 33.8       ,\n",
       "       33.8       , 33.8       , 33.8       , 33.8       , 33.8       ,\n",
       "       33.        , 32.2       , 32.2       , 33.        , 33.        ,\n",
       "       33.8       , 33.8       , 33.8       , 33.8       , 33.        ,\n",
       "       32.2       , 33.8       , 32.2       , 32.2       , 33.8       ,\n",
       "       33.8       , 33.8       , 33.8       , 33.        , 33.        ,\n",
       "       33.8       , 33.8       , 33.        , 33.        , 23.9       ,\n",
       "       25.7       , 32.2       , 33.8       , 33.        , 33.8       ,\n",
       "       33.        , 33.        , 33.        , 33.8       , 33.        ,\n",
       "       32.2       , 33.8       , 33.8       , 33.8       , 33.8       ,\n",
       "       32.2       ])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_new)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Hasil diatas menunjukkan bahwa data Harga (Price) yang memiliki Jumlah Kamar (RM) diprediksi dengan hasil lebih dari angka `32.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Evaluasi KNN Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Pada tahap ini kita akan mulai mempelajari beberapa matriks yang bisa kita gunakan untuk mengukur peforma dari `Regression Taks`, sebelum melakukannya kita persiapkan terlebih dahulu `Testing Set` sebgai berikut :\n",
    "\n",
    "- `X_test = np.array(boston_df_knn[['RM', 'AGE']])` sebagai nilai **Features** yang ditampung ke dalam variabel `X_test`.\n",
    "- `y_test = np.array(boston_df_knn['Price'])` sebagai nilai **Target** yang ditampung ke dalam variabel `y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test:\n",
      "[[ 6.575 65.2  ]\n",
      " [ 6.421 78.9  ]\n",
      " [ 7.185 61.1  ]\n",
      " ...\n",
      " [ 6.976 91.   ]\n",
      " [ 6.794 89.3  ]\n",
      " [ 6.03  80.8  ]]\n",
      "\n",
      "y_test: [24.  21.6 34.7 33.4 36.2 28.7 22.9 27.1 16.5 18.9 15.  18.9 21.7 20.4\n",
      " 18.2 19.9 23.1 17.5 20.2 18.2 13.6 19.6 15.2 14.5 15.6 13.9 16.6 14.8\n",
      " 18.4 21.  12.7 14.5 13.2 13.1 13.5 18.9 20.  21.  24.7 30.8 34.9 26.6\n",
      " 25.3 24.7 21.2 19.3 20.  16.6 14.4 19.4 19.7 20.5 25.  23.4 18.9 35.4\n",
      " 24.7 31.6 23.3 19.6 18.7 16.  22.2 25.  33.  23.5 19.4 22.  17.4 20.9\n",
      " 24.2 21.7 22.8 23.4 24.1 21.4 20.  20.8 21.2 20.3 28.  23.9 24.8 22.9\n",
      " 23.9 26.6 22.5 22.2 23.6 28.7 22.6 22.  22.9 25.  20.6 28.4 21.4 38.7\n",
      " 43.8 33.2 27.5 26.5 18.6 19.3 20.1 19.5 19.5 20.4 19.8 19.4 21.7 22.8\n",
      " 18.8 18.7 18.5 18.3 21.2 19.2 20.4 19.3 22.  20.3 20.5 17.3 18.8 21.4\n",
      " 15.7 16.2 18.  14.3 19.2 19.6 23.  18.4 15.6 18.1 17.4 17.1 13.3 17.8\n",
      " 14.  14.4 13.4 15.6 11.8 13.8 15.6 14.6 17.8 15.4 21.5 19.6 15.3 19.4\n",
      " 17.  15.6 13.1 41.3 24.3 23.3 27.  50.  50.  50.  22.7 25.  50.  23.8\n",
      " 23.8 22.3 17.4 19.1 23.1 23.6 22.6 29.4 23.2 24.6 29.9 37.2 39.8 36.2\n",
      " 37.9 32.5 26.4 29.6 50.  32.  29.8 34.9 37.  30.5 36.4 31.1 29.1 50.\n",
      " 33.3 30.3 34.6 34.9 32.9 24.1 42.3 48.5 50.  22.6 24.4 22.5 24.4 20.\n",
      " 21.7 19.3 22.4 28.1 23.7 25.  23.3 28.7 21.5 23.  26.7 21.7 27.5 30.1\n",
      " 44.8 50.  37.6 31.6 46.7 31.5 24.3 31.7 41.7 48.3 29.  24.  25.1 31.5\n",
      " 23.7 23.3 22.  20.1 22.2 23.7 17.6 18.5 24.3 20.5 24.5 26.2 24.4 24.8\n",
      " 29.6 42.8 21.9 20.9 44.  50.  36.  30.1 33.8 43.1 48.8 31.  36.5 22.8\n",
      " 30.7 50.  43.5 20.7 21.1 25.2 24.4 35.2 32.4 32.  33.2 33.1 29.1 35.1\n",
      " 45.4 35.4 46.  50.  32.2 22.  20.1 23.2 22.3 24.8 28.5 37.3 27.9 23.9\n",
      " 21.7 28.6 27.1 20.3 22.5 29.  24.8 22.  26.4 33.1 36.1 28.4 33.4 28.2\n",
      " 22.8 20.3 16.1 22.1 19.4 21.6 23.8 16.2 17.8 19.8 23.1 21.  23.8 23.1\n",
      " 20.4 18.5 25.  24.6 23.  22.2 19.3 22.6 19.8 17.1 19.4 22.2 20.7 21.1\n",
      " 19.5 18.5 20.6 19.  18.7 32.7 16.5 23.9 31.2 17.5 17.2 23.1 24.5 26.6\n",
      " 22.9 24.1 18.6 30.1 18.2 20.6 17.8 21.7 22.7 22.6 25.  19.9 20.8 16.8\n",
      " 21.9 27.5 21.9 23.1 50.  50.  50.  50.  50.  13.8 13.8 15.  13.9 13.3\n",
      " 13.1 10.2 10.4 10.9 11.3 12.3  8.8  7.2 10.5  7.4 10.2 11.5 15.1 23.2\n",
      "  9.7 13.8 12.7 13.1 12.5  8.5  5.   6.3  5.6  7.2 12.1  8.3  8.5  5.\n",
      " 11.9 27.9 17.2 27.5 15.  17.2 17.9 16.3  7.   7.2  7.5 10.4  8.8  8.4\n",
      " 16.7 14.2 20.8 13.4 11.7  8.3 10.2 10.9 11.   9.5 14.5 14.1 16.1 14.3\n",
      " 11.7 13.4  9.6  8.7  8.4 12.8 10.5 17.1 18.4 15.4 10.8 11.8 14.9 12.6\n",
      " 14.1 13.  13.4 15.2 16.1 17.8 14.9 14.1 12.7 13.5 14.9 20.  16.4 17.7\n",
      " 19.5 20.2 21.4 19.9 19.  19.1 19.1 20.1 19.9 19.6 23.2 29.8 13.8 13.3\n",
      " 16.7 12.  14.6 21.4 23.  23.7 25.  21.8 20.6 21.2 19.1 20.6 15.2  7.\n",
      "  8.1 13.6 20.1 21.8 24.5 23.1 19.7 18.3 21.2 17.5 16.8 22.4 20.6 23.9\n",
      " 22.  11.9]\n"
     ]
    }
   ],
   "source": [
    "X_test = np.array(boston_df_knn[['RM', 'AGE']])\n",
    "y_test = np.array(boston_df_knn['Price'])\n",
    "\n",
    "print(f'X_test:\\n{X_test}\\n')\n",
    "print(f'y_test: {y_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Tahap berikutnya kita akan lakukan predikis terhadap `Testing Set` ini dengan memanfaatkan `KNN Regressor` yang sudah ditraining sebelumnya yang menggunakan `model.predict` dengan parameter `X_test` yang ditampung ke dalam variabel `y_pred`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21.83333333, 17.66666667, 26.46666667, 25.5       , 27.1       ,\n",
       "       24.7       , 21.4       , 22.63333333, 20.        , 16.66666667,\n",
       "       15.6       , 19.9       , 22.16666667, 21.7       , 19.06666667,\n",
       "       20.73333333, 23.8       , 17.76666667, 19.3       , 20.53333333,\n",
       "       12.6       , 17.06666667, 18.        , 11.5       , 16.6       ,\n",
       "       13.76666667, 18.7       , 17.66666667, 15.6       , 21.36666667,\n",
       "       13.7       , 17.53333333, 17.96666667, 14.26666667, 15.13333333,\n",
       "       21.93333333, 21.56666667, 20.9       , 24.1       , 33.1       ,\n",
       "       37.36666667, 24.7       , 24.73333333, 24.73333333, 22.66666667,\n",
       "       20.13333333, 20.06666667, 18.53333333, 14.63333333, 25.33333333,\n",
       "       19.83333333, 26.5       , 26.63333333, 25.63333333, 20.56666667,\n",
       "       34.4       , 26.3       , 26.2       , 23.8       , 20.56666667,\n",
       "       21.4       , 15.8       , 25.43333333, 26.4       , 24.63333333,\n",
       "       23.8       , 20.9       , 21.2       , 19.3       , 23.43333333,\n",
       "       24.73333333, 22.6       , 23.76666667, 24.06666667, 24.06666667,\n",
       "       20.96666667, 19.76666667, 20.93333333, 22.16666667, 19.3       ,\n",
       "       29.93333333, 23.46666667, 24.23333333, 21.86666667, 20.1       ,\n",
       "       24.6       , 20.96666667, 20.73333333, 17.4       , 27.46666667,\n",
       "       24.83333333, 22.2       , 22.16666667, 23.76666667, 15.83333333,\n",
       "       31.33333333, 20.53333333, 26.26666667, 36.5       , 32.7       ,\n",
       "       26.06666667, 30.46666667, 22.56666667, 18.6       , 19.9       ,\n",
       "       15.86666667, 21.3       , 16.8       , 28.96666667, 20.33333333,\n",
       "       22.2       , 26.4       , 21.43333333, 13.73333333, 20.66666667,\n",
       "       16.03333333, 21.36666667, 19.33333333, 20.13333333, 20.2       ,\n",
       "       20.53333333, 19.56666667, 21.43333333, 15.3       , 17.33333333,\n",
       "       19.13333333, 15.96666667, 14.43333333, 16.76666667, 14.13333333,\n",
       "       16.76666667, 20.13333333, 20.13333333, 13.63333333, 16.1       ,\n",
       "       16.06666667, 15.8       , 16.06666667, 14.16666667, 20.13333333,\n",
       "       15.8       , 26.06666667, 12.66666667, 10.96666667,  9.03333333,\n",
       "       12.33333333, 20.        , 12.23333333, 14.56666667, 14.26666667,\n",
       "       17.53333333, 12.66666667, 19.23333333, 16.1       , 22.63333333,\n",
       "       19.33333333, 14.56666667, 37.03333333, 17.53333333, 15.3       ,\n",
       "       21.26666667, 27.13333333, 38.33333333, 31.7       , 19.13333333,\n",
       "       21.43333333, 44.16666667, 20.36666667, 16.46666667, 17.56666667,\n",
       "       16.4       , 17.96666667, 21.26666667, 20.66666667, 23.7       ,\n",
       "       29.93333333, 20.56666667, 22.33333333, 24.53333333, 30.        ,\n",
       "       37.23333333, 25.33333333, 20.56666667, 18.16666667, 31.        ,\n",
       "       24.86666667, 43.23333333, 33.23333333, 25.93333333, 30.06666667,\n",
       "       33.1       , 27.43333333, 35.6       , 28.3       , 26.4       ,\n",
       "       45.03333333, 34.63333333, 31.93333333, 30.56666667, 37.36666667,\n",
       "       27.3       , 22.33333333, 37.36666667, 41.93333333, 45.03333333,\n",
       "       23.86666667, 23.43333333, 21.36666667, 21.3       , 17.66666667,\n",
       "       21.3       , 17.6       , 21.8       , 27.33333333, 26.53333333,\n",
       "       23.73333333, 21.1       , 22.56666667, 17.63333333, 21.26666667,\n",
       "       23.13333333, 20.33333333, 24.36666667, 21.53333333, 34.66666667,\n",
       "       37.23333333, 37.06666667, 29.73333333, 35.33333333, 29.1       ,\n",
       "       21.8       , 21.7       , 35.        , 36.        , 24.83333333,\n",
       "       21.56666667, 18.03333333, 30.46666667, 26.4       , 23.33333333,\n",
       "       27.1       , 20.9       , 22.9       , 23.76666667, 19.5       ,\n",
       "       16.16666667, 23.36666667, 21.96666667, 24.9       , 27.3       ,\n",
       "       27.3       , 26.53333333, 26.16666667, 30.43333333, 22.16666667,\n",
       "       20.03333333, 34.63333333, 37.06666667, 31.2       , 24.93333333,\n",
       "       26.46666667, 27.16666667, 45.1       , 19.5       , 28.26666667,\n",
       "       20.9       , 27.66666667, 36.26666667, 42.9       , 21.56666667,\n",
       "       21.13333333, 27.56666667, 24.7       , 34.16666667, 29.93333333,\n",
       "       26.76666667, 37.3       , 28.23333333, 25.3       , 30.76666667,\n",
       "       32.7       , 36.5       , 37.3       , 38.1       , 31.4       ,\n",
       "       25.3       , 21.76666667, 20.9       , 20.93333333, 24.03333333,\n",
       "       30.93333333, 32.96666667, 24.03333333, 22.06666667, 22.6       ,\n",
       "       27.43333333, 22.9       , 22.46666667, 22.7       , 28.3       ,\n",
       "       23.96666667, 26.2       , 24.66666667, 27.6       , 33.23333333,\n",
       "       31.33333333, 30.46666667, 24.5       , 20.        , 19.5       ,\n",
       "       18.03333333, 22.9       , 18.53333333, 18.9       , 21.36666667,\n",
       "       11.16666667, 20.2       , 20.03333333, 22.73333333, 24.7       ,\n",
       "       23.13333333, 22.26666667, 24.        , 20.16666667, 22.73333333,\n",
       "       30.8       , 25.93333333, 23.36666667, 26.26666667, 23.5       ,\n",
       "       22.16666667, 21.73333333, 24.03333333, 22.33333333, 22.33333333,\n",
       "       21.56666667, 21.06666667, 17.7       , 19.43333333, 20.4       ,\n",
       "       22.8       , 37.3       , 22.66666667, 24.23333333, 32.33333333,\n",
       "       20.43333333, 21.8       , 28.23333333, 25.86666667, 34.63333333,\n",
       "       22.16666667, 26.3       , 22.06666667, 26.3       , 20.93333333,\n",
       "       21.33333333, 17.53333333, 20.33333333, 20.2       , 17.33333333,\n",
       "       20.23333333, 20.33333333, 15.1       , 17.06666667, 37.23333333,\n",
       "       20.7       , 17.8       , 16.26666667, 26.06666667, 27.46666667,\n",
       "       35.43333333, 26.2       , 32.        , 24.66666667, 16.26666667,\n",
       "       38.33333333, 13.4       , 15.2       , 16.46666667, 26.2       ,\n",
       "       28.26666667, 14.4       , 13.06666667, 13.06666667, 17.8       ,\n",
       "        7.43333333, 11.8       , 14.73333333, 24.66666667, 13.13333333,\n",
       "       17.3       , 19.33333333, 12.26666667, 21.26666667, 16.4       ,\n",
       "       16.76666667, 16.46666667, 11.2       , 13.4       , 11.16666667,\n",
       "       12.9       , 12.        , 12.        , 15.1       , 13.        ,\n",
       "       12.36666667, 16.26666667, 20.        , 14.7       , 24.93333333,\n",
       "       11.5       , 18.63333333, 11.8       , 26.9       , 11.8       ,\n",
       "       12.        , 17.7       , 11.53333333, 12.9       , 19.5       ,\n",
       "       12.        , 13.73333333, 13.96666667, 16.8       , 16.16666667,\n",
       "       13.63333333, 17.7       , 17.66666667,  9.4       , 20.23333333,\n",
       "       15.83333333, 15.8       , 19.76666667, 20.23333333, 15.26666667,\n",
       "       14.53333333, 13.4       , 24.16666667, 13.13333333, 15.66666667,\n",
       "       15.33333333, 18.23333333, 26.2       , 15.3       , 14.96666667,\n",
       "       12.3       , 13.53333333, 14.03333333, 15.23333333, 16.06666667,\n",
       "       21.13333333, 15.1       , 18.        , 22.36666667, 15.8       ,\n",
       "       17.4       , 14.16666667, 14.83333333, 19.16666667, 18.9       ,\n",
       "       18.9       , 21.36666667, 20.        , 18.9       , 20.9       ,\n",
       "       18.76666667, 19.06666667, 16.4       , 16.36666667, 20.73333333,\n",
       "       19.56666667, 20.23333333, 21.        , 25.03333333, 14.63333333,\n",
       "       17.53333333, 13.43333333, 12.26666667, 13.56666667, 20.23333333,\n",
       "       22.36666667, 21.        , 21.7       , 22.66666667, 20.9       ,\n",
       "       20.73333333, 16.46666667, 21.63333333, 14.83333333,  9.26666667,\n",
       "        9.03333333, 12.06666667, 20.2       , 21.8       , 23.73333333,\n",
       "       21.73333333, 20.86666667, 16.36666667, 20.9       , 19.2       ,\n",
       "       19.9       , 24.46666667, 22.        , 27.13333333, 19.53333333,\n",
       "       16.        ])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Coefficient of Determination atau $R^2$\n",
    "\n",
    "**`Coefficient of Determination`**, denoted R2 or r2 and pronounced `\"R squared\"`, is the proportion of the variance in the dependent variable that is predictable from the independent variable(s).\n",
    "\n",
    "It is a statistic used in the context of statistical models whose main purpose is either the prediction of future outcomes or the testing of hypotheses, on the basis of other related information. It provides a measure of how well observed outcomes are replicated by the model, based on the proportion of total variation of outcomes explained by the model.\n",
    "\n",
    "Referensi: [https://en.wikipedia.org/wiki/Coefficient_of_determination](https://en.wikipedia.org/wiki/Coefficient_of_determination)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Sebelum melakukan `R2` terlebih dahulu kita melakukan import `from sklearn.metrics import r2_score` dengan keterangan sebagai berikut :\n",
    "- `r_squared = r2_score(y_test, y_pred)` dengan r2_score memiliki 2 parameter yaitu `y_test` dan `y_pred` yang ditampung ke dalam variabel `r_squared`.\n",
    "- `print(f'R-squared: {r_squared}')` untuk menampilkan hasil `r_squared`. Jika hasil semakin mendekati nilai `1` akan lebih baik daripada hasil mendekati `0` seperti pada penjelasan sebelumnya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.679240598928071\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r_squared = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'R-squared: {r_squared}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Mean Absolute Error (MAE) atau Mean Absolute Deviation (MAD)\n",
    "\n",
    "$MAE$ is the average of the absolute values of the errors of the predictions.\n",
    "\n",
    "**`Mean Absolute Error (MAE)`** is a measure of errors between paired observations expressing the same phenomenon. Examples of Y versus X include comparisons of predicted versus observed, subsequent time versus initial time, and one technique of measurement versus an alternative technique of measurement. MAE dikalkulasikan sebagai berikut :\n",
    "\n",
    "$MAE = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i|$\n",
    "\n",
    "- $y_i$\n",
    "\n",
    "Information of the Calculate MAE :\n",
    "- $y_i$ merepresentasikan setiap nilai Target pada Testing Set.\n",
    "- $\\hat{y}_i$ adalah nilai prediksi yang dihasilkan oleh kita.\n",
    "- Nilai **n** merupakan nilai jumlah data point.\n",
    "\n",
    "Untuk menghindari nilai negatif kita gunakan `absolute` function.\n",
    "\n",
    "Referensi: [https://en.wikipedia.org/wiki/Mean_absolute_error](https://en.wikipedia.org/wiki/Mean_absolute_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Selanjutnya untuk menggunakan `Mean Absolute Error (MAE)` telebih dahulu kita melakukan import `from sklearn.metrics import mean_absolute_error` dengan keterangan sebagai berikut :\n",
    "\n",
    "- `MAE = mean_absolute_error(y_test, y_pred)` dengan mean_absolute_error memiliki 2 parameter yaitu `y_test` dan `y_pred`.\n",
    "- `print(f'MAE: {MAE}')` untuk menampilkan hasil dari MAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 3.4915678524374174\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "MAE = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(f'MAE: {MAE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Mean Squared Error (MSE) atau Mean Squared Deviation (MSD)\n",
    "\n",
    "$MSE$ is the average of the squares of the errors of the predictions.\n",
    "\n",
    "**Mean Squared Error (MSE) or Mean Squared Deviation (MSD)** of an estimator (of a procedure for estimating an unobserved quantity) measures the average of the squares of the errors—that is, the average squared difference between the estimated values and the actual value. MSE is a risk function, corresponding to the expected value of the squared error loss. The fact that MSE is almost always strictly positive (and not zero) is because of randomness or because the estimator does not account for information that could produce a more accurate estimate. MSE atau MSD dikalkulasikan sebagai berikut :\n",
    "\n",
    "$MSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$\n",
    "\n",
    "\n",
    "Referensi: [https://en.wikipedia.org/wiki/Mean_squared_error](https://en.wikipedia.org/wiki/Mean_squared_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Selanjutnya untuk menggunakan `Mean Squared Error (MSE) or Mean Squared Deviation (MSD)` telebih dahulu kita melakukan import `from sklearn.metrics import mean_squared_error` dengan keterangan sebagai berikut :\n",
    "\n",
    "- `MSE = mean_squared_error(y_test, y_pred)` dengan mean_squared_error memiliki 2 parameter yaitu `y_test` dan `y_pred`.\n",
    "- `print(f'MSE: {MSE}')` untuk menampilkan hasil dari MSE.\n",
    "\n",
    "\n",
    "Untuk menghindari kemunculan nilai negatif $(y_i - \\hat{y}_i)^2$ hasil selisih harus dipangkatkan dengan 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 27.078366271409745\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "MSE = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f'MSE: {MSE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Jika hasil dari `Mean Squared Error (MSE) or Mean Squared Deviation (MSD)` lebih kecil akan didefiniskan lebih baik dikarenakan ini untuk menghitung dari `Mean Sqaured Error`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Permasalahan Scaling pada Features\n",
    "\n",
    "**Feature Scaling** adalah suatu cara untuk membuat numerical data pada dataset memiliki rentang nilai (scale) yang sama. Tidak ada lagi satu variabel data yang mendominasi variabel data lainnya.\n",
    "\n",
    "Referensi : https://medium.com/machine-learning-id/melakukan-feature-scaling-pada-dataset-229531bb08de#:~:text=Feature%20Scaling%20adalah%20suatu%20cara,yang%20mendominasi%20variabel%20data%20lainnya."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Untuk melakukan Scaling pada Features terlebih dahulu kita melakukan import dengan `from scipy.spatial.distance import euclidean` dengan keterangan sebagai berikut :\n",
    "\n",
    "- `X_train = np.array(boston_df_knn[['RM', 'AGE']])` dengan np.array memiliki 2 parameter yaitu `RM` dan `AGE` yang ditampung ke dalam variabel `X_train`.\n",
    "- `X_new = np.array(boston_df_knn['Price'])` dengan np.array memiliki parameter yaitu `Price` yang ditampung ke dalam variabel `X_new`.\n",
    "- `[euclidean(X_new[0], d) for d in X_train]` sebagai proses pengukuran untuk mengetahui apakah hasilnya akan berdampak pada eksistensi **`euclidean`** seperti script dibawah ini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[44.73332789990032,\n",
       " 57.64573914002665,\n",
       " 40.732716887043026,\n",
       " 27.646120957559305,\n",
       " 34.584152570216325,\n",
       " 38.89466415846781,\n",
       " 46.24206033472124,\n",
       " 74.2714452801344,\n",
       " 78.1883633349618,\n",
       " 64.46290418527543,\n",
       " 72.47523804031277,\n",
       " 61.58641149636826,\n",
       " 23.51612895440064,\n",
       " 41.88888397892691,\n",
       " 63.09360677596423,\n",
       " 37.23242613636667,\n",
       " 18.826423584951023,\n",
       " 60.4454307619691,\n",
       " 22.41963282482566,\n",
       " 49.0321581107746,\n",
       " 76.35754645089114,\n",
       " 67.64836454046765,\n",
       " 70.01569941091785,\n",
       " 78.14580583115129,\n",
       " 72.39303679222193,\n",
       " 64.3854548869541,\n",
       " 68.74923249753411,\n",
       " 67.24098607992003,\n",
       " 72.54367667136813,\n",
       " 65.62834963641855,\n",
       " 72.4460100281582,\n",
       " 78.08593461053022,\n",
       " 60.74374453390242,\n",
       " 73.32021140858774,\n",
       " 75.0663920539678,\n",
       " 47.74993705755014,\n",
       " 41.57534462875804,\n",
       " 25.212546479877833,\n",
       " 19.070006712112082,\n",
       " 17.54348953315731,\n",
       " 18.852707391777976,\n",
       " 27.241198578623518,\n",
       " 24.91394310421375,\n",
       " 24.95392796735616,\n",
       " 24.03166163626644,\n",
       " 20.77472319911868,\n",
       " 20.450911862310686,\n",
       " 64.07160759650097,\n",
       " 73.68641123707953,\n",
       " 42.219502649841814,\n",
       " 28.217430233811157,\n",
       " 42.905398553095864,\n",
       " 17.72780643508948,\n",
       " 18.18878786505577,\n",
       " 29.749025933633526,\n",
       " 16.882120749479316,\n",
       " 21.14825498711419,\n",
       " 23.82309501303305,\n",
       " 18.59680147229625,\n",
       " 29.408728789255754,\n",
       " 45.98076859949168,\n",
       " 71.70484750698519,\n",
       " 47.18296234871227,\n",
       " 25.95204508319142,\n",
       " 39.315706988428936,\n",
       " 18.763904177968936,\n",
       " 19.547976084495296,\n",
       " 18.307563573561612,\n",
       " 22.419206854837658,\n",
       " 20.227536305739264,\n",
       " 24.73705497831138,\n",
       " 19.1743453864793,\n",
       " 24.16824828157804,\n",
       " 25.141201741364714,\n",
       " 25.263541497581055,\n",
       " 27.47336521069088,\n",
       " 53.51900448438853,\n",
       " 28.181901994010268,\n",
       " 34.60912920025582,\n",
       " 22.075141585049916,\n",
       " 19.71310551384535,\n",
       " 49.548553571219415,\n",
       " 19.505363467518368,\n",
       " 28.867038105770398,\n",
       " 29.76822670230795,\n",
       " 36.49831365967474,\n",
       " 27.724902614797408,\n",
       " 37.35637349904297,\n",
       " 64.57594017124333,\n",
       " 42.60434533002473,\n",
       " 45.62424672254875,\n",
       " 52.911189979058314,\n",
       " 34.415742967426986,\n",
       " 18.451518121824016,\n",
       " 56.1781808267231,\n",
       " 38.00435007995795,\n",
       " 48.964462306860874,\n",
       " 54.38563009656135,\n",
       " 20.693051974032247,\n",
       " 41.919912404488635,\n",
       " 58.50783305677968,\n",
       " 50.336705901359885,\n",
       " 63.87130830819109,\n",
       " 65.86840493742051,\n",
       " 68.3667747447545,\n",
       " 74.93114306481652,\n",
       " 70.28755861459409,\n",
       " 63.75644382335013,\n",
       " 75.17160817755597,\n",
       " 69.51005999853547,\n",
       " 35.230356583492025,\n",
       " 60.137602421446765,\n",
       " 71.2344689669264,\n",
       " 73.61152398911464,\n",
       " 62.76113858113156,\n",
       " 66.6951061473029,\n",
       " 51.67151029339089,\n",
       " 61.29603935818365,\n",
       " 52.339606265236654,\n",
       " 45.06879586809482,\n",
       " 49.16489499632843,\n",
       " 62.73648074286602,\n",
       " 71.22229651590857,\n",
       " 75.22103918452603,\n",
       " 74.05140539517127,\n",
       " 66.87199859432945,\n",
       " 73.92321535891143,\n",
       " 74.29095671075989,\n",
       " 76.83560217112897,\n",
       " 73.04580596447684,\n",
       " 76.92679483768968,\n",
       " 75.78957894064328,\n",
       " 75.97339260556949,\n",
       " 73.67767425753884,\n",
       " 76.60396235835324,\n",
       " 76.27379776174779,\n",
       " 71.80766925614562,\n",
       " 76.44097144856285,\n",
       " 76.38591787103171,\n",
       " 76.02497485037402,\n",
       " 71.84654672285927,\n",
       " 78.33440087854123,\n",
       " 78.24224184543795,\n",
       " 78.22681780566049,\n",
       " 76.23080354423662,\n",
       " 78.07263861302499,\n",
       " 78.1890681873112,\n",
       " 74.19371587944629,\n",
       " 72.29112390881747,\n",
       " 73.24943964973384,\n",
       " 75.44874342227311,\n",
       " 78.24200416656005,\n",
       " 66.75735273361279,\n",
       " 76.71251971484186,\n",
       " 74.18471972717832,\n",
       " 61.257743216674235,\n",
       " 72.46197612541353,\n",
       " 75.35583088918867,\n",
       " 78.08731238812102,\n",
       " 77.98653794085234,\n",
       " 70.85917371801621,\n",
       " 68.81026900833915,\n",
       " 75.94745027978227,\n",
       " 71.62506980799391,\n",
       " 70.18630433353789,\n",
       " 71.28375832544185,\n",
       " 73.96699967553097,\n",
       " 58.098908156694314,\n",
       " 74.23629678937385,\n",
       " 73.3425497511506,\n",
       " 72.8894754062615,\n",
       " 75.50645270438812,\n",
       " 67.08085556997615,\n",
       " 62.61954212544195,\n",
       " 48.24091500997883,\n",
       " 19.68380339263731,\n",
       " 29.351667755001593,\n",
       " 52.47017462330386,\n",
       " 53.23475932133066,\n",
       " 38.3802084413308,\n",
       " 61.482235035821525,\n",
       " 42.16724719494979,\n",
       " 70.24951263176138,\n",
       " 73.69266563912585,\n",
       " 68.32314992738551,\n",
       " 48.22401278408921,\n",
       " 33.728275393206815,\n",
       " 24.266633965179434,\n",
       " 18.17424375317994,\n",
       " 22.46673596675761,\n",
       " 17.231320349874526,\n",
       " 18.552145994466517,\n",
       " 16.978506530316498,\n",
       " 22.240728405337805,\n",
       " 18.156563992121416,\n",
       " 18.00043402254512,\n",
       " 19.527784538958844,\n",
       " 21.074473872436297,\n",
       " 22.005660090076823,\n",
       " 19.119116742151032,\n",
       " 19.658032073429936,\n",
       " 22.924969880023834,\n",
       " 18.371774546842232,\n",
       " 18.584014878384057,\n",
       " 17.813566627713833,\n",
       " 18.188619546298728,\n",
       " 33.53535859358,\n",
       " 51.99566413654124,\n",
       " 39.417129474379536,\n",
       " 78.25628623950921,\n",
       " 70.44892901953868,\n",
       " 67.22329370091887,\n",
       " 34.91454208492501,\n",
       " 19.481545754893272,\n",
       " 23.391317705507742,\n",
       " 25.613299748372913,\n",
       " 36.77015833525877,\n",
       " 63.5177940737869,\n",
       " 72.0958140324388,\n",
       " 70.6347728034854,\n",
       " 66.71520367202666,\n",
       " 69.62336458402451,\n",
       " 56.363273866942826,\n",
       " 59.40011720527157,\n",
       " 56.53360731458766,\n",
       " 60.94526745367519,\n",
       " 64.505593555908,\n",
       " 58.38060096470402,\n",
       " 17.752368743353664,\n",
       " 17.640654863127956,\n",
       " 47.63921033140662,\n",
       " 55.439802885652476,\n",
       " 51.72832462974226,\n",
       " 49.00119395484156,\n",
       " 45.87636729297559,\n",
       " 41.559131319121676,\n",
       " 55.29857286585251,\n",
       " 50.42535239341416,\n",
       " 18.36206309214735,\n",
       " 25.17521074390441,\n",
       " 34.79371507901966,\n",
       " 44.83078211452483,\n",
       " 33.85926998622386,\n",
       " 23.92585315093278,\n",
       " 55.633332175953655,\n",
       " 49.727417236369725,\n",
       " 20.950743757680776,\n",
       " 57.990991334861654,\n",
       " 30.63673430703736,\n",
       " 18.463952014669015,\n",
       " 20.681034040879094,\n",
       " 23.161041513714363,\n",
       " 24.213712003738706,\n",
       " 22.161657902783354,\n",
       " 19.599073039304688,\n",
       " 18.774700423708495,\n",
       " 19.43733819225256,\n",
       " 64.7331261102073,\n",
       " 77.8060980193712,\n",
       " 77.91275225532725,\n",
       " 60.19118879869378,\n",
       " 67.44442452864432,\n",
       " 69.27966804192988,\n",
       " 72.44473016721092,\n",
       " 69.65485220715065,\n",
       " 42.95897577922453,\n",
       " 62.93555589648827,\n",
       " 45.777551365270725,\n",
       " 33.03333013790768,\n",
       " 41.6309548293094,\n",
       " 25.62839706263347,\n",
       " 19.357365523231714,\n",
       " 38.84599649899588,\n",
       " 32.23078467862673,\n",
       " 19.40351937149547,\n",
       " 25.444553759105304,\n",
       " 30.083106372181717,\n",
       " 17.547258361350924,\n",
       " 19.30000839378056,\n",
       " 19.043826926329697,\n",
       " 43.61241107758204,\n",
       " 21.548295152981364,\n",
       " 30.462698911948042,\n",
       " 16.09689190496103,\n",
       " 17.212081338408783,\n",
       " 19.24336792248176,\n",
       " 19.287895167695204,\n",
       " 19.23043631850302,\n",
       " 27.916289599443548,\n",
       " 17.46966585255711,\n",
       " 17.57712493555189,\n",
       " 17.25340267889207,\n",
       " 17.38035960502544,\n",
       " 18.729765855450516,\n",
       " 25.66254237210335,\n",
       " 18.720621891379572,\n",
       " 32.14867650464013,\n",
       " 38.56947108789541,\n",
       " 18.080625680545463,\n",
       " 21.991081851514263,\n",
       " 28.999355872156883,\n",
       " 23.917945145852304,\n",
       " 18.378928831681133,\n",
       " 18.146689064399602,\n",
       " 23.946642687441596,\n",
       " 38.27549419667889,\n",
       " 50.68832607218353,\n",
       " 49.374556210663805,\n",
       " 61.022890991823715,\n",
       " 55.69828349240217,\n",
       " 23.50461080298927,\n",
       " 33.89783007804482,\n",
       " 68.79049737427403,\n",
       " 61.41607896959883,\n",
       " 65.65667893672357,\n",
       " 56.73091771688521,\n",
       " 61.90107750273819,\n",
       " 51.06060638104487,\n",
       " 46.65440948077685,\n",
       " 39.127800462075555,\n",
       " 33.31269241595461,\n",
       " 35.05275133281266,\n",
       " 31.51722832039645,\n",
       " 53.52277332126951,\n",
       " 23.842026444914453,\n",
       " 19.878625732177767,\n",
       " 18.35416421415042,\n",
       " 26.629098539004282,\n",
       " 18.22112576105,\n",
       " 18.930475139309106,\n",
       " 19.64883548712239,\n",
       " 18.81569653241676,\n",
       " 17.982629423974682,\n",
       " 22.617114227946942,\n",
       " 22.873261682584754,\n",
       " 20.806714517193722,\n",
       " 28.740618660703877,\n",
       " 39.93934181981471,\n",
       " 22.33314758380466,\n",
       " 27.97320548310472,\n",
       " 38.92817776367139,\n",
       " 30.347225260310037,\n",
       " 39.74093104093059,\n",
       " 36.73130022201774,\n",
       " 17.609936853946976,\n",
       " 30.393193251121215,\n",
       " 33.59423170724403,\n",
       " 17.871213053399593,\n",
       " 18.27657585544951,\n",
       " 20.033165526196804,\n",
       " 26.88419796088401,\n",
       " 21.097422615096846,\n",
       " 18.9324973524361,\n",
       " 21.088669564484146,\n",
       " 18.45685696428295,\n",
       " 18.61607090661185,\n",
       " 75.52465123388522,\n",
       " 69.27435329903847,\n",
       " 62.03067087336716,\n",
       " 60.02724834606364,\n",
       " 66.3764295815917,\n",
       " 69.40775893947304,\n",
       " 74.56684949761522,\n",
       " 67.49911709792951,\n",
       " 60.83468089831655,\n",
       " 67.08921463991064,\n",
       " 70.03690005275791,\n",
       " 78.6225080304616,\n",
       " 78.34628836135124,\n",
       " 74.831266787353,\n",
       " 75.43676992024511,\n",
       " 78.05299901989673,\n",
       " 68.0578843705856,\n",
       " 78.36185829853706,\n",
       " 78.55252410966817,\n",
       " 75.76058321449223,\n",
       " 71.43911534306679,\n",
       " 76.75341318794884,\n",
       " 74.31893702146176,\n",
       " 78.05140440120216,\n",
       " 70.00356436639494,\n",
       " 77.10179650954963,\n",
       " 78.21073644967167,\n",
       " 78.21451527689729,\n",
       " 70.00896673998267,\n",
       " 76.42879515601433,\n",
       " 78.42413597866411,\n",
       " 68.20007331374359,\n",
       " 78.36819763143721,\n",
       " 77.17734188218716,\n",
       " 75.2556600462716,\n",
       " 61.19163832583664,\n",
       " 75.42302895004947,\n",
       " 70.87347352148052,\n",
       " 72.98335953489672,\n",
       " 76.82646575887765,\n",
       " 74.11871575384991,\n",
       " 77.09203596351571,\n",
       " 78.2303726758348,\n",
       " 56.778428157179555,\n",
       " 78.10549384646384,\n",
       " 78.0241606747551,\n",
       " 78.01037889922085,\n",
       " 74.37647343750575,\n",
       " 64.11757918855015,\n",
       " 78.17616317650797,\n",
       " 78.55252410966817,\n",
       " 78.19376998201328,\n",
       " 76.15211545978222,\n",
       " 77.91055065907312,\n",
       " 78.158857776966,\n",
       " 77.95370195827778,\n",
       " 78.43006046153478,\n",
       " 78.30155825397091,\n",
       " 78.45705424625628,\n",
       " 78.00361758277624,\n",
       " 68.98332786985563,\n",
       " 67.73145809740109,\n",
       " 78.11241802044026,\n",
       " 55.23825645329512,\n",
       " 78.00880027919928,\n",
       " 73.53552907268703,\n",
       " 66.19483291012976,\n",
       " 63.66720198815084,\n",
       " 50.113962375769084,\n",
       " 73.65945164064148,\n",
       " 40.054769616114385,\n",
       " 57.52268077897622,\n",
       " 56.955238995196915,\n",
       " 73.73618107821966,\n",
       " 64.560073605906,\n",
       " 72.36570934496531,\n",
       " 53.75426145897644,\n",
       " 66.2699335747366,\n",
       " 73.19532269209557,\n",
       " 72.7056506813604,\n",
       " 71.4850090648382,\n",
       " 78.067605983532,\n",
       " 66.40447443508609,\n",
       " 72.27431859934758,\n",
       " 70.77531436878257,\n",
       " 75.28471847592975,\n",
       " 78.05231553900244,\n",
       " 77.99214848303642,\n",
       " 74.83339706307606,\n",
       " 72.94056951381721,\n",
       " 74.52248171525154,\n",
       " 74.73812280891191,\n",
       " 76.79494921542694,\n",
       " 76.35215706841556,\n",
       " 70.735825442275,\n",
       " 76.20032168567269,\n",
       " 70.07307763328224,\n",
       " 77.10954836464806,\n",
       " 72.19648179793805,\n",
       " 64.89703864584268,\n",
       " 66.39333231582822,\n",
       " 59.12696589543556,\n",
       " 62.26832743056457,\n",
       " 63.00198854798157,\n",
       " 68.2294320729698,\n",
       " 66.76799664509937,\n",
       " 61.59292564085586,\n",
       " 68.18068032074777,\n",
       " 45.06084421091111,\n",
       " 30.30468744270431,\n",
       " 63.32630025510728,\n",
       " 72.76085492213517,\n",
       " 50.355431444879905,\n",
       " 37.46604287885231,\n",
       " 62.59405633924039,\n",
       " 69.02679509436898,\n",
       " 53.93940089582012,\n",
       " 46.804277582289416,\n",
       " 73.77612302771135,\n",
       " 75.53644315163376,\n",
       " 71.77026024754264,\n",
       " 75.64674755731404,\n",
       " 74.85094672079973,\n",
       " 66.4214456406965,\n",
       " 44.40536638740863,\n",
       " 53.74358101206134,\n",
       " 55.64107943776792,\n",
       " 24.46047105024758,\n",
       " 25.476864818890096,\n",
       " 33.03445692001005,\n",
       " 58.596493034993145,\n",
       " 34.352132757661494,\n",
       " 71.1592869272873,\n",
       " 76.58935563118415,\n",
       " 76.37718670519358,\n",
       " 76.93927663423928,\n",
       " 62.168016608220654,\n",
       " 35.1373568869373,\n",
       " 25.93510123365629,\n",
       " 18.948057947979787,\n",
       " 52.321526162756385,\n",
       " 50.03017525454013,\n",
       " 45.044493126241306,\n",
       " 52.81999395115452,\n",
       " 58.527931186741945,\n",
       " 48.342669030577945,\n",
       " 55.650556151758266,\n",
       " 69.12898506415381,\n",
       " 67.52878227837371,\n",
       " 59.57483445214095]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "\n",
    "X_train = np.array(boston_df_knn[['RM', 'AGE']])\n",
    "X_new = np.array(boston_df_knn['Price'])\n",
    "\n",
    "[euclidean(X_new[0], d) for d in X_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Menerapkan Standard Scaler (Standard Score atau Z-Score)\n",
    "\n",
    "Standardize features by removing the mean and scaling to unit variance.\n",
    "\n",
    "**Standard Score** is the number of standard deviations by which the value of a raw score (i.e., an observed value or data point) is above or below the mean value of what is being observed or measured. Raw scores above the mean have positive standard scores, while those below the mean have negative standard scores.\n",
    "\n",
    "It is calculated by subtracting the population mean from an individual raw score and then dividing the difference by the population standard deviation. This process of converting a raw score into a standard score is called standardizing or normalizing (however, \"normalizing\" can refer to many types of ratios; see normalization for more). Z-Score dikalkulasikan sebagai berikut :\n",
    "\n",
    "\n",
    "$z = \\frac{x - \\bar{x}}{S}$\n",
    "\n",
    "information of the Calculate :\n",
    "- $x$ sebagai nilai Features.\n",
    "- $\\bar{x}$ sebagai nilai rata-rata dari nilai **Z**.\n",
    "- $(S)$ sebagai nilai standard deviation dari sekumpulan nilai Features.\n",
    "\n",
    "\n",
    "Referensi: [https://en.wikipedia.org/wiki/Standard_score](https://en.wikipedia.org/wiki/Standard_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Untuk melakukan **Standard Scaler (Standard Score atau Z-Score)** terlebih dahulu kita melakukan import dengan `from sklearn.preprocessing import StandardScaler` dengan keterangan sebagai berikut :\n",
    "\n",
    "- `ss = StandardScaler()` dengan fungsi StandardScaler() yang ditampung ke dalam variabel `ss` seperti scrript dibawah ini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ss = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Standard Scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Untuk melakukan `Standart Scaler` terlebih dahulu kita memastikan bahwa data yang akan di demo berbentuk data 2 dimensi, berikut cara untuk menampilkan hasil data berbentuk 2 dimensi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.575, 65.2  ],\n",
       "       [ 6.421, 78.9  ],\n",
       "       [ 7.185, 61.1  ],\n",
       "       ...,\n",
       "       [ 6.976, 91.   ],\n",
       "       [ 6.794, 89.3  ],\n",
       "       [ 6.03 , 80.8  ]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = np.array(boston_df_knn[['RM', 'AGE']])\n",
    "X_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Variabel `X_new` yang bernilai `Features` hanya menampung nilai dengan satu dimensi\n",
    "\n",
    "Untuk melakukan `Standard Scaler` kita akan melakukan `reshape` dengan parameter `(-1, 1)` seperti script dibawah ini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1012, 1)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_new.reshape(-1, 1)\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.575],\n",
       "       [65.2  ],\n",
       "       [ 6.421],\n",
       "       ...,\n",
       "       [89.3  ],\n",
       "       [ 6.03 ],\n",
       "       [80.8  ]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Standard Scaler\n",
    "\n",
    "Untuk melakukan Scaling pada Features terlebih dahulu kita melakukan import dengan `from scipy.spatial.distance import euclidean` dengan keterangan sebagai berikut :\n",
    "\n",
    "**X_train_scaled :**\n",
    "- `X_train = np.array(boston_df_knn[['RM', 'AGE']])` dengan np.array memiliki 2 parameter yaitu `RM` dan `AGE` yang ditampung ke dalam variabel `X_train`.\n",
    "- `X_train_scaled = ss.fit_transform(X_train)` dengan ss.fit_transform memiliki parameter yaitu `X_train` yang ditampung ke dalam variabel `X_train_scaled`.\n",
    "\n",
    "**X_new_scaled :**\n",
    "- `X_new = np.array(boston_df_knn[['RM', 'Price']])` dengan np.array memiliki parameter yaitu `[RM, Price]` yang ditampung ke dalam variabel `X_new`.\n",
    "- `X_new_scaled = ss.transform(X_new)` dengan ss.fit_transform memiliki parameter yaitu `X_new` yang ditampung ke dalam variabel `X_new_scaled`.\n",
    "\n",
    "\n",
    "- `jarak = [euclidean(X_new_scaled[0], d) for d in X_train_scaled]` sebagai proses pengukuran yang ditampung ke dalam variabel `jarak` untuk mengetahui apakah hasilnya akan berdampak pada eksistensi **`euclidean`** seperti script dibawah ini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_scaled:\n",
      "[[ 0.41367189 -0.12001342]\n",
      " [ 0.19427445  0.36716642]\n",
      " [ 1.28271368 -0.26581176]\n",
      " ...\n",
      " [ 0.98496002  0.79744934]\n",
      " [ 0.72567214  0.73699637]\n",
      " [-0.36276709  0.43473151]]\n",
      "\n",
      "X_new_scaled: [[ 0.41367189 -1.58510898]\n",
      " [ 0.19427445 -1.67045435]\n",
      " [ 1.28271368 -1.20461086]\n",
      " ...\n",
      " [ 0.98496002 -1.58866503]\n",
      " [ 0.72567214 -1.65623012]\n",
      " [-0.36276709 -2.0153919 ]]\n",
      "\n",
      "jarak: [1.4650955613772816, 1.9645646991690662, 1.5798034000822117, 0.9819014393097831, 1.3481075071479625, 1.2511237325899471, 1.7141176694814708, 2.6274142007094223, 3.018735123768671, 2.346705920001405, 2.5157725481540982, 2.244374218600156, 1.1134051308763053, 1.6131391037821028, 2.257049011097538, 1.5652887875661017, 0.9310568883616464, 2.2146479779944994, 1.655962603513308, 2.019275761497437, 2.9989042752333526, 2.4760663219477284, 2.4852276432727116, 2.912485353107812, 2.659737023164975, 2.597579089138752, 2.5955912668356693, 2.4239943420824144, 2.5060572773151204, 2.2553985214903443, 2.7788762720673077, 2.795994597015078, 2.2465069594032263, 2.815141346383052, 2.6806800132725246, 1.8185250718632324, 1.6918319395965153, 1.2058630763444014, 0.895192134125304, 0.08326045649212173, 0.7029996951287549, 0.8001060791714085, 0.8470042651352684, 0.8100559010229343, 0.9183626522800604, 1.3190875724923583, 1.1716964220637465, 2.32071495097803, 3.0390068094361014, 1.9358582341203998, 1.1643281618978503, 1.5339040009162639, 0.13765303276202917, 0.8272112861395922, 1.289278532498236, 0.9631194278444613, 0.4979216186527961, 0.679822872805732, 0.6399033253684981, 1.238100492336653, 1.9140809010183597, 2.6159717325865643, 1.566752502783988, 0.7395286057469184, 1.4702497961542238, 0.46202594929267227, 1.1506722494207349, 0.997282187836417, 1.469844492053622, 1.0338019040169286, 0.6584259203442839, 0.9047641863254541, 0.9272444110050149, 0.7884735352761194, 0.7712509296925688, 0.8527526179707845, 1.844657028459272, 0.9924856356876287, 1.1637169959225382, 1.0945929962635403, 0.40127186646550295, 1.6512008275860497, 0.4861034753738471, 0.9947241922581467, 0.8936448474171481, 1.1441805216206449, 1.0952128480161494, 1.3337173203944257, 2.2993224416026274, 1.5648729618378725, 1.5139276332976255, 1.7909242687187892, 1.0695112862975975, 0.5470674226903303, 1.951451490320058, 1.2040562751388373, 1.72452453708875, 2.8195056038683037, 1.8320606840474194, 1.819318583757264, 1.999596190073777, 1.7074264126782628, 2.1968104099152863, 2.339300834634249, 2.4179045592861, 2.783420754500055, 2.634112645649373, 2.26796637928366, 2.6034571896888785, 2.439980865693651, 1.209021205220491, 2.057976862937469, 2.6253738112069147, 2.6306164037231947, 2.1890483485045924, 2.4620455334310463, 1.8159489171592242, 2.2283091274603923, 2.012876682803837, 1.8953362328768917, 1.9104441651426782, 2.286773394277026, 2.601590955904199, 2.7907097344880047, 2.739028447514895, 2.4389938145426986, 2.8915640981087773, 2.8520807522182663, 2.667830318191923, 2.847216065029053, 2.6686974395866523, 2.6447130790002085, 2.643792045685322, 2.756352343873543, 2.8909950244381473, 2.660655663310794, 2.630850174674764, 2.6513165176305002, 2.829931991834281, 2.696456789399185, 2.5400931774563342, 3.495444153877651, 3.176785082633628, 3.1291054490627044, 3.5442040837938453, 2.7759660268252513, 3.020641647931572, 3.466982419155703, 3.174399137730248, 2.8806256357862923, 2.6852958741668327, 3.1760365214844364, 3.184021365354253, 2.9224548418516876, 2.638025715023692, 2.169237758533742, 3.105201756689993, 2.66227828263835, 2.7981976048103956, 2.704189482624498, 2.4830070181192276, 2.7089311739283657, 3.1651036391618166, 3.5713720630315713, 2.6206965037772507, 2.5449080651981775, 3.211372480481377, 2.2004549961708437, 2.589727180733, 2.5438803971762742, 2.7013928594211047, 2.7883120032111854, 2.7023527592922822, 2.1491613057125623, 1.8887050319443137, 0.3262279523733284, 1.1427236562690715, 1.7953195153944037, 1.837669364143084, 1.3525297295406724, 2.705731534442822, 1.4907442521333927, 2.56213201490429, 2.5461943406038596, 2.7182171003455617, 1.7027799665818915, 2.0760061441176454, 0.6758231188888587, 0.1833678301077001, 1.0178297160979022, 0.5429987052493276, 0.33624770479380583, 0.862953852202984, 0.5951110692635195, 0.18947423345590877, 1.8737779841202833, 1.0760656387459948, 0.8804549739245174, 1.1181586952574316, 0.6484277043851722, 0.8749263718778827, 0.7800088105046893, 1.5037717497604974, 1.8498731231210896, 2.0974754377909193, 0.9763398940025614, 1.0737665866547625, 2.0669442589470783, 1.444966559673067, 3.2217575143908395, 2.575300913743642, 2.839071999086113, 1.523191530886475, 0.4102453382484008, 1.7321170756986435, 0.8611650650221813, 1.5009452227494124, 2.174846607062326, 2.6365236406420913, 2.4493082636566683, 2.3553781099906623, 2.463814912583847, 1.958099808601989, 2.0207692601179494, 3.0874387344340195, 3.712678464294199, 3.0488941809898873, 2.1571351268365895, 1.602250189421432, 0.0980921656932144, 1.7819798563792821, 2.227252305802317, 3.0618351495955687, 2.8976884551064206, 1.5265579770902569, 1.5045304727467617, 1.868633913522616, 2.027198562934126, 0.23703749670308297, 0.6487075250508404, 1.1710751920462117, 1.613607641970591, 1.0731927473494054, 0.6317434823125292, 2.332953102703805, 2.1468151086823117, 0.7699912616461665, 2.0249348470846282, 0.9152091274359155, 0.30811001083174044, 0.410765985319137, 0.5713366472226938, 0.8187067389942814, 2.4624263854281145, 0.7235857401489265, 1.0109659305415208, 1.3037472311560532, 3.768657664991729, 2.9103660673220584, 2.7292411697566714, 2.2416814905020694, 2.6872348679008424, 3.5364993844044452, 2.726339558948103, 2.566483574479201, 1.9986768546131313, 2.24389285766594, 2.8907882089362382, 1.6309987985710654, 1.6275905633926266, 1.2097651549965471, 0.5502300946355064, 1.2350772234107148, 1.8722021292595696, 0.4100443527678027, 0.7777751796394679, 1.327506632735077, 0.37981410012734085, 0.3170518394891624, 0.4461302183731766, 2.2847750477266144, 0.7306255615504117, 1.7773503929356587, 1.920650594599843, 0.7396557397253742, 0.3303485698670634, 0.5592052825125489, 0.5824707773641999, 0.8527572571937758, 0.041630228246060746, 0.4304083102850388, 0.8268648452099601, 0.08120922285561752, 0.6685923764963861, 1.036193942450871, 0.2920252772922505, 0.9608496810055549, 1.6469812549288596, 0.35581242171616445, 0.8298215601282294, 0.9328715651461322, 0.5835847743509093, 0.22944759091563752, 0.6216108429712366, 1.1209665678748826, 1.214021498557028, 2.085816023142254, 1.6920964887715413, 2.0820488963527795, 2.0615610090023013, 2.3344655937341776, 1.210526671887366, 2.4887371078579266, 2.136799887357245, 2.251013053243615, 2.276582168119415, 2.3062101414209892, 2.038031534768088, 1.5606294516221433, 1.4016572051350673, 1.0285082317685097, 1.1141592769007203, 1.1945891323103974, 2.173730309664403, 0.6162338946480441, 0.38917627112106906, 0.41322024517019457, 0.9909927509263392, 1.009265500271682, 0.42111465112236385, 0.6797491288936373, 1.2478766221090714, 0.7754139716886737, 0.6225408771502235, 0.6390656238334964, 0.852577152757414, 1.2808208264646697, 1.5941006072787327, 0.8741247734568693, 1.1338594512895968, 1.5009860421985268, 1.307552300668617, 1.2704912823865275, 1.1649869668137809, 0.45023339110916455, 1.1822956132513922, 1.3939215903479545, 0.15613125182076756, 0.21998208277758338, 0.6390132435340546, 0.7354734149784671, 0.4232091739759885, 1.003679828090712, 0.4823437806312333, 1.3014329959894793, 0.9243142855780465, 2.6608846789916836, 2.3963190238919214, 2.206617786598045, 2.1417266258539285, 2.289803763992435, 2.430351123918613, 3.094880713639271, 2.559762122284613, 3.775609190834846, 4.858106663042147, 3.319443851769178, 4.715086934719835, 3.540127208829425, 2.5933779476626007, 2.6881531085323327, 2.750572504126348, 2.5369986049458597, 3.599692471326014, 4.399784974861742, 2.8304477399042045, 2.4666016345155795, 2.6781665168008306, 2.5824594136515, 2.7487356221984647, 2.4786269258050053, 2.6709409256674896, 3.081414902960353, 3.0924293486350587, 3.9492600385652863, 3.2191603921892966, 3.8483211582929027, 3.2342016497227095, 3.6242664638081408, 3.153450598160552, 2.8717469792652577, 2.21018430910391, 3.397952900661336, 2.499423295845671, 2.6984413359136066, 2.66405413898019, 2.57179048530604, 2.9130154969250417, 3.139930307738614, 2.172817205316647, 2.829453232800068, 2.7227393346622946, 2.713561228525986, 3.0993823696497156, 2.6418762614748794, 2.9864672740456273, 4.399784974861742, 3.0334750793313163, 2.961205546850543, 2.7312632006899045, 2.943153847730631, 2.705127142879445, 3.87273673866684, 3.375893431673887, 3.9854337235812607, 2.7100584855359178, 2.3936819398733538, 2.939043596616367, 2.8424001158153276, 1.9003337043690822, 2.7126840962806904, 2.6619023612604593, 2.6190094631122527, 2.274427559310942, 2.1946534649123133, 2.7170572397451824, 1.6483627469154152, 2.0164433276145854, 1.9993211543569624, 2.5612479146977325, 2.231865967487974, 2.526785072411424, 1.8190729823144596, 2.2809330466087108, 2.578369626552453, 2.5117548046930125, 2.4696936265491107, 2.7689761900273533, 2.448425259231269, 2.828901111670062, 2.6607110481843113, 2.614145019804994, 2.7497809905843944, 2.7056432988787766, 2.778535330006897, 2.523106483963455, 2.596078898275147, 2.622637386420715, 2.7138601236489044, 2.651721602237344, 2.452017858337588, 2.6410547814700274, 2.4433201412774386, 2.920312590876645, 2.502307829048149, 2.223676967776057, 2.4272787109537513, 2.1993168725461008, 2.158555863461332, 2.2602222353778036, 2.3538524105662426, 2.3075827329055167, 2.1300270421877587, 2.3451057381024683, 1.5618193076852125, 1.4463850644953338, 2.3338818532921475, 2.636137447897231, 1.9100502569817854, 1.691241033582706, 2.2113930966610527, 2.422569857903146, 1.8242144505160551, 1.6543218595822031, 3.0201877491266855, 2.6756415652730126, 2.4784089200018564, 3.173813891102599, 2.6442855691582485, 2.3286468515578025, 1.523084904141657, 1.827122863199355, 2.0078667076734518, 1.2951898333339509, 1.187898989903349, 1.0605332215631866, 2.0901460499366795, 1.4104327320661572, 2.9187066491649127, 3.117173436150179, 3.3737921317952986, 2.790439358694036, 2.2777529149089295, 1.6331832818888636, 1.136827512306256, 1.3005657772628536, 2.423613703412806, 1.996012086281463, 1.6686450142385958, 2.269924083466411, 2.129032574102737, 1.6039867963152292, 1.9829832856833565, 2.450092703309673, 2.3429719125503237, 2.163934625341819]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train = np.array(boston_df_knn[['RM', 'AGE']])\n",
    "X_train_scaled = ss.fit_transform(X_train)\n",
    "print(f'X_train_scaled:\\n{X_train_scaled}\\n')\n",
    "\n",
    "X_new = np.array(boston_df_knn[['RM', 'Price']])\n",
    "X_new_scaled = ss.transform(X_new)\n",
    "print(f'X_new_scaled: {X_new_scaled}\\n')\n",
    "\n",
    "jarak = [euclidean(X_new_scaled[0], d) for d in X_train_scaled]\n",
    "print(f'jarak: {jarak}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Menerapkan Features Scaling pada KNN\n",
    "\n",
    "#### Dataset\n",
    "\n",
    "Sebelumnya kita siapkan terlebih dahulu sebagai berikut :\n",
    "**Training Set**\n",
    "- `X_train` sebagai variabel dengan sekumpulan nilai Features\n",
    "- `y_train` sebagai variabel dengan sekumpulan nilai Target\n",
    "\n",
    "**Test Set** sebagai keperluan evaluasi yaitu `X_test` dan `y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Set\n",
    "X_train = np.array(boston_df_knn[['RM', 'AGE']])\n",
    "\n",
    "y_train = np.array(boston_df_knn[['Price']])\n",
    "\n",
    "# Test Set\n",
    "X_test = np.array(boston_df_knn[['RM', 'AGE']])\n",
    "y_test = np.array(boston_df_knn[['Price']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features Scaling (Standard Scaler)\n",
    "\n",
    "- `X_train_scaled = ss.fit_transform(X_train)` memiliki ss.fit_transform sebagai fit_transform yang memiliki parameter `X_train` yang ditampung ke dalam variabel `X_train_scaled`.\n",
    "- `X_test_scaled = ss.transform(X_test)` memiliki ss.transform sebagai transform yang memiliki parameter `X_test` yang ditampung ke dalam variabel `X_test_scaled`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_scaled:\n",
      "[[ 0.41367189 -0.12001342]\n",
      " [ 0.19427445  0.36716642]\n",
      " [ 1.28271368 -0.26581176]\n",
      " ...\n",
      " [ 0.98496002  0.79744934]\n",
      " [ 0.72567214  0.73699637]\n",
      " [-0.36276709  0.43473151]]\n",
      "\n",
      "X_test_scaled:\n",
      "[[ 0.41367189 -0.12001342]\n",
      " [ 0.19427445  0.36716642]\n",
      " [ 1.28271368 -0.26581176]\n",
      " ...\n",
      " [ 0.98496002  0.79744934]\n",
      " [ 0.72567214  0.73699637]\n",
      " [-0.36276709  0.43473151]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train_scaled = ss.fit_transform(X_train)\n",
    "X_test_scaled = ss.transform(X_test)\n",
    "\n",
    "print(f'X_train_scaled:\\n{X_train_scaled}\\n')\n",
    "print(f'X_test_scaled:\\n{X_test_scaled}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training & Evaluasi Model\n",
    "\n",
    "Pada tahap `Training dan Evaluasi Model` terlebih dahulu kita melakukan model `model.fit(X_train_scaled, y_train)` memiliki 2 parameter yaitu `X_train_scaled` dan `y_train` dengan keterangan sebagai berikut :\n",
    "\n",
    "- `y_pred = model.predict(X_test_scaled)` melakukan prediksi dengan model.predict yang memiliki parameter yaitu `X_test_scaled`.\n",
    "\n",
    "- `MAE = mean_absolute_error(y_test, y_pred)` melakukan prediksi dengan mean_absolute_error yang memiliki 2 parameter yaitu `y_test` dan `y_pred` yang ditampung ke dalam variabel `MAE`.\n",
    "\n",
    "- `MSE = mean_squared_error(y_test, y_pred)` melakukan prediksi dengan mean_squared_error yang memiliki 2 parameter yaitu `y_test` dan `y_pred` yang ditampung ke dalam variabel `MSE`.\n",
    "\n",
    "Seperti script dibawah ini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 2.847957839262187\n",
      "MSE: 18.650188844971453\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train)\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "MAE = mean_absolute_error(y_test, y_pred)\n",
    "MSE = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f'MAE: {MAE}')\n",
    "print(f'MSE: {MSE}')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
